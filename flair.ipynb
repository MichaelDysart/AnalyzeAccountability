{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "flair.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anjapago/AnalyzeAccountability/blob/master/flair.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtgjqStCtTF8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install git+https://github.com/anjapago/flair"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKBOr5FsNy19",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "81dec7bf-a08c-4c6d-ad62-11ed0494dc4f"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentPoolEmbeddings\n",
        "from flair.data_fetcher import NLPTaskDataFetcher\n",
        "from flair.models import TextClassifier\n",
        "from flair.trainers import ModelTrainer\n",
        "from pathlib import Path\n",
        "\n",
        "corpus = NLPTaskDataFetcher.load_classification_corpus(Path('./'),\n",
        "                                                       test_file='flair_test.csv',\n",
        "                                                       dev_file='flair_dev.csv',\n",
        "                                                       train_file='flair_train.csv')\n",
        "word_embeddings = [WordEmbeddings('glove'),\n",
        "                   FlairEmbeddings('news-forward-fast'),\n",
        "                   FlairEmbeddings('news-backward-fast')]\n",
        "document_embeddings = DocumentPoolEmbeddings(word_embeddings)\n",
        "\n",
        "print(\"Create Classifier *************************\")\n",
        "classifier = TextClassifier(document_embeddings,\n",
        "                            label_dictionary=corpus.make_label_dictionary(), multi_label=False)\n",
        "print(\"Create Trainer *******************************\")\n",
        "trainer = ModelTrainer(classifier, corpus)\n",
        "print(\"Begin Training *******************************\")\n",
        "trainer.train(max_epochs=10, base_path = \"flair_pooled\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-07-22 03:47:07,440 Reading data from .\n",
            "2019-07-22 03:47:07,442 Train: flair_train.csv\n",
            "2019-07-22 03:47:07,443 Dev: flair_dev.csv\n",
            "2019-07-22 03:47:07,444 Test: flair_test.csv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: Call to deprecated function (or staticmethod) load_classification_corpus. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/flair/data_fetcher.py:447: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
            "  max_tokens_per_doc=max_tokens_per_doc,\n",
            "/usr/local/lib/python3.6/dist-packages/flair/data_fetcher.py:454: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
            "  max_tokens_per_doc=max_tokens_per_doc,\n",
            "/usr/local/lib/python3.6/dist-packages/flair/data_fetcher.py:463: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
            "  max_tokens_per_doc=max_tokens_per_doc,\n",
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Create Classifier *************************\n",
            "2019-07-22 03:47:26,526 Computing label dictionary. Progress:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 34066/34066 [00:00<00:00, 249225.83it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-07-22 03:47:26,666 [b'0', b'1']\n",
            "Create Trainer *******************************\n",
            "Begin Training *******************************\n",
            "2019-07-22 03:47:26,727 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-07-22 03:47:26,729 Model: \"TextClassifier(\n",
            "  (document_embeddings): DocumentPoolEmbeddings(\n",
            "    fine_tune_mode=linear, pooling=mean\n",
            "    (embeddings): StackedEmbeddings(\n",
            "      (list_embedding_0): WordEmbeddings('glove')\n",
            "      (list_embedding_1): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.25)\n",
            "          (encoder): Embedding(275, 100)\n",
            "          (rnn): LSTM(100, 1024)\n",
            "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (list_embedding_2): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.25)\n",
            "          (encoder): Embedding(275, 100)\n",
            "          (rnn): LSTM(100, 1024)\n",
            "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (embedding_flex): Linear(in_features=2148, out_features=2148, bias=False)\n",
            "  )\n",
            "  (decoder): Linear(in_features=2148, out_features=2, bias=True)\n",
            "  (loss_function): CrossEntropyLoss()\n",
            ")\"\n",
            "2019-07-22 03:47:26,730 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 03:47:26,731 Corpus: \"Corpus: 34066 train + 5678 dev + 5678 test sentences\"\n",
            "2019-07-22 03:47:26,732 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 03:47:26,734 Parameters:\n",
            "2019-07-22 03:47:26,734  - learning_rate: \"0.1\"\n",
            "2019-07-22 03:47:26,735  - mini_batch_size: \"32\"\n",
            "2019-07-22 03:47:26,737  - patience: \"3\"\n",
            "2019-07-22 03:47:26,738  - anneal_factor: \"0.5\"\n",
            "2019-07-22 03:47:26,739  - max_epochs: \"10\"\n",
            "2019-07-22 03:47:26,740  - shuffle: \"True\"\n",
            "2019-07-22 03:47:26,741  - train_with_dev: \"False\"\n",
            "2019-07-22 03:47:26,742 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 03:47:26,743 Model training base path: \"flair_pooled\"\n",
            "2019-07-22 03:47:26,744 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 03:47:26,745 Device: cuda:0\n",
            "2019-07-22 03:47:26,747 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 03:47:26,748 Embedding storage mode: cpu\n",
            "2019-07-22 03:47:26,750 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 03:47:27,002 epoch 1 - iter 0/1065 - loss 0.68184566\n",
            "2019-07-22 03:47:44,084 epoch 1 - iter 106/1065 - loss 0.38421781\n",
            "2019-07-22 03:48:01,345 epoch 1 - iter 212/1065 - loss 0.38004329\n",
            "2019-07-22 03:48:18,681 epoch 1 - iter 318/1065 - loss 0.37059110\n",
            "2019-07-22 03:48:40,605 epoch 1 - iter 424/1065 - loss 0.36299340\n",
            "2019-07-22 03:48:58,240 epoch 1 - iter 530/1065 - loss 0.36130671\n",
            "2019-07-22 03:49:15,350 epoch 1 - iter 636/1065 - loss 0.35745760\n",
            "2019-07-22 03:49:35,200 epoch 1 - iter 742/1065 - loss 0.35480835\n",
            "2019-07-22 03:49:52,634 epoch 1 - iter 848/1065 - loss 0.35422706\n",
            "2019-07-22 03:50:09,576 epoch 1 - iter 954/1065 - loss 0.35197819\n",
            "2019-07-22 03:50:29,598 epoch 1 - iter 1060/1065 - loss 0.34931223\n",
            "2019-07-22 03:50:30,285 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 03:50:30,287 EPOCH 1 done: loss 0.3491 - lr 0.1000\n",
            "2019-07-22 03:50:50,033 DEV : loss 0.37265369296073914 - score 0.0176\n",
            "2019-07-22 03:50:58,064 BAD EPOCHS (no improvement): 0\n",
            "2019-07-22 03:51:02,400 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 03:51:02,470 epoch 2 - iter 0/1065 - loss 0.44348967\n",
            "2019-07-22 03:51:07,237 epoch 2 - iter 106/1065 - loss 0.32683076\n",
            "2019-07-22 03:51:12,008 epoch 2 - iter 212/1065 - loss 0.31553974\n",
            "2019-07-22 03:51:16,816 epoch 2 - iter 318/1065 - loss 0.31281633\n",
            "2019-07-22 03:51:21,639 epoch 2 - iter 424/1065 - loss 0.32315282\n",
            "2019-07-22 03:51:26,468 epoch 2 - iter 530/1065 - loss 0.32357276\n",
            "2019-07-22 03:51:31,398 epoch 2 - iter 636/1065 - loss 0.32344180\n",
            "2019-07-22 03:51:36,295 epoch 2 - iter 742/1065 - loss 0.32502988\n",
            "2019-07-22 03:51:41,216 epoch 2 - iter 848/1065 - loss 0.32669898\n",
            "2019-07-22 03:51:46,080 epoch 2 - iter 954/1065 - loss 0.32679016\n",
            "2019-07-22 03:51:51,041 epoch 2 - iter 1060/1065 - loss 0.32844628\n",
            "2019-07-22 03:51:51,212 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 03:51:51,214 EPOCH 2 done: loss 0.3286 - lr 0.1000\n",
            "2019-07-22 03:51:56,151 DEV : loss 0.39004209637641907 - score 0.4484\n",
            "2019-07-22 03:51:56,660 BAD EPOCHS (no improvement): 0\n",
            "2019-07-22 03:52:00,620 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 03:52:00,679 epoch 3 - iter 0/1065 - loss 0.47302920\n",
            "2019-07-22 03:52:05,213 epoch 3 - iter 106/1065 - loss 0.32606514\n",
            "2019-07-22 03:52:09,668 epoch 3 - iter 212/1065 - loss 0.32859944\n",
            "2019-07-22 03:52:14,184 epoch 3 - iter 318/1065 - loss 0.32607363\n",
            "2019-07-22 03:52:18,771 epoch 3 - iter 424/1065 - loss 0.32758413\n",
            "2019-07-22 03:52:23,307 epoch 3 - iter 530/1065 - loss 0.32604836\n",
            "2019-07-22 03:52:27,873 epoch 3 - iter 636/1065 - loss 0.32599391\n",
            "2019-07-22 03:52:32,400 epoch 3 - iter 742/1065 - loss 0.32655645\n",
            "2019-07-22 03:52:36,823 epoch 3 - iter 848/1065 - loss 0.32479959\n",
            "2019-07-22 03:52:41,393 epoch 3 - iter 954/1065 - loss 0.32504329\n",
            "2019-07-22 03:52:45,914 epoch 3 - iter 1060/1065 - loss 0.32367451\n",
            "2019-07-22 03:52:46,084 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 03:52:46,086 EPOCH 3 done: loss 0.3238 - lr 0.1000\n",
            "2019-07-22 03:52:50,802 DEV : loss 0.33652469515800476 - score 0.1038\n",
            "2019-07-22 03:52:51,277 BAD EPOCHS (no improvement): 1\n",
            "2019-07-22 03:52:51,278 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 03:52:51,326 epoch 4 - iter 0/1065 - loss 0.42045212\n",
            "2019-07-22 03:52:55,836 epoch 4 - iter 106/1065 - loss 0.32217883\n",
            "2019-07-22 03:53:00,251 epoch 4 - iter 212/1065 - loss 0.31505778\n",
            "2019-07-22 03:53:04,683 epoch 4 - iter 318/1065 - loss 0.32125966\n",
            "2019-07-22 03:53:09,115 epoch 4 - iter 424/1065 - loss 0.32327686\n",
            "2019-07-22 03:53:13,524 epoch 4 - iter 530/1065 - loss 0.32047176\n",
            "2019-07-22 03:53:17,894 epoch 4 - iter 636/1065 - loss 0.32139229\n",
            "2019-07-22 03:53:22,320 epoch 4 - iter 742/1065 - loss 0.32107320\n",
            "2019-07-22 03:53:26,672 epoch 4 - iter 848/1065 - loss 0.31978307\n",
            "2019-07-22 03:53:30,996 epoch 4 - iter 954/1065 - loss 0.32070599\n",
            "2019-07-22 03:53:35,464 epoch 4 - iter 1060/1065 - loss 0.32032568\n",
            "2019-07-22 03:53:35,626 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 03:53:35,628 EPOCH 4 done: loss 0.3201 - lr 0.1000\n",
            "2019-07-22 03:53:40,375 DEV : loss 0.34196674823760986 - score 0.0678\n",
            "2019-07-22 03:53:40,823 BAD EPOCHS (no improvement): 2\n",
            "2019-07-22 03:53:40,825 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 03:53:40,877 epoch 5 - iter 0/1065 - loss 0.43574569\n",
            "2019-07-22 03:53:45,299 epoch 5 - iter 106/1065 - loss 0.31828655\n",
            "2019-07-22 03:53:49,695 epoch 5 - iter 212/1065 - loss 0.31963812\n",
            "2019-07-22 03:53:54,166 epoch 5 - iter 318/1065 - loss 0.32250259\n",
            "2019-07-22 03:53:58,554 epoch 5 - iter 424/1065 - loss 0.32106598\n",
            "2019-07-22 03:54:03,007 epoch 5 - iter 530/1065 - loss 0.32025737\n",
            "2019-07-22 03:54:07,444 epoch 5 - iter 636/1065 - loss 0.31765589\n",
            "2019-07-22 03:54:11,872 epoch 5 - iter 742/1065 - loss 0.31920903\n",
            "2019-07-22 03:54:16,288 epoch 5 - iter 848/1065 - loss 0.31973884\n",
            "2019-07-22 03:54:20,695 epoch 5 - iter 954/1065 - loss 0.31955296\n",
            "2019-07-22 03:54:25,060 epoch 5 - iter 1060/1065 - loss 0.31824849\n",
            "2019-07-22 03:54:25,225 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 03:54:25,227 EPOCH 5 done: loss 0.3181 - lr 0.1000\n",
            "2019-07-22 03:54:29,931 DEV : loss 0.3223678171634674 - score 0.1771\n",
            "2019-07-22 03:54:30,407 BAD EPOCHS (no improvement): 3\n",
            "2019-07-22 03:54:30,409 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 03:54:30,456 epoch 6 - iter 0/1065 - loss 0.12489024\n",
            "2019-07-22 03:54:34,927 epoch 6 - iter 106/1065 - loss 0.30962621\n",
            "2019-07-22 03:54:39,324 epoch 6 - iter 212/1065 - loss 0.31051640\n",
            "2019-07-22 03:54:43,663 epoch 6 - iter 318/1065 - loss 0.31176834\n",
            "2019-07-22 03:54:48,105 epoch 6 - iter 424/1065 - loss 0.31432784\n",
            "2019-07-22 03:54:52,463 epoch 6 - iter 530/1065 - loss 0.31334368\n",
            "2019-07-22 03:54:56,840 epoch 6 - iter 636/1065 - loss 0.31363607\n",
            "2019-07-22 03:55:01,286 epoch 6 - iter 742/1065 - loss 0.31386995\n",
            "2019-07-22 03:55:05,743 epoch 6 - iter 848/1065 - loss 0.31541133\n",
            "2019-07-22 03:55:10,118 epoch 6 - iter 954/1065 - loss 0.31480838\n",
            "2019-07-22 03:55:14,498 epoch 6 - iter 1060/1065 - loss 0.31555212\n",
            "2019-07-22 03:55:14,654 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 03:55:14,655 EPOCH 6 done: loss 0.3157 - lr 0.1000\n",
            "2019-07-22 03:55:19,383 DEV : loss 0.318146288394928 - score 0.2518\n",
            "Epoch     5: reducing learning rate of group 0 to 5.0000e-02.\n",
            "2019-07-22 03:55:19,825 BAD EPOCHS (no improvement): 4\n",
            "2019-07-22 03:55:19,827 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 03:55:19,873 epoch 7 - iter 0/1065 - loss 0.26601648\n",
            "2019-07-22 03:55:24,372 epoch 7 - iter 106/1065 - loss 0.31835437\n",
            "2019-07-22 03:55:28,774 epoch 7 - iter 212/1065 - loss 0.31546714\n",
            "2019-07-22 03:55:33,222 epoch 7 - iter 318/1065 - loss 0.31309860\n",
            "2019-07-22 03:55:37,662 epoch 7 - iter 424/1065 - loss 0.30686858\n",
            "2019-07-22 03:55:42,089 epoch 7 - iter 530/1065 - loss 0.30579954\n",
            "2019-07-22 03:55:46,540 epoch 7 - iter 636/1065 - loss 0.30612647\n",
            "2019-07-22 03:55:51,055 epoch 7 - iter 742/1065 - loss 0.30720972\n",
            "2019-07-22 03:55:55,505 epoch 7 - iter 848/1065 - loss 0.30756212\n",
            "2019-07-22 03:55:59,841 epoch 7 - iter 954/1065 - loss 0.30941953\n",
            "2019-07-22 03:56:04,194 epoch 7 - iter 1060/1065 - loss 0.30857472\n",
            "2019-07-22 03:56:04,351 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 03:56:04,353 EPOCH 7 done: loss 0.3083 - lr 0.0500\n",
            "2019-07-22 03:56:09,062 DEV : loss 0.31720486283302307 - score 0.2278\n",
            "2019-07-22 03:56:09,567 BAD EPOCHS (no improvement): 1\n",
            "2019-07-22 03:56:09,568 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 03:56:09,617 epoch 8 - iter 0/1065 - loss 0.38415733\n",
            "2019-07-22 03:56:14,090 epoch 8 - iter 106/1065 - loss 0.31667772\n",
            "2019-07-22 03:56:18,615 epoch 8 - iter 212/1065 - loss 0.30980231\n",
            "2019-07-22 03:56:22,991 epoch 8 - iter 318/1065 - loss 0.30916575\n",
            "2019-07-22 03:56:27,365 epoch 8 - iter 424/1065 - loss 0.31111348\n",
            "2019-07-22 03:56:31,781 epoch 8 - iter 530/1065 - loss 0.30843759\n",
            "2019-07-22 03:56:36,232 epoch 8 - iter 636/1065 - loss 0.30705908\n",
            "2019-07-22 03:56:40,705 epoch 8 - iter 742/1065 - loss 0.30785625\n",
            "2019-07-22 03:56:45,129 epoch 8 - iter 848/1065 - loss 0.30678692\n",
            "2019-07-22 03:56:49,626 epoch 8 - iter 954/1065 - loss 0.30658904\n",
            "2019-07-22 03:56:54,136 epoch 8 - iter 1060/1065 - loss 0.30710384\n",
            "2019-07-22 03:56:54,304 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 03:56:54,306 EPOCH 8 done: loss 0.3070 - lr 0.0500\n",
            "2019-07-22 03:56:59,152 DEV : loss 0.3147706985473633 - score 0.3096\n",
            "2019-07-22 03:56:59,660 BAD EPOCHS (no improvement): 2\n",
            "2019-07-22 03:56:59,662 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 03:56:59,708 epoch 9 - iter 0/1065 - loss 0.40244189\n",
            "2019-07-22 03:57:04,211 epoch 9 - iter 106/1065 - loss 0.30463433\n",
            "2019-07-22 03:57:08,688 epoch 9 - iter 212/1065 - loss 0.30744208\n",
            "2019-07-22 03:57:13,100 epoch 9 - iter 318/1065 - loss 0.30912026\n",
            "2019-07-22 03:57:17,550 epoch 9 - iter 424/1065 - loss 0.31028799\n",
            "2019-07-22 03:57:22,032 epoch 9 - iter 530/1065 - loss 0.30869827\n",
            "2019-07-22 03:57:26,494 epoch 9 - iter 636/1065 - loss 0.30777967\n",
            "2019-07-22 03:57:30,989 epoch 9 - iter 742/1065 - loss 0.30688705\n",
            "2019-07-22 03:57:35,479 epoch 9 - iter 848/1065 - loss 0.30723536\n",
            "2019-07-22 03:57:40,006 epoch 9 - iter 954/1065 - loss 0.30823493\n",
            "2019-07-22 03:57:44,434 epoch 9 - iter 1060/1065 - loss 0.30707881\n",
            "2019-07-22 03:57:44,598 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 03:57:44,599 EPOCH 9 done: loss 0.3071 - lr 0.0500\n",
            "2019-07-22 03:57:49,548 DEV : loss 0.31398388743400574 - score 0.277\n",
            "2019-07-22 03:57:50,062 BAD EPOCHS (no improvement): 3\n",
            "2019-07-22 03:57:50,064 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 03:57:50,113 epoch 10 - iter 0/1065 - loss 0.29354569\n",
            "2019-07-22 03:57:54,628 epoch 10 - iter 106/1065 - loss 0.30070359\n",
            "2019-07-22 03:57:59,131 epoch 10 - iter 212/1065 - loss 0.29845202\n",
            "2019-07-22 03:58:03,595 epoch 10 - iter 318/1065 - loss 0.30489515\n",
            "2019-07-22 03:58:08,033 epoch 10 - iter 424/1065 - loss 0.30220119\n",
            "2019-07-22 03:58:12,483 epoch 10 - iter 530/1065 - loss 0.30570835\n",
            "2019-07-22 03:58:16,942 epoch 10 - iter 636/1065 - loss 0.30581418\n",
            "2019-07-22 03:58:21,392 epoch 10 - iter 742/1065 - loss 0.30576249\n",
            "2019-07-22 03:58:25,885 epoch 10 - iter 848/1065 - loss 0.30536298\n",
            "2019-07-22 03:58:30,363 epoch 10 - iter 954/1065 - loss 0.30535217\n",
            "2019-07-22 03:58:34,850 epoch 10 - iter 1060/1065 - loss 0.30503712\n",
            "2019-07-22 03:58:35,013 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 03:58:35,014 EPOCH 10 done: loss 0.3050 - lr 0.0500\n",
            "2019-07-22 03:58:39,945 DEV : loss 0.31301671266555786 - score 0.3472\n",
            "Epoch     9: reducing learning rate of group 0 to 2.5000e-02.\n",
            "2019-07-22 03:58:40,448 BAD EPOCHS (no improvement): 4\n",
            "2019-07-22 03:58:44,155 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 03:58:44,156 Testing using best model ...\n",
            "2019-07-22 03:58:44,158 loading file flair_pooled/best-model.pt\n",
            "2019-07-22 03:59:08,440 0.3801\t0.4457\t0.4103\n",
            "2019-07-22 03:59:08,441 \n",
            "MICRO_AVG: acc 0.7151 - f1-score 0.8339\n",
            "MACRO_AVG: acc 0.5409 - f1-score 0.6568\n",
            "0          tp: 4407 - fp: 408 - fn: 535 - tn: 328 - precision: 0.9153 - recall: 0.8917 - accuracy: 0.8237 - f1-score: 0.9033\n",
            "1          tp: 328 - fp: 535 - fn: 408 - tn: 4407 - precision: 0.3801 - recall: 0.4457 - accuracy: 0.2581 - f1-score: 0.4103\n",
            "2019-07-22 03:59:08,442 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dev_loss_history': [tensor(0.3727, device='cuda:0'),\n",
              "  tensor(0.3900, device='cuda:0'),\n",
              "  tensor(0.3365, device='cuda:0'),\n",
              "  tensor(0.3420, device='cuda:0'),\n",
              "  tensor(0.3224, device='cuda:0'),\n",
              "  tensor(0.3181, device='cuda:0'),\n",
              "  tensor(0.3172, device='cuda:0'),\n",
              "  tensor(0.3148, device='cuda:0'),\n",
              "  tensor(0.3140, device='cuda:0'),\n",
              "  tensor(0.3130, device='cuda:0')],\n",
              " 'dev_score_history': [0.0176,\n",
              "  0.4484,\n",
              "  0.1038,\n",
              "  0.0678,\n",
              "  0.1771,\n",
              "  0.2518,\n",
              "  0.2278,\n",
              "  0.3096,\n",
              "  0.277,\n",
              "  0.3472],\n",
              " 'test_score': 0.4103,\n",
              " 'train_loss_history': [0.3490674949098081,\n",
              "  0.32861952582995096,\n",
              "  0.3238305854055803,\n",
              "  0.3200767190523551,\n",
              "  0.31807704455975633,\n",
              "  0.3157115360206002,\n",
              "  0.30832492641999687,\n",
              "  0.30695674105639187,\n",
              "  0.30709897971628974,\n",
              "  0.3050481594924076]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxfs6DE-PsZx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d784c941-435b-4104-dca2-9a41a2b29c95"
      },
      "source": [
        "from flair.embeddings import DocumentRNNEmbeddings\n",
        "corpus = NLPTaskDataFetcher.load_classification_corpus(Path('./'),\n",
        "                                                       test_file='flair_test.csv',\n",
        "                                                       dev_file='flair_dev.csv',\n",
        "                                                       train_file='flair_train.csv')\n",
        "word_embeddings = [WordEmbeddings('glove'),\n",
        "                   FlairEmbeddings('news-forward-fast'),\n",
        "                   FlairEmbeddings('news-backward-fast')]\n",
        "document_embeddings = DocumentRNNEmbeddings(word_embeddings, hidden_size=512,\n",
        "                                             reproject_words=True, reproject_words_dimension=256)\n",
        "\n",
        "classifier = TextClassifier(document_embeddings,\n",
        "                            label_dictionary=corpus.make_label_dictionary(), multi_label=False)\n",
        "trainer = ModelTrainer(classifier, corpus)\n",
        "trainer.train(max_epochs=10, base_path = \"flair_rnn\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-07-22 04:00:11,940 Reading data from .\n",
            "2019-07-22 04:00:11,941 Train: flair_train.csv\n",
            "2019-07-22 04:00:11,943 Dev: flair_dev.csv\n",
            "2019-07-22 04:00:11,944 Test: flair_test.csv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated function (or staticmethod) load_classification_corpus. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/flair/data_fetcher.py:447: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
            "  max_tokens_per_doc=max_tokens_per_doc,\n",
            "/usr/local/lib/python3.6/dist-packages/flair/data_fetcher.py:454: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
            "  max_tokens_per_doc=max_tokens_per_doc,\n",
            "/usr/local/lib/python3.6/dist-packages/flair/data_fetcher.py:463: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
            "  max_tokens_per_doc=max_tokens_per_doc,\n",
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-07-22 04:00:29,254 Computing label dictionary. Progress:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 34066/34066 [00:00<00:00, 258607.37it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-07-22 04:00:29,390 [b'0', b'1']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-07-22 04:00:29,513 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 04:00:29,514 Model: \"TextClassifier(\n",
            "  (document_embeddings): DocumentRNNEmbeddings(\n",
            "    (embeddings): StackedEmbeddings(\n",
            "      (list_embedding_0): WordEmbeddings('glove')\n",
            "      (list_embedding_1): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.25)\n",
            "          (encoder): Embedding(275, 100)\n",
            "          (rnn): LSTM(100, 1024)\n",
            "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (list_embedding_2): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.25)\n",
            "          (encoder): Embedding(275, 100)\n",
            "          (rnn): LSTM(100, 1024)\n",
            "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (word_reprojection_map): Linear(in_features=2148, out_features=256, bias=True)\n",
            "    (rnn): GRU(256, 512)\n",
            "    (dropout): Dropout(p=0.5)\n",
            "  )\n",
            "  (decoder): Linear(in_features=512, out_features=2, bias=True)\n",
            "  (loss_function): CrossEntropyLoss()\n",
            ")\"\n",
            "2019-07-22 04:00:29,516 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 04:00:29,517 Corpus: \"Corpus: 34066 train + 5678 dev + 5678 test sentences\"\n",
            "2019-07-22 04:00:29,518 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 04:00:29,518 Parameters:\n",
            "2019-07-22 04:00:29,519  - learning_rate: \"0.1\"\n",
            "2019-07-22 04:00:29,521  - mini_batch_size: \"32\"\n",
            "2019-07-22 04:00:29,521  - patience: \"3\"\n",
            "2019-07-22 04:00:29,522  - anneal_factor: \"0.5\"\n",
            "2019-07-22 04:00:29,523  - max_epochs: \"10\"\n",
            "2019-07-22 04:00:29,524  - shuffle: \"True\"\n",
            "2019-07-22 04:00:29,525  - train_with_dev: \"False\"\n",
            "2019-07-22 04:00:29,525 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 04:00:29,526 Model training base path: \"flair_rnn\"\n",
            "2019-07-22 04:00:29,527 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 04:00:29,528 Device: cuda:0\n",
            "2019-07-22 04:00:29,529 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 04:00:29,530 Embedding storage mode: cpu\n",
            "2019-07-22 04:00:29,531 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 04:00:29,771 epoch 1 - iter 0/1065 - loss 0.71697867\n",
            "2019-07-22 04:00:46,573 epoch 1 - iter 106/1065 - loss 0.39584383\n",
            "2019-07-22 04:01:03,520 epoch 1 - iter 212/1065 - loss 0.38525563\n",
            "2019-07-22 04:01:36,681 epoch 1 - iter 318/1065 - loss 0.38102248\n",
            "2019-07-22 04:01:53,170 epoch 1 - iter 424/1065 - loss 0.37796114\n",
            "2019-07-22 04:02:11,695 epoch 1 - iter 530/1065 - loss 0.37297430\n",
            "2019-07-22 04:02:28,415 epoch 1 - iter 636/1065 - loss 0.37292372\n",
            "2019-07-22 04:02:46,593 epoch 1 - iter 742/1065 - loss 0.37001234\n",
            "2019-07-22 04:03:04,123 epoch 1 - iter 848/1065 - loss 0.36906210\n",
            "2019-07-22 04:03:24,429 epoch 1 - iter 954/1065 - loss 0.37027735\n",
            "2019-07-22 04:03:40,711 epoch 1 - iter 1060/1065 - loss 0.36767127\n",
            "2019-07-22 04:03:41,329 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 04:03:41,330 EPOCH 1 done: loss 0.3679 - lr 0.1000\n",
            "2019-07-22 04:04:00,505 DEV : loss 0.3532070815563202 - score 0.1001\n",
            "2019-07-22 04:04:07,975 BAD EPOCHS (no improvement): 0\n",
            "2019-07-22 04:04:11,524 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 04:04:11,566 epoch 2 - iter 0/1065 - loss 0.30223742\n",
            "2019-07-22 04:04:15,058 epoch 2 - iter 106/1065 - loss 0.36038454\n",
            "2019-07-22 04:04:18,506 epoch 2 - iter 212/1065 - loss 0.35472878\n",
            "2019-07-22 04:04:22,041 epoch 2 - iter 318/1065 - loss 0.35719530\n",
            "2019-07-22 04:04:25,482 epoch 2 - iter 424/1065 - loss 0.35433677\n",
            "2019-07-22 04:04:29,059 epoch 2 - iter 530/1065 - loss 0.35541551\n",
            "2019-07-22 04:04:32,545 epoch 2 - iter 636/1065 - loss 0.35463561\n",
            "2019-07-22 04:04:36,108 epoch 2 - iter 742/1065 - loss 0.35337699\n",
            "2019-07-22 04:04:39,556 epoch 2 - iter 848/1065 - loss 0.34951509\n",
            "2019-07-22 04:04:42,954 epoch 2 - iter 954/1065 - loss 0.34826944\n",
            "2019-07-22 04:04:46,461 epoch 2 - iter 1060/1065 - loss 0.34781102\n",
            "2019-07-22 04:04:46,608 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 04:04:46,609 EPOCH 2 done: loss 0.3475 - lr 0.1000\n",
            "2019-07-22 04:04:50,119 DEV : loss 0.34453338384628296 - score 0.0858\n",
            "2019-07-22 04:04:50,621 BAD EPOCHS (no improvement): 1\n",
            "2019-07-22 04:04:50,622 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 04:04:50,668 epoch 3 - iter 0/1065 - loss 0.08161123\n",
            "2019-07-22 04:04:54,268 epoch 3 - iter 106/1065 - loss 0.33274176\n",
            "2019-07-22 04:04:57,788 epoch 3 - iter 212/1065 - loss 0.33402880\n",
            "2019-07-22 04:05:01,212 epoch 3 - iter 318/1065 - loss 0.33780109\n",
            "2019-07-22 04:05:04,714 epoch 3 - iter 424/1065 - loss 0.33544124\n",
            "2019-07-22 04:05:08,190 epoch 3 - iter 530/1065 - loss 0.33574307\n",
            "2019-07-22 04:05:11,747 epoch 3 - iter 636/1065 - loss 0.33423237\n",
            "2019-07-22 04:05:15,286 epoch 3 - iter 742/1065 - loss 0.33644470\n",
            "2019-07-22 04:05:18,749 epoch 3 - iter 848/1065 - loss 0.33693728\n",
            "2019-07-22 04:05:22,284 epoch 3 - iter 954/1065 - loss 0.33755691\n",
            "2019-07-22 04:05:25,882 epoch 3 - iter 1060/1065 - loss 0.33598328\n",
            "2019-07-22 04:05:26,030 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 04:05:26,032 EPOCH 3 done: loss 0.3357 - lr 0.1000\n",
            "2019-07-22 04:05:29,769 DEV : loss 0.35708364844322205 - score 0.0587\n",
            "2019-07-22 04:05:30,247 BAD EPOCHS (no improvement): 2\n",
            "2019-07-22 04:05:30,248 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 04:05:30,285 epoch 4 - iter 0/1065 - loss 0.47227418\n",
            "2019-07-22 04:05:33,879 epoch 4 - iter 106/1065 - loss 0.32297500\n",
            "2019-07-22 04:05:37,494 epoch 4 - iter 212/1065 - loss 0.33161216\n",
            "2019-07-22 04:05:41,027 epoch 4 - iter 318/1065 - loss 0.32630636\n",
            "2019-07-22 04:05:44,640 epoch 4 - iter 424/1065 - loss 0.32840556\n",
            "2019-07-22 04:05:48,153 epoch 4 - iter 530/1065 - loss 0.33165247\n",
            "2019-07-22 04:05:51,563 epoch 4 - iter 636/1065 - loss 0.33042862\n",
            "2019-07-22 04:05:55,035 epoch 4 - iter 742/1065 - loss 0.33239045\n",
            "2019-07-22 04:05:58,562 epoch 4 - iter 848/1065 - loss 0.33086279\n",
            "2019-07-22 04:06:02,035 epoch 4 - iter 954/1065 - loss 0.33097519\n",
            "2019-07-22 04:06:05,767 epoch 4 - iter 1060/1065 - loss 0.33091111\n",
            "2019-07-22 04:06:05,924 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 04:06:05,925 EPOCH 4 done: loss 0.3308 - lr 0.1000\n",
            "2019-07-22 04:06:09,714 DEV : loss 0.32863762974739075 - score 0.3167\n",
            "2019-07-22 04:06:10,228 BAD EPOCHS (no improvement): 0\n",
            "2019-07-22 04:06:13,783 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 04:06:13,832 epoch 5 - iter 0/1065 - loss 0.35133940\n",
            "2019-07-22 04:06:17,569 epoch 5 - iter 106/1065 - loss 0.30968454\n",
            "2019-07-22 04:06:21,109 epoch 5 - iter 212/1065 - loss 0.31722393\n",
            "2019-07-22 04:06:24,678 epoch 5 - iter 318/1065 - loss 0.31818248\n",
            "2019-07-22 04:06:28,226 epoch 5 - iter 424/1065 - loss 0.31867800\n",
            "2019-07-22 04:06:31,656 epoch 5 - iter 530/1065 - loss 0.32416169\n",
            "2019-07-22 04:06:35,126 epoch 5 - iter 636/1065 - loss 0.32439272\n",
            "2019-07-22 04:06:38,680 epoch 5 - iter 742/1065 - loss 0.32482870\n",
            "2019-07-22 04:06:42,250 epoch 5 - iter 848/1065 - loss 0.32500438\n",
            "2019-07-22 04:06:45,737 epoch 5 - iter 954/1065 - loss 0.32518803\n",
            "2019-07-22 04:06:49,382 epoch 5 - iter 1060/1065 - loss 0.32646913\n",
            "2019-07-22 04:06:49,531 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 04:06:49,532 EPOCH 5 done: loss 0.3266 - lr 0.1000\n",
            "2019-07-22 04:06:53,275 DEV : loss 0.3483636677265167 - score 0.0202\n",
            "2019-07-22 04:06:53,789 BAD EPOCHS (no improvement): 1\n",
            "2019-07-22 04:06:53,790 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 04:06:53,829 epoch 6 - iter 0/1065 - loss 0.29777828\n",
            "2019-07-22 04:06:57,424 epoch 6 - iter 106/1065 - loss 0.31616796\n",
            "2019-07-22 04:07:00,928 epoch 6 - iter 212/1065 - loss 0.30954436\n",
            "2019-07-22 04:07:04,455 epoch 6 - iter 318/1065 - loss 0.31853026\n",
            "2019-07-22 04:07:07,981 epoch 6 - iter 424/1065 - loss 0.31777798\n",
            "2019-07-22 04:07:11,640 epoch 6 - iter 530/1065 - loss 0.32031835\n",
            "2019-07-22 04:07:15,106 epoch 6 - iter 636/1065 - loss 0.32171163\n",
            "2019-07-22 04:07:18,559 epoch 6 - iter 742/1065 - loss 0.32217125\n",
            "2019-07-22 04:07:22,018 epoch 6 - iter 848/1065 - loss 0.32130660\n",
            "2019-07-22 04:07:25,525 epoch 6 - iter 954/1065 - loss 0.32290519\n",
            "2019-07-22 04:07:29,125 epoch 6 - iter 1060/1065 - loss 0.32211131\n",
            "2019-07-22 04:07:29,278 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 04:07:29,279 EPOCH 6 done: loss 0.3221 - lr 0.1000\n",
            "2019-07-22 04:07:33,007 DEV : loss 0.31842419505119324 - score 0.3051\n",
            "2019-07-22 04:07:33,476 BAD EPOCHS (no improvement): 2\n",
            "2019-07-22 04:07:33,478 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 04:07:33,516 epoch 7 - iter 0/1065 - loss 0.23396115\n",
            "2019-07-22 04:07:37,151 epoch 7 - iter 106/1065 - loss 0.32623226\n",
            "2019-07-22 04:07:40,780 epoch 7 - iter 212/1065 - loss 0.32532029\n",
            "2019-07-22 04:07:44,448 epoch 7 - iter 318/1065 - loss 0.31917765\n",
            "2019-07-22 04:07:48,045 epoch 7 - iter 424/1065 - loss 0.31860317\n",
            "2019-07-22 04:07:51,474 epoch 7 - iter 530/1065 - loss 0.31785295\n",
            "2019-07-22 04:07:54,909 epoch 7 - iter 636/1065 - loss 0.32079883\n",
            "2019-07-22 04:07:58,421 epoch 7 - iter 742/1065 - loss 0.31885311\n",
            "2019-07-22 04:08:01,981 epoch 7 - iter 848/1065 - loss 0.32024579\n",
            "2019-07-22 04:08:05,526 epoch 7 - iter 954/1065 - loss 0.32087414\n",
            "2019-07-22 04:08:09,195 epoch 7 - iter 1060/1065 - loss 0.31946803\n",
            "2019-07-22 04:08:09,369 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 04:08:09,370 EPOCH 7 done: loss 0.3195 - lr 0.1000\n",
            "2019-07-22 04:08:13,133 DEV : loss 0.3209840953350067 - score 0.2009\n",
            "2019-07-22 04:08:13,650 BAD EPOCHS (no improvement): 3\n",
            "2019-07-22 04:08:13,651 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 04:08:13,688 epoch 8 - iter 0/1065 - loss 0.08575824\n",
            "2019-07-22 04:08:17,344 epoch 8 - iter 106/1065 - loss 0.32727436\n",
            "2019-07-22 04:08:20,930 epoch 8 - iter 212/1065 - loss 0.31455543\n",
            "2019-07-22 04:08:24,453 epoch 8 - iter 318/1065 - loss 0.31370052\n",
            "2019-07-22 04:08:28,033 epoch 8 - iter 424/1065 - loss 0.31409459\n",
            "2019-07-22 04:08:31,609 epoch 8 - iter 530/1065 - loss 0.31674290\n",
            "2019-07-22 04:08:35,156 epoch 8 - iter 636/1065 - loss 0.31534873\n",
            "2019-07-22 04:08:38,682 epoch 8 - iter 742/1065 - loss 0.31474659\n",
            "2019-07-22 04:08:42,291 epoch 8 - iter 848/1065 - loss 0.31443979\n",
            "2019-07-22 04:08:45,847 epoch 8 - iter 954/1065 - loss 0.31605055\n",
            "2019-07-22 04:08:49,535 epoch 8 - iter 1060/1065 - loss 0.31534385\n",
            "2019-07-22 04:08:49,690 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 04:08:49,692 EPOCH 8 done: loss 0.3155 - lr 0.1000\n",
            "2019-07-22 04:08:53,484 DEV : loss 0.31844088435173035 - score 0.1502\n",
            "Epoch     7: reducing learning rate of group 0 to 5.0000e-02.\n",
            "2019-07-22 04:08:53,995 BAD EPOCHS (no improvement): 4\n",
            "2019-07-22 04:08:53,997 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 04:08:54,038 epoch 9 - iter 0/1065 - loss 0.41295421\n",
            "2019-07-22 04:08:57,633 epoch 9 - iter 106/1065 - loss 0.30033069\n",
            "2019-07-22 04:09:01,247 epoch 9 - iter 212/1065 - loss 0.30407640\n",
            "2019-07-22 04:09:04,798 epoch 9 - iter 318/1065 - loss 0.31099269\n",
            "2019-07-22 04:09:08,287 epoch 9 - iter 424/1065 - loss 0.30671896\n",
            "2019-07-22 04:09:11,841 epoch 9 - iter 530/1065 - loss 0.30556380\n",
            "2019-07-22 04:09:15,316 epoch 9 - iter 636/1065 - loss 0.30644969\n",
            "2019-07-22 04:09:18,821 epoch 9 - iter 742/1065 - loss 0.30621005\n",
            "2019-07-22 04:09:22,346 epoch 9 - iter 848/1065 - loss 0.30313624\n",
            "2019-07-22 04:09:25,916 epoch 9 - iter 954/1065 - loss 0.30370158\n",
            "2019-07-22 04:09:29,603 epoch 9 - iter 1060/1065 - loss 0.30425255\n",
            "2019-07-22 04:09:29,751 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 04:09:29,752 EPOCH 9 done: loss 0.3038 - lr 0.0500\n",
            "2019-07-22 04:09:33,561 DEV : loss 0.32166430354118347 - score 0.195\n",
            "2019-07-22 04:09:34,073 BAD EPOCHS (no improvement): 1\n",
            "2019-07-22 04:09:34,075 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 04:09:34,120 epoch 10 - iter 0/1065 - loss 0.37681454\n",
            "2019-07-22 04:09:37,768 epoch 10 - iter 106/1065 - loss 0.29064316\n",
            "2019-07-22 04:09:41,443 epoch 10 - iter 212/1065 - loss 0.29390306\n",
            "2019-07-22 04:09:44,971 epoch 10 - iter 318/1065 - loss 0.29577083\n",
            "2019-07-22 04:09:48,572 epoch 10 - iter 424/1065 - loss 0.29963113\n",
            "2019-07-22 04:09:52,083 epoch 10 - iter 530/1065 - loss 0.30291720\n",
            "2019-07-22 04:09:55,671 epoch 10 - iter 636/1065 - loss 0.30074662\n",
            "2019-07-22 04:09:59,266 epoch 10 - iter 742/1065 - loss 0.30041449\n",
            "2019-07-22 04:10:02,797 epoch 10 - iter 848/1065 - loss 0.30100073\n",
            "2019-07-22 04:10:06,344 epoch 10 - iter 954/1065 - loss 0.30327278\n",
            "2019-07-22 04:10:09,898 epoch 10 - iter 1060/1065 - loss 0.30173496\n",
            "2019-07-22 04:10:10,046 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 04:10:10,047 EPOCH 10 done: loss 0.3021 - lr 0.0500\n",
            "2019-07-22 04:10:13,654 DEV : loss 0.3139718472957611 - score 0.4215\n",
            "2019-07-22 04:10:14,090 BAD EPOCHS (no improvement): 0\n",
            "2019-07-22 04:10:20,893 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 04:10:20,894 Testing using best model ...\n",
            "2019-07-22 04:10:20,895 loading file flair_rnn/best-model.pt\n",
            "2019-07-22 04:10:42,912 0.5032\t0.3179\t0.3896\n",
            "2019-07-22 04:10:42,914 \n",
            "MICRO_AVG: acc 0.7713 - f1-score 0.8709\n",
            "MACRO_AVG: acc 0.5537 - f1-score 0.6587\n",
            "0          tp: 4711 - fp: 502 - fn: 231 - tn: 234 - precision: 0.9037 - recall: 0.9533 - accuracy: 0.8654 - f1-score: 0.9278\n",
            "1          tp: 234 - fp: 231 - fn: 502 - tn: 4711 - precision: 0.5032 - recall: 0.3179 - accuracy: 0.2420 - f1-score: 0.3896\n",
            "2019-07-22 04:10:42,914 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dev_loss_history': [tensor(0.3532, device='cuda:0'),\n",
              "  tensor(0.3445, device='cuda:0'),\n",
              "  tensor(0.3571, device='cuda:0'),\n",
              "  tensor(0.3286, device='cuda:0'),\n",
              "  tensor(0.3484, device='cuda:0'),\n",
              "  tensor(0.3184, device='cuda:0'),\n",
              "  tensor(0.3210, device='cuda:0'),\n",
              "  tensor(0.3184, device='cuda:0'),\n",
              "  tensor(0.3217, device='cuda:0'),\n",
              "  tensor(0.3140, device='cuda:0')],\n",
              " 'dev_score_history': [0.1001,\n",
              "  0.0858,\n",
              "  0.0587,\n",
              "  0.3167,\n",
              "  0.0202,\n",
              "  0.3051,\n",
              "  0.2009,\n",
              "  0.1502,\n",
              "  0.195,\n",
              "  0.4215],\n",
              " 'test_score': 0.3896,\n",
              " 'train_loss_history': [0.36786057157135904,\n",
              "  0.34752518860666964,\n",
              "  0.33568752971893184,\n",
              "  0.3308070373787007,\n",
              "  0.3266023180084609,\n",
              "  0.3220671186984425,\n",
              "  0.3195135344781786,\n",
              "  0.31547420419787575,\n",
              "  0.3038143427718973,\n",
              "  0.3021200100790727]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gh_FtqT24k_f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "45582706-c86f-4052-d07a-2126eba0b416"
      },
      "source": [
        "from flair.embeddings import BertEmbeddings, ELMoEmbeddings\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentPoolEmbeddings\n",
        "from flair.data_fetcher import NLPTaskDataFetcher\n",
        "from flair.models import TextClassifier\n",
        "from flair.trainers import ModelTrainer\n",
        "from pathlib import Path\n",
        "\n",
        "corpus = NLPTaskDataFetcher.load_classification_corpus(Path('./'),\n",
        "                                                       test_file='flair_test.csv',\n",
        "                                                       dev_file='flair_dev.csv',\n",
        "                                                       train_file='flair_train.csv')\n",
        "word_embeddings = [#BertEmbeddings(),\n",
        "                   WordEmbeddings(\"news\")] # bert and fasttext\n",
        "document_embeddings = DocumentPoolEmbeddings(word_embeddings)\n",
        "\n",
        "print(\"Create Classifier *************************\")\n",
        "classifier = TextClassifier(document_embeddings,\n",
        "                            label_dictionary=corpus.make_label_dictionary(), multi_label=False)\n",
        "print(\"Create Trainer *******************************\")\n",
        "trainer = ModelTrainer(classifier, corpus)\n",
        "print(\"Begin Training *******************************\")\n",
        "trainer.train(max_epochs=10, base_path = \"fasttext_pooled\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-07-22 23:43:02,549 Reading data from .\n",
            "2019-07-22 23:43:02,550 Train: flair_train.csv\n",
            "2019-07-22 23:43:02,551 Dev: flair_dev.csv\n",
            "2019-07-22 23:43:02,552 Test: flair_test.csv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated function (or staticmethod) load_classification_corpus. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/flair/data_fetcher.py:447: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
            "  max_tokens_per_doc=max_tokens_per_doc,\n",
            "/usr/local/lib/python3.6/dist-packages/flair/data_fetcher.py:454: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
            "  max_tokens_per_doc=max_tokens_per_doc,\n",
            "/usr/local/lib/python3.6/dist-packages/flair/data_fetcher.py:463: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
            "  max_tokens_per_doc=max_tokens_per_doc,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-07-22 23:43:19,538 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings-v0.3/en-fasttext-news-300d-1M.vectors.npy not found in cache, downloading to /tmp/tmp0yy6pgle\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1200000128/1200000128 [00:55<00:00, 21556953.77B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-07-22 23:44:15,765 copying /tmp/tmp0yy6pgle to cache at /root/.flair/embeddings/en-fasttext-news-300d-1M.vectors.npy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-07-22 23:44:19,131 removing temp file /tmp/tmp0yy6pgle\n",
            "2019-07-22 23:44:19,735 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings-v0.3/en-fasttext-news-300d-1M not found in cache, downloading to /tmp/tmpm3sj67a1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 54600983/54600983 [00:10<00:00, 5084712.60B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-07-22 23:44:31,020 copying /tmp/tmpm3sj67a1 to cache at /root/.flair/embeddings/en-fasttext-news-300d-1M\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-07-22 23:44:31,091 removing temp file /tmp/tmpm3sj67a1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Create Classifier *************************\n",
            "2019-07-22 23:44:43,637 Computing label dictionary. Progress:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 34066/34066 [00:00<00:00, 273660.67it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-07-22 23:44:43,777 [b'0', b'1']\n",
            "Create Trainer *******************************\n",
            "Begin Training *******************************\n",
            "2019-07-22 23:44:43,781 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 23:44:43,782 Model: \"TextClassifier(\n",
            "  (document_embeddings): DocumentPoolEmbeddings(\n",
            "    fine_tune_mode=linear, pooling=mean\n",
            "    (embeddings): StackedEmbeddings(\n",
            "      (list_embedding_0): WordEmbeddings('news')\n",
            "    )\n",
            "    (embedding_flex): Linear(in_features=300, out_features=300, bias=False)\n",
            "  )\n",
            "  (decoder): Linear(in_features=300, out_features=2, bias=True)\n",
            "  (loss_function): CrossEntropyLoss()\n",
            ")\"\n",
            "2019-07-22 23:44:43,783 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 23:44:43,784 Corpus: \"Corpus: 34066 train + 5678 dev + 5678 test sentences\"\n",
            "2019-07-22 23:44:43,785 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 23:44:43,786 Parameters:\n",
            "2019-07-22 23:44:43,786  - learning_rate: \"0.1\"\n",
            "2019-07-22 23:44:43,787  - mini_batch_size: \"32\"\n",
            "2019-07-22 23:44:43,788  - patience: \"3\"\n",
            "2019-07-22 23:44:43,788  - anneal_factor: \"0.5\"\n",
            "2019-07-22 23:44:43,789  - max_epochs: \"10\"\n",
            "2019-07-22 23:44:43,790  - shuffle: \"True\"\n",
            "2019-07-22 23:44:43,791  - train_with_dev: \"False\"\n",
            "2019-07-22 23:44:43,792 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 23:44:43,793 Model training base path: \"fasttext_pooled\"\n",
            "2019-07-22 23:44:43,794 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 23:44:43,795 Device: cuda:0\n",
            "2019-07-22 23:44:43,796 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 23:44:43,798 Embedding storage mode: cpu\n",
            "2019-07-22 23:44:43,800 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-07-22 23:44:43,957 epoch 1 - iter 0/1065 - loss 0.69401217\n",
            "2019-07-22 23:44:49,305 epoch 1 - iter 106/1065 - loss 0.39745150\n",
            "2019-07-22 23:44:54,584 epoch 1 - iter 212/1065 - loss 0.39613033\n",
            "2019-07-22 23:44:59,789 epoch 1 - iter 318/1065 - loss 0.38813759\n",
            "2019-07-22 23:45:04,995 epoch 1 - iter 424/1065 - loss 0.38154050\n",
            "2019-07-22 23:45:11,743 epoch 1 - iter 530/1065 - loss 0.37667488\n",
            "2019-07-22 23:45:17,060 epoch 1 - iter 636/1065 - loss 0.37362134\n",
            "2019-07-22 23:45:22,274 epoch 1 - iter 742/1065 - loss 0.37297126\n",
            "2019-07-22 23:45:27,909 epoch 1 - iter 848/1065 - loss 0.36948554\n",
            "2019-07-22 23:45:33,196 epoch 1 - iter 954/1065 - loss 0.36840121\n",
            "2019-07-22 23:45:38,486 epoch 1 - iter 1060/1065 - loss 0.36774734\n",
            "2019-07-22 23:45:38,665 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 23:45:38,667 EPOCH 1 done: loss 0.3673 - lr 0.1000\n",
            "2019-07-22 23:45:47,216 DEV : loss 0.35957905650138855 - score 0.0101\n",
            "2019-07-22 23:45:49,919 BAD EPOCHS (no improvement): 0\n",
            "2019-07-22 23:46:04,169 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 23:46:04,196 epoch 2 - iter 0/1065 - loss 0.34704548\n",
            "2019-07-22 23:46:07,079 epoch 2 - iter 106/1065 - loss 0.34655996\n",
            "2019-07-22 23:46:09,222 epoch 2 - iter 212/1065 - loss 0.34859594\n",
            "2019-07-22 23:46:11,293 epoch 2 - iter 318/1065 - loss 0.34352397\n",
            "2019-07-22 23:46:13,449 epoch 2 - iter 424/1065 - loss 0.34284883\n",
            "2019-07-22 23:46:15,678 epoch 2 - iter 530/1065 - loss 0.34369203\n",
            "2019-07-22 23:46:18,000 epoch 2 - iter 636/1065 - loss 0.34144319\n",
            "2019-07-22 23:46:20,293 epoch 2 - iter 742/1065 - loss 0.34143377\n",
            "2019-07-22 23:46:22,514 epoch 2 - iter 848/1065 - loss 0.33972695\n",
            "2019-07-22 23:46:24,742 epoch 2 - iter 954/1065 - loss 0.33774148\n",
            "2019-07-22 23:46:26,875 epoch 2 - iter 1060/1065 - loss 0.33714413\n",
            "2019-07-22 23:46:26,948 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 23:46:26,949 EPOCH 2 done: loss 0.3368 - lr 0.1000\n",
            "2019-07-22 23:46:29,756 DEV : loss 0.350004643201828 - score 0.0151\n",
            "2019-07-22 23:46:29,995 BAD EPOCHS (no improvement): 0\n",
            "2019-07-22 23:46:43,914 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 23:46:43,941 epoch 3 - iter 0/1065 - loss 0.17419717\n",
            "2019-07-22 23:46:46,088 epoch 3 - iter 106/1065 - loss 0.32025411\n",
            "2019-07-22 23:46:48,242 epoch 3 - iter 212/1065 - loss 0.32386021\n",
            "2019-07-22 23:46:50,326 epoch 3 - iter 318/1065 - loss 0.32665852\n",
            "2019-07-22 23:46:52,439 epoch 3 - iter 424/1065 - loss 0.32633386\n",
            "2019-07-22 23:46:54,545 epoch 3 - iter 530/1065 - loss 0.32415458\n",
            "2019-07-22 23:46:56,698 epoch 3 - iter 636/1065 - loss 0.32300663\n",
            "2019-07-22 23:46:58,873 epoch 3 - iter 742/1065 - loss 0.32444810\n",
            "2019-07-22 23:47:01,018 epoch 3 - iter 848/1065 - loss 0.32509770\n",
            "2019-07-22 23:47:03,199 epoch 3 - iter 954/1065 - loss 0.32440632\n",
            "2019-07-22 23:47:05,428 epoch 3 - iter 1060/1065 - loss 0.32238685\n",
            "2019-07-22 23:47:05,514 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 23:47:05,515 EPOCH 3 done: loss 0.3223 - lr 0.1000\n",
            "2019-07-22 23:47:08,284 DEV : loss 0.3224788308143616 - score 0.1746\n",
            "2019-07-22 23:47:08,546 BAD EPOCHS (no improvement): 0\n",
            "2019-07-22 23:47:21,864 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 23:47:21,894 epoch 4 - iter 0/1065 - loss 0.35565060\n",
            "2019-07-22 23:47:24,128 epoch 4 - iter 106/1065 - loss 0.30914591\n",
            "2019-07-22 23:47:26,332 epoch 4 - iter 212/1065 - loss 0.30762350\n",
            "2019-07-22 23:47:28,541 epoch 4 - iter 318/1065 - loss 0.31513113\n",
            "2019-07-22 23:47:30,668 epoch 4 - iter 424/1065 - loss 0.31516736\n",
            "2019-07-22 23:47:32,798 epoch 4 - iter 530/1065 - loss 0.31464684\n",
            "2019-07-22 23:47:34,965 epoch 4 - iter 636/1065 - loss 0.31607395\n",
            "2019-07-22 23:47:37,182 epoch 4 - iter 742/1065 - loss 0.31473744\n",
            "2019-07-22 23:47:39,335 epoch 4 - iter 848/1065 - loss 0.31564666\n",
            "2019-07-22 23:47:41,505 epoch 4 - iter 954/1065 - loss 0.31547435\n",
            "2019-07-22 23:47:43,657 epoch 4 - iter 1060/1065 - loss 0.31664227\n",
            "2019-07-22 23:47:43,727 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 23:47:43,728 EPOCH 4 done: loss 0.3166 - lr 0.1000\n",
            "2019-07-22 23:47:46,502 DEV : loss 0.3197724521160126 - score 0.175\n",
            "2019-07-22 23:47:46,748 BAD EPOCHS (no improvement): 0\n",
            "2019-07-22 23:47:59,729 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 23:47:59,760 epoch 5 - iter 0/1065 - loss 0.27244526\n",
            "2019-07-22 23:48:01,930 epoch 5 - iter 106/1065 - loss 0.31766631\n",
            "2019-07-22 23:48:04,035 epoch 5 - iter 212/1065 - loss 0.30835033\n",
            "2019-07-22 23:48:06,176 epoch 5 - iter 318/1065 - loss 0.30626811\n",
            "2019-07-22 23:48:08,283 epoch 5 - iter 424/1065 - loss 0.31567608\n",
            "2019-07-22 23:48:10,420 epoch 5 - iter 530/1065 - loss 0.31449838\n",
            "2019-07-22 23:48:12,538 epoch 5 - iter 636/1065 - loss 0.31262714\n",
            "2019-07-22 23:48:14,733 epoch 5 - iter 742/1065 - loss 0.31319585\n",
            "2019-07-22 23:48:16,921 epoch 5 - iter 848/1065 - loss 0.31136795\n",
            "2019-07-22 23:48:19,071 epoch 5 - iter 954/1065 - loss 0.31288475\n",
            "2019-07-22 23:48:21,207 epoch 5 - iter 1060/1065 - loss 0.31294949\n",
            "2019-07-22 23:48:21,281 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 23:48:21,282 EPOCH 5 done: loss 0.3130 - lr 0.1000\n",
            "2019-07-22 23:48:23,992 DEV : loss 0.31536415219306946 - score 0.2253\n",
            "2019-07-22 23:48:24,251 BAD EPOCHS (no improvement): 0\n",
            "2019-07-22 23:48:37,403 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 23:48:37,430 epoch 6 - iter 0/1065 - loss 0.27181810\n",
            "2019-07-22 23:48:39,597 epoch 6 - iter 106/1065 - loss 0.32204584\n",
            "2019-07-22 23:48:41,692 epoch 6 - iter 212/1065 - loss 0.32583833\n",
            "2019-07-22 23:48:43,912 epoch 6 - iter 318/1065 - loss 0.31883948\n",
            "2019-07-22 23:48:45,965 epoch 6 - iter 424/1065 - loss 0.31688579\n",
            "2019-07-22 23:48:48,087 epoch 6 - iter 530/1065 - loss 0.31519163\n",
            "2019-07-22 23:48:50,149 epoch 6 - iter 636/1065 - loss 0.31241791\n",
            "2019-07-22 23:48:52,299 epoch 6 - iter 742/1065 - loss 0.31373493\n",
            "2019-07-22 23:48:54,483 epoch 6 - iter 848/1065 - loss 0.31279514\n",
            "2019-07-22 23:48:56,688 epoch 6 - iter 954/1065 - loss 0.31260241\n",
            "2019-07-22 23:48:58,842 epoch 6 - iter 1060/1065 - loss 0.31054493\n",
            "2019-07-22 23:48:58,928 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 23:48:58,930 EPOCH 6 done: loss 0.3102 - lr 0.1000\n",
            "2019-07-22 23:49:01,636 DEV : loss 0.3259889483451843 - score 0.1332\n",
            "2019-07-22 23:49:01,869 BAD EPOCHS (no improvement): 1\n",
            "2019-07-22 23:49:01,871 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 23:49:01,902 epoch 7 - iter 0/1065 - loss 0.19690756\n",
            "2019-07-22 23:49:04,038 epoch 7 - iter 106/1065 - loss 0.31787315\n",
            "2019-07-22 23:49:06,224 epoch 7 - iter 212/1065 - loss 0.30776099\n",
            "2019-07-22 23:49:08,429 epoch 7 - iter 318/1065 - loss 0.30502370\n",
            "2019-07-22 23:49:10,564 epoch 7 - iter 424/1065 - loss 0.30577614\n",
            "2019-07-22 23:49:12,671 epoch 7 - iter 530/1065 - loss 0.30833577\n",
            "2019-07-22 23:49:14,776 epoch 7 - iter 636/1065 - loss 0.30999143\n",
            "2019-07-22 23:49:16,975 epoch 7 - iter 742/1065 - loss 0.31024234\n",
            "2019-07-22 23:49:19,162 epoch 7 - iter 848/1065 - loss 0.30773207\n",
            "2019-07-22 23:49:21,360 epoch 7 - iter 954/1065 - loss 0.30784668\n",
            "2019-07-22 23:49:23,551 epoch 7 - iter 1060/1065 - loss 0.30864332\n",
            "2019-07-22 23:49:23,631 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 23:49:23,632 EPOCH 7 done: loss 0.3084 - lr 0.1000\n",
            "2019-07-22 23:49:26,529 DEV : loss 0.32585781812667847 - score 0.1349\n",
            "2019-07-22 23:49:26,791 BAD EPOCHS (no improvement): 2\n",
            "2019-07-22 23:49:26,792 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 23:49:26,819 epoch 8 - iter 0/1065 - loss 0.27911419\n",
            "2019-07-22 23:49:28,991 epoch 8 - iter 106/1065 - loss 0.29889066\n",
            "2019-07-22 23:49:31,108 epoch 8 - iter 212/1065 - loss 0.30604222\n",
            "2019-07-22 23:49:33,399 epoch 8 - iter 318/1065 - loss 0.30855588\n",
            "2019-07-22 23:49:35,656 epoch 8 - iter 424/1065 - loss 0.30988967\n",
            "2019-07-22 23:49:37,881 epoch 8 - iter 530/1065 - loss 0.30965358\n",
            "2019-07-22 23:49:40,116 epoch 8 - iter 636/1065 - loss 0.31054987\n",
            "2019-07-22 23:49:42,361 epoch 8 - iter 742/1065 - loss 0.30834645\n",
            "2019-07-22 23:49:44,560 epoch 8 - iter 848/1065 - loss 0.30719736\n",
            "2019-07-22 23:49:46,786 epoch 8 - iter 954/1065 - loss 0.30721675\n",
            "2019-07-22 23:49:49,050 epoch 8 - iter 1060/1065 - loss 0.30769179\n",
            "2019-07-22 23:49:49,138 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 23:49:49,139 EPOCH 8 done: loss 0.3080 - lr 0.1000\n",
            "2019-07-22 23:49:52,014 DEV : loss 0.31235218048095703 - score 0.3033\n",
            "2019-07-22 23:49:52,284 BAD EPOCHS (no improvement): 0\n",
            "2019-07-22 23:50:05,929 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 23:50:05,960 epoch 9 - iter 0/1065 - loss 0.19856194\n",
            "2019-07-22 23:50:08,137 epoch 9 - iter 106/1065 - loss 0.29615372\n",
            "2019-07-22 23:50:10,326 epoch 9 - iter 212/1065 - loss 0.30292978\n",
            "2019-07-22 23:50:12,532 epoch 9 - iter 318/1065 - loss 0.30926533\n",
            "2019-07-22 23:50:14,650 epoch 9 - iter 424/1065 - loss 0.30549317\n",
            "2019-07-22 23:50:16,810 epoch 9 - iter 530/1065 - loss 0.30639012\n",
            "2019-07-22 23:50:19,056 epoch 9 - iter 636/1065 - loss 0.30602493\n",
            "2019-07-22 23:50:21,245 epoch 9 - iter 742/1065 - loss 0.30694391\n",
            "2019-07-22 23:50:23,485 epoch 9 - iter 848/1065 - loss 0.30658355\n",
            "2019-07-22 23:50:25,762 epoch 9 - iter 954/1065 - loss 0.30606787\n",
            "2019-07-22 23:50:27,992 epoch 9 - iter 1060/1065 - loss 0.30691610\n",
            "2019-07-22 23:50:28,075 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 23:50:28,076 EPOCH 9 done: loss 0.3071 - lr 0.1000\n",
            "2019-07-22 23:50:30,795 DEV : loss 0.311906635761261 - score 0.2354\n",
            "2019-07-22 23:50:31,019 BAD EPOCHS (no improvement): 1\n",
            "2019-07-22 23:50:31,020 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 23:50:31,048 epoch 10 - iter 0/1065 - loss 0.38763377\n",
            "2019-07-22 23:50:33,149 epoch 10 - iter 106/1065 - loss 0.31278341\n",
            "2019-07-22 23:50:35,250 epoch 10 - iter 212/1065 - loss 0.31129861\n",
            "2019-07-22 23:50:37,313 epoch 10 - iter 318/1065 - loss 0.30986859\n",
            "2019-07-22 23:50:39,451 epoch 10 - iter 424/1065 - loss 0.30760684\n",
            "2019-07-22 23:50:41,520 epoch 10 - iter 530/1065 - loss 0.30688396\n",
            "2019-07-22 23:50:43,690 epoch 10 - iter 636/1065 - loss 0.30656288\n",
            "2019-07-22 23:50:45,802 epoch 10 - iter 742/1065 - loss 0.30716724\n",
            "2019-07-22 23:50:47,965 epoch 10 - iter 848/1065 - loss 0.30775676\n",
            "2019-07-22 23:50:50,108 epoch 10 - iter 954/1065 - loss 0.30607700\n",
            "2019-07-22 23:50:52,284 epoch 10 - iter 1060/1065 - loss 0.30602403\n",
            "2019-07-22 23:50:52,369 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 23:50:52,370 EPOCH 10 done: loss 0.3060 - lr 0.1000\n",
            "2019-07-22 23:50:55,181 DEV : loss 0.3213725984096527 - score 0.1648\n",
            "2019-07-22 23:50:55,447 BAD EPOCHS (no improvement): 2\n",
            "2019-07-22 23:51:08,679 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 23:51:08,680 Testing using best model ...\n",
            "2019-07-22 23:51:08,682 loading file fasttext_pooled/best-model.pt\n",
            "2019-07-22 23:51:21,321 0.5804\t0.2011\t0.2987\n",
            "2019-07-22 23:51:21,323 \n",
            "MICRO_AVG: acc 0.7819 - f1-score 0.8776\n",
            "MACRO_AVG: acc 0.525 - f1-score 0.6158\n",
            "0          tp: 4835 - fp: 588 - fn: 107 - tn: 148 - precision: 0.8916 - recall: 0.9783 - accuracy: 0.8743 - f1-score: 0.9329\n",
            "1          tp: 148 - fp: 107 - fn: 588 - tn: 4835 - precision: 0.5804 - recall: 0.2011 - accuracy: 0.1756 - f1-score: 0.2987\n",
            "2019-07-22 23:51:21,324 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dev_loss_history': [tensor(0.3596, device='cuda:0'),\n",
              "  tensor(0.3500, device='cuda:0'),\n",
              "  tensor(0.3225, device='cuda:0'),\n",
              "  tensor(0.3198, device='cuda:0'),\n",
              "  tensor(0.3154, device='cuda:0'),\n",
              "  tensor(0.3260, device='cuda:0'),\n",
              "  tensor(0.3259, device='cuda:0'),\n",
              "  tensor(0.3124, device='cuda:0'),\n",
              "  tensor(0.3119, device='cuda:0'),\n",
              "  tensor(0.3214, device='cuda:0')],\n",
              " 'dev_score_history': [0.0101,\n",
              "  0.0151,\n",
              "  0.1746,\n",
              "  0.175,\n",
              "  0.2253,\n",
              "  0.1332,\n",
              "  0.1349,\n",
              "  0.3033,\n",
              "  0.2354,\n",
              "  0.1648],\n",
              " 'test_score': 0.2987,\n",
              " 'train_loss_history': [0.36731406753191925,\n",
              "  0.3367832300948425,\n",
              "  0.3223428954191051,\n",
              "  0.3166024279286604,\n",
              "  0.3130212271087606,\n",
              "  0.3102030845874912,\n",
              "  0.30843144180209425,\n",
              "  0.3080318818000001,\n",
              "  0.30708569089221843,\n",
              "  0.3059988208849665]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5K1g5iHG82o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "aa177f0b-9aae-4ef6-ed74-b070c51e482a"
      },
      "source": [
        "corpus = NLPTaskDataFetcher.load_classification_corpus(Path('./'),\n",
        "                                                       test_file='flair_test.csv',\n",
        "                                                       dev_file='flair_dev.csv',\n",
        "                                                       train_file='flair_train.csv')\n",
        "word_embeddings = [#BertEmbeddings(),\n",
        "                   WordEmbeddings(\"glove\")] # bert and fasttext\n",
        "document_embeddings = DocumentPoolEmbeddings(word_embeddings)\n",
        "\n",
        "print(\"Create Classifier *************************\")\n",
        "classifier = TextClassifier(document_embeddings,\n",
        "                            label_dictionary=corpus.make_label_dictionary(), multi_label=False)\n",
        "print(\"Create Trainer *******************************\")\n",
        "trainer = ModelTrainer(classifier, corpus)\n",
        "print(\"Begin Training *******************************\")\n",
        "trainer.train(max_epochs=10, base_path = \"glove_pooled\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-07-22 23:54:58,872 Reading data from .\n",
            "2019-07-22 23:54:58,874 Train: flair_train.csv\n",
            "2019-07-22 23:54:58,875 Dev: flair_dev.csv\n",
            "2019-07-22 23:54:58,876 Test: flair_test.csv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated function (or staticmethod) load_classification_corpus. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/flair/data_fetcher.py:447: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
            "  max_tokens_per_doc=max_tokens_per_doc,\n",
            "/usr/local/lib/python3.6/dist-packages/flair/data_fetcher.py:454: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
            "  max_tokens_per_doc=max_tokens_per_doc,\n",
            "/usr/local/lib/python3.6/dist-packages/flair/data_fetcher.py:463: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
            "  max_tokens_per_doc=max_tokens_per_doc,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-07-22 23:55:14,736 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/glove.gensim.vectors.npy not found in cache, downloading to /tmp/tmplmiuwpxh\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 160000128/160000128 [00:08<00:00, 18407355.87B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-07-22 23:55:23,947 copying /tmp/tmplmiuwpxh to cache at /root/.flair/embeddings/glove.gensim.vectors.npy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-07-22 23:55:24,209 removing temp file /tmp/tmplmiuwpxh\n",
            "2019-07-22 23:55:25,307 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/glove.gensim not found in cache, downloading to /tmp/tmp2pscfuag\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 21494764/21494764 [00:01<00:00, 12583532.55B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-07-22 23:55:27,539 copying /tmp/tmp2pscfuag to cache at /root/.flair/embeddings/glove.gensim\n",
            "2019-07-22 23:55:27,567 removing temp file /tmp/tmp2pscfuag\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Create Classifier *************************\n",
            "2019-07-22 23:55:28,475 Computing label dictionary. Progress:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 34066/34066 [00:00<00:00, 250128.51it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-07-22 23:55:28,615 [b'0', b'1']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Create Trainer *******************************\n",
            "Begin Training *******************************\n",
            "2019-07-22 23:55:28,979 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 23:55:28,981 Model: \"TextClassifier(\n",
            "  (document_embeddings): DocumentPoolEmbeddings(\n",
            "    fine_tune_mode=linear, pooling=mean\n",
            "    (embeddings): StackedEmbeddings(\n",
            "      (list_embedding_0): WordEmbeddings('glove')\n",
            "    )\n",
            "    (embedding_flex): Linear(in_features=100, out_features=100, bias=False)\n",
            "  )\n",
            "  (decoder): Linear(in_features=100, out_features=2, bias=True)\n",
            "  (loss_function): CrossEntropyLoss()\n",
            ")\"\n",
            "2019-07-22 23:55:28,982 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 23:55:28,983 Corpus: \"Corpus: 34066 train + 5678 dev + 5678 test sentences\"\n",
            "2019-07-22 23:55:28,985 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 23:55:28,986 Parameters:\n",
            "2019-07-22 23:55:28,987  - learning_rate: \"0.1\"\n",
            "2019-07-22 23:55:28,988  - mini_batch_size: \"32\"\n",
            "2019-07-22 23:55:28,989  - patience: \"3\"\n",
            "2019-07-22 23:55:28,990  - anneal_factor: \"0.5\"\n",
            "2019-07-22 23:55:28,991  - max_epochs: \"10\"\n",
            "2019-07-22 23:55:28,992  - shuffle: \"True\"\n",
            "2019-07-22 23:55:28,993  - train_with_dev: \"False\"\n",
            "2019-07-22 23:55:28,994 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 23:55:28,996 Model training base path: \"glove_pooled\"\n",
            "2019-07-22 23:55:28,997 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 23:55:28,998 Device: cuda:0\n",
            "2019-07-22 23:55:28,999 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 23:55:29,000 Embedding storage mode: cpu\n",
            "2019-07-22 23:55:29,002 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 23:55:29,082 epoch 1 - iter 0/1065 - loss 0.47407722\n",
            "2019-07-22 23:55:34,413 epoch 1 - iter 106/1065 - loss 0.37933892\n",
            "2019-07-22 23:55:39,549 epoch 1 - iter 212/1065 - loss 0.37630068\n",
            "2019-07-22 23:55:44,642 epoch 1 - iter 318/1065 - loss 0.37417412\n",
            "2019-07-22 23:55:58,697 epoch 1 - iter 424/1065 - loss 0.37067737\n",
            "2019-07-22 23:56:03,803 epoch 1 - iter 530/1065 - loss 0.36854811\n",
            "2019-07-22 23:56:08,984 epoch 1 - iter 636/1065 - loss 0.36562941\n",
            "2019-07-22 23:56:14,336 epoch 1 - iter 742/1065 - loss 0.36612532\n",
            "2019-07-22 23:56:19,728 epoch 1 - iter 848/1065 - loss 0.36306159\n",
            "2019-07-22 23:56:26,794 epoch 1 - iter 954/1065 - loss 0.35847722\n",
            "2019-07-22 23:56:32,066 epoch 1 - iter 1060/1065 - loss 0.35614858\n",
            "2019-07-22 23:56:32,258 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 23:56:32,259 EPOCH 1 done: loss 0.3560 - lr 0.1000\n",
            "2019-07-22 23:56:38,167 DEV : loss 0.3487299978733063 - score 0.0584\n",
            "2019-07-22 23:56:40,755 BAD EPOCHS (no improvement): 0\n",
            "2019-07-22 23:56:44,375 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 23:56:44,397 epoch 2 - iter 0/1065 - loss 0.46448153\n",
            "2019-07-22 23:56:46,417 epoch 2 - iter 106/1065 - loss 0.33617453\n",
            "2019-07-22 23:56:48,314 epoch 2 - iter 212/1065 - loss 0.32354798\n",
            "2019-07-22 23:56:50,103 epoch 2 - iter 318/1065 - loss 0.32616865\n",
            "2019-07-22 23:56:52,095 epoch 2 - iter 424/1065 - loss 0.33120874\n",
            "2019-07-22 23:56:54,000 epoch 2 - iter 530/1065 - loss 0.33323381\n",
            "2019-07-22 23:56:56,001 epoch 2 - iter 636/1065 - loss 0.33582188\n",
            "2019-07-22 23:56:57,952 epoch 2 - iter 742/1065 - loss 0.33749195\n",
            "2019-07-22 23:56:59,924 epoch 2 - iter 848/1065 - loss 0.33961119\n",
            "2019-07-22 23:57:01,930 epoch 2 - iter 954/1065 - loss 0.33977168\n",
            "2019-07-22 23:57:03,817 epoch 2 - iter 1060/1065 - loss 0.34063439\n",
            "2019-07-22 23:57:03,885 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 23:57:03,887 EPOCH 2 done: loss 0.3408 - lr 0.1000\n",
            "2019-07-22 23:57:06,310 DEV : loss 0.3407863974571228 - score 0.1454\n",
            "2019-07-22 23:57:06,579 BAD EPOCHS (no improvement): 0\n",
            "2019-07-22 23:57:10,130 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 23:57:10,159 epoch 3 - iter 0/1065 - loss 0.22999910\n",
            "2019-07-22 23:57:12,159 epoch 3 - iter 106/1065 - loss 0.33442709\n",
            "2019-07-22 23:57:14,235 epoch 3 - iter 212/1065 - loss 0.33513266\n",
            "2019-07-22 23:57:16,297 epoch 3 - iter 318/1065 - loss 0.34073129\n",
            "2019-07-22 23:57:18,250 epoch 3 - iter 424/1065 - loss 0.34098836\n",
            "2019-07-22 23:57:20,276 epoch 3 - iter 530/1065 - loss 0.34242628\n",
            "2019-07-22 23:57:22,324 epoch 3 - iter 636/1065 - loss 0.34058629\n",
            "2019-07-22 23:57:24,423 epoch 3 - iter 742/1065 - loss 0.33841437\n",
            "2019-07-22 23:57:26,396 epoch 3 - iter 848/1065 - loss 0.33784283\n",
            "2019-07-22 23:57:28,259 epoch 3 - iter 954/1065 - loss 0.33684930\n",
            "2019-07-22 23:57:30,223 epoch 3 - iter 1060/1065 - loss 0.33680004\n",
            "2019-07-22 23:57:30,295 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 23:57:30,296 EPOCH 3 done: loss 0.3369 - lr 0.1000\n",
            "2019-07-22 23:57:32,782 DEV : loss 0.34672239422798157 - score 0.0696\n",
            "2019-07-22 23:57:33,019 BAD EPOCHS (no improvement): 1\n",
            "2019-07-22 23:57:33,020 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 23:57:33,044 epoch 4 - iter 0/1065 - loss 0.24688275\n",
            "2019-07-22 23:57:34,944 epoch 4 - iter 106/1065 - loss 0.34041306\n",
            "2019-07-22 23:57:36,899 epoch 4 - iter 212/1065 - loss 0.33003495\n",
            "2019-07-22 23:57:38,930 epoch 4 - iter 318/1065 - loss 0.33179412\n",
            "2019-07-22 23:57:41,033 epoch 4 - iter 424/1065 - loss 0.33160112\n",
            "2019-07-22 23:57:42,868 epoch 4 - iter 530/1065 - loss 0.33434046\n",
            "2019-07-22 23:57:44,919 epoch 4 - iter 636/1065 - loss 0.33604477\n",
            "2019-07-22 23:57:46,769 epoch 4 - iter 742/1065 - loss 0.33706626\n",
            "2019-07-22 23:57:48,786 epoch 4 - iter 848/1065 - loss 0.33532774\n",
            "2019-07-22 23:57:50,850 epoch 4 - iter 954/1065 - loss 0.33463459\n",
            "2019-07-22 23:57:52,792 epoch 4 - iter 1060/1065 - loss 0.33429426\n",
            "2019-07-22 23:57:52,863 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 23:57:52,865 EPOCH 4 done: loss 0.3345 - lr 0.1000\n",
            "2019-07-22 23:57:55,212 DEV : loss 0.33764439821243286 - score 0.1314\n",
            "2019-07-22 23:57:55,441 BAD EPOCHS (no improvement): 2\n",
            "2019-07-22 23:57:55,443 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 23:57:55,466 epoch 5 - iter 0/1065 - loss 0.33961880\n",
            "2019-07-22 23:57:57,336 epoch 5 - iter 106/1065 - loss 0.34684362\n",
            "2019-07-22 23:57:59,285 epoch 5 - iter 212/1065 - loss 0.33993697\n",
            "2019-07-22 23:58:01,171 epoch 5 - iter 318/1065 - loss 0.33809665\n",
            "2019-07-22 23:58:03,067 epoch 5 - iter 424/1065 - loss 0.33734654\n",
            "2019-07-22 23:58:04,998 epoch 5 - iter 530/1065 - loss 0.33604110\n",
            "2019-07-22 23:58:06,942 epoch 5 - iter 636/1065 - loss 0.33483805\n",
            "2019-07-22 23:58:08,838 epoch 5 - iter 742/1065 - loss 0.33537669\n",
            "2019-07-22 23:58:10,893 epoch 5 - iter 848/1065 - loss 0.33685992\n",
            "2019-07-22 23:58:13,016 epoch 5 - iter 954/1065 - loss 0.33624319\n",
            "2019-07-22 23:58:15,010 epoch 5 - iter 1060/1065 - loss 0.33408987\n",
            "2019-07-22 23:58:15,085 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 23:58:15,086 EPOCH 5 done: loss 0.3337 - lr 0.1000\n",
            "2019-07-22 23:58:17,483 DEV : loss 0.3457311987876892 - score 0.0695\n",
            "2019-07-22 23:58:17,725 BAD EPOCHS (no improvement): 3\n",
            "2019-07-22 23:58:17,726 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 23:58:17,751 epoch 6 - iter 0/1065 - loss 0.39861330\n",
            "2019-07-22 23:58:19,679 epoch 6 - iter 106/1065 - loss 0.32075344\n",
            "2019-07-22 23:58:21,599 epoch 6 - iter 212/1065 - loss 0.31866460\n",
            "2019-07-22 23:58:23,499 epoch 6 - iter 318/1065 - loss 0.32517141\n",
            "2019-07-22 23:58:25,538 epoch 6 - iter 424/1065 - loss 0.32502424\n",
            "2019-07-22 23:58:27,528 epoch 6 - iter 530/1065 - loss 0.32900927\n",
            "2019-07-22 23:58:29,558 epoch 6 - iter 636/1065 - loss 0.32878903\n",
            "2019-07-22 23:58:31,617 epoch 6 - iter 742/1065 - loss 0.32830760\n",
            "2019-07-22 23:58:33,734 epoch 6 - iter 848/1065 - loss 0.33075084\n",
            "2019-07-22 23:58:35,829 epoch 6 - iter 954/1065 - loss 0.33163779\n",
            "2019-07-22 23:58:37,879 epoch 6 - iter 1060/1065 - loss 0.33311522\n",
            "2019-07-22 23:58:37,951 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 23:58:37,953 EPOCH 6 done: loss 0.3325 - lr 0.1000\n",
            "2019-07-22 23:58:40,448 DEV : loss 0.3596385717391968 - score 0.0442\n",
            "Epoch     5: reducing learning rate of group 0 to 5.0000e-02.\n",
            "2019-07-22 23:58:40,711 BAD EPOCHS (no improvement): 4\n",
            "2019-07-22 23:58:40,712 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 23:58:40,737 epoch 7 - iter 0/1065 - loss 0.52485675\n",
            "2019-07-22 23:58:42,773 epoch 7 - iter 106/1065 - loss 0.32945322\n",
            "2019-07-22 23:58:44,803 epoch 7 - iter 212/1065 - loss 0.32791824\n",
            "2019-07-22 23:58:46,837 epoch 7 - iter 318/1065 - loss 0.32563812\n",
            "2019-07-22 23:58:48,830 epoch 7 - iter 424/1065 - loss 0.33006220\n",
            "2019-07-22 23:58:50,840 epoch 7 - iter 530/1065 - loss 0.33086143\n",
            "2019-07-22 23:58:52,835 epoch 7 - iter 636/1065 - loss 0.33211919\n",
            "2019-07-22 23:58:54,827 epoch 7 - iter 742/1065 - loss 0.33192105\n",
            "2019-07-22 23:58:56,850 epoch 7 - iter 848/1065 - loss 0.33170117\n",
            "2019-07-22 23:58:58,907 epoch 7 - iter 954/1065 - loss 0.32978280\n",
            "2019-07-22 23:59:00,913 epoch 7 - iter 1060/1065 - loss 0.32884448\n",
            "2019-07-22 23:59:00,986 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 23:59:00,987 EPOCH 7 done: loss 0.3294 - lr 0.0500\n",
            "2019-07-22 23:59:03,428 DEV : loss 0.3452749252319336 - score 0.2562\n",
            "2019-07-22 23:59:03,702 BAD EPOCHS (no improvement): 0\n",
            "2019-07-22 23:59:07,050 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 23:59:07,072 epoch 8 - iter 0/1065 - loss 0.31553683\n",
            "2019-07-22 23:59:09,077 epoch 8 - iter 106/1065 - loss 0.33919927\n",
            "2019-07-22 23:59:11,153 epoch 8 - iter 212/1065 - loss 0.33084688\n",
            "2019-07-22 23:59:13,241 epoch 8 - iter 318/1065 - loss 0.33433597\n",
            "2019-07-22 23:59:15,294 epoch 8 - iter 424/1065 - loss 0.33496357\n",
            "2019-07-22 23:59:17,350 epoch 8 - iter 530/1065 - loss 0.33231873\n",
            "2019-07-22 23:59:19,325 epoch 8 - iter 636/1065 - loss 0.33321583\n",
            "2019-07-22 23:59:21,363 epoch 8 - iter 742/1065 - loss 0.33513163\n",
            "2019-07-22 23:59:23,428 epoch 8 - iter 848/1065 - loss 0.33333290\n",
            "2019-07-22 23:59:25,388 epoch 8 - iter 954/1065 - loss 0.33170121\n",
            "2019-07-22 23:59:27,359 epoch 8 - iter 1060/1065 - loss 0.32961703\n",
            "2019-07-22 23:59:27,436 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 23:59:27,438 EPOCH 8 done: loss 0.3295 - lr 0.0500\n",
            "2019-07-22 23:59:29,827 DEV : loss 0.34334132075309753 - score 0.0967\n",
            "2019-07-22 23:59:30,057 BAD EPOCHS (no improvement): 1\n",
            "2019-07-22 23:59:30,059 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 23:59:30,081 epoch 9 - iter 0/1065 - loss 0.16748482\n",
            "2019-07-22 23:59:32,080 epoch 9 - iter 106/1065 - loss 0.32938928\n",
            "2019-07-22 23:59:34,042 epoch 9 - iter 212/1065 - loss 0.32594452\n",
            "2019-07-22 23:59:36,043 epoch 9 - iter 318/1065 - loss 0.33235485\n",
            "2019-07-22 23:59:38,076 epoch 9 - iter 424/1065 - loss 0.33168436\n",
            "2019-07-22 23:59:40,195 epoch 9 - iter 530/1065 - loss 0.33209525\n",
            "2019-07-22 23:59:42,109 epoch 9 - iter 636/1065 - loss 0.33183659\n",
            "2019-07-22 23:59:44,224 epoch 9 - iter 742/1065 - loss 0.33030834\n",
            "2019-07-22 23:59:46,212 epoch 9 - iter 848/1065 - loss 0.33026285\n",
            "2019-07-22 23:59:48,295 epoch 9 - iter 954/1065 - loss 0.32979311\n",
            "2019-07-22 23:59:50,446 epoch 9 - iter 1060/1065 - loss 0.32909443\n",
            "2019-07-22 23:59:50,521 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 23:59:50,522 EPOCH 9 done: loss 0.3293 - lr 0.0500\n",
            "2019-07-22 23:59:52,953 DEV : loss 0.3374671936035156 - score 0.2216\n",
            "2019-07-22 23:59:53,189 BAD EPOCHS (no improvement): 2\n",
            "2019-07-22 23:59:53,190 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 23:59:53,213 epoch 10 - iter 0/1065 - loss 0.30786675\n",
            "2019-07-22 23:59:55,152 epoch 10 - iter 106/1065 - loss 0.31912883\n",
            "2019-07-22 23:59:57,029 epoch 10 - iter 212/1065 - loss 0.33088570\n",
            "2019-07-22 23:59:59,016 epoch 10 - iter 318/1065 - loss 0.33046736\n",
            "2019-07-23 00:00:00,936 epoch 10 - iter 424/1065 - loss 0.33017014\n",
            "2019-07-23 00:00:02,888 epoch 10 - iter 530/1065 - loss 0.33535287\n",
            "2019-07-23 00:00:04,852 epoch 10 - iter 636/1065 - loss 0.33376231\n",
            "2019-07-23 00:00:06,985 epoch 10 - iter 742/1065 - loss 0.33146507\n",
            "2019-07-23 00:00:08,962 epoch 10 - iter 848/1065 - loss 0.33125969\n",
            "2019-07-23 00:00:10,894 epoch 10 - iter 954/1065 - loss 0.33055819\n",
            "2019-07-23 00:00:12,927 epoch 10 - iter 1060/1065 - loss 0.32917423\n",
            "2019-07-23 00:00:13,000 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-23 00:00:13,002 EPOCH 10 done: loss 0.3290 - lr 0.0500\n",
            "2019-07-23 00:00:15,357 DEV : loss 0.3363032042980194 - score 0.1982\n",
            "2019-07-23 00:00:15,594 BAD EPOCHS (no improvement): 3\n",
            "2019-07-23 00:00:19,082 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-23 00:00:19,083 Testing using best model ...\n",
            "2019-07-23 00:00:19,084 loading file glove_pooled/best-model.pt\n",
            "2019-07-23 00:00:28,568 0.4384\t0.1644\t0.2391\n",
            "2019-07-23 00:00:28,569 \n",
            "MICRO_AVG: acc 0.7612 - f1-score 0.8644\n",
            "MACRO_AVG: acc 0.4986 - f1-score 0.58235\n",
            "0          tp: 4787 - fp: 615 - fn: 155 - tn: 121 - precision: 0.8862 - recall: 0.9686 - accuracy: 0.8614 - f1-score: 0.9256\n",
            "1          tp: 121 - fp: 155 - fn: 615 - tn: 4787 - precision: 0.4384 - recall: 0.1644 - accuracy: 0.1358 - f1-score: 0.2391\n",
            "2019-07-23 00:00:28,570 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dev_loss_history': [tensor(0.3487, device='cuda:0'),\n",
              "  tensor(0.3408, device='cuda:0'),\n",
              "  tensor(0.3467, device='cuda:0'),\n",
              "  tensor(0.3376, device='cuda:0'),\n",
              "  tensor(0.3457, device='cuda:0'),\n",
              "  tensor(0.3596, device='cuda:0'),\n",
              "  tensor(0.3453, device='cuda:0'),\n",
              "  tensor(0.3433, device='cuda:0'),\n",
              "  tensor(0.3375, device='cuda:0'),\n",
              "  tensor(0.3363, device='cuda:0')],\n",
              " 'dev_score_history': [0.0584,\n",
              "  0.1454,\n",
              "  0.0696,\n",
              "  0.1314,\n",
              "  0.0695,\n",
              "  0.0442,\n",
              "  0.2562,\n",
              "  0.0967,\n",
              "  0.2216,\n",
              "  0.1982],\n",
              " 'test_score': 0.2391,\n",
              " 'train_loss_history': [0.35602582874992084,\n",
              "  0.34077189323348056,\n",
              "  0.3368952038142603,\n",
              "  0.33451063412595805,\n",
              "  0.33370714184124145,\n",
              "  0.3325438851271996,\n",
              "  0.3293878852271698,\n",
              "  0.3294598066750826,\n",
              "  0.32925278885123876,\n",
              "  0.3289960900033024]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    }
  ]
}