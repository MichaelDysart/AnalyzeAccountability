{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "flair.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anjapago/AnalyzeAccountability/blob/master/flair.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtgjqStCtTF8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install git+https://github.com/anjapago/flair"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlV-lvcYyycf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_dictionary = corpus.make_label_dictionary()\n",
        "available_labels = label_dictionary.get_items()\n",
        "for label in available_labels:\n",
        "  print(type(label))\n",
        "  print(label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKBOr5FsNy19",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "81dec7bf-a08c-4c6d-ad62-11ed0494dc4f"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentPoolEmbeddings\n",
        "from flair.data_fetcher import NLPTaskDataFetcher\n",
        "from flair.models import TextClassifier\n",
        "from flair.trainers import ModelTrainer\n",
        "from pathlib import Path\n",
        "\n",
        "corpus = NLPTaskDataFetcher.load_classification_corpus(Path('./'),\n",
        "                                                       test_file='flair_test.csv',\n",
        "                                                       dev_file='flair_dev.csv',\n",
        "                                                       train_file='flair_train.csv')\n",
        "word_embeddings = [WordEmbeddings('glove'),\n",
        "                   FlairEmbeddings('news-forward-fast'),\n",
        "                   FlairEmbeddings('news-backward-fast')]\n",
        "document_embeddings = DocumentPoolEmbeddings(word_embeddings)\n",
        "\n",
        "print(\"Create Classifier *************************\")\n",
        "classifier = TextClassifier(document_embeddings,\n",
        "                            label_dictionary=corpus.make_label_dictionary(), multi_label=False)\n",
        "print(\"Create Trainer *******************************\")\n",
        "trainer = ModelTrainer(classifier, corpus)\n",
        "print(\"Begin Training *******************************\")\n",
        "trainer.train(max_epochs=10, base_path = \"flair_pooled\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-07-22 03:47:07,440 Reading data from .\n",
            "2019-07-22 03:47:07,442 Train: flair_train.csv\n",
            "2019-07-22 03:47:07,443 Dev: flair_dev.csv\n",
            "2019-07-22 03:47:07,444 Test: flair_test.csv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: Call to deprecated function (or staticmethod) load_classification_corpus. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/flair/data_fetcher.py:447: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
            "  max_tokens_per_doc=max_tokens_per_doc,\n",
            "/usr/local/lib/python3.6/dist-packages/flair/data_fetcher.py:454: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
            "  max_tokens_per_doc=max_tokens_per_doc,\n",
            "/usr/local/lib/python3.6/dist-packages/flair/data_fetcher.py:463: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
            "  max_tokens_per_doc=max_tokens_per_doc,\n",
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Create Classifier *************************\n",
            "2019-07-22 03:47:26,526 Computing label dictionary. Progress:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 34066/34066 [00:00<00:00, 249225.83it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-07-22 03:47:26,666 [b'0', b'1']\n",
            "Create Trainer *******************************\n",
            "Begin Training *******************************\n",
            "2019-07-22 03:47:26,727 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-07-22 03:47:26,729 Model: \"TextClassifier(\n",
            "  (document_embeddings): DocumentPoolEmbeddings(\n",
            "    fine_tune_mode=linear, pooling=mean\n",
            "    (embeddings): StackedEmbeddings(\n",
            "      (list_embedding_0): WordEmbeddings('glove')\n",
            "      (list_embedding_1): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.25)\n",
            "          (encoder): Embedding(275, 100)\n",
            "          (rnn): LSTM(100, 1024)\n",
            "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (list_embedding_2): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.25)\n",
            "          (encoder): Embedding(275, 100)\n",
            "          (rnn): LSTM(100, 1024)\n",
            "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (embedding_flex): Linear(in_features=2148, out_features=2148, bias=False)\n",
            "  )\n",
            "  (decoder): Linear(in_features=2148, out_features=2, bias=True)\n",
            "  (loss_function): CrossEntropyLoss()\n",
            ")\"\n",
            "2019-07-22 03:47:26,730 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 03:47:26,731 Corpus: \"Corpus: 34066 train + 5678 dev + 5678 test sentences\"\n",
            "2019-07-22 03:47:26,732 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 03:47:26,734 Parameters:\n",
            "2019-07-22 03:47:26,734  - learning_rate: \"0.1\"\n",
            "2019-07-22 03:47:26,735  - mini_batch_size: \"32\"\n",
            "2019-07-22 03:47:26,737  - patience: \"3\"\n",
            "2019-07-22 03:47:26,738  - anneal_factor: \"0.5\"\n",
            "2019-07-22 03:47:26,739  - max_epochs: \"10\"\n",
            "2019-07-22 03:47:26,740  - shuffle: \"True\"\n",
            "2019-07-22 03:47:26,741  - train_with_dev: \"False\"\n",
            "2019-07-22 03:47:26,742 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 03:47:26,743 Model training base path: \"flair_pooled\"\n",
            "2019-07-22 03:47:26,744 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 03:47:26,745 Device: cuda:0\n",
            "2019-07-22 03:47:26,747 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 03:47:26,748 Embedding storage mode: cpu\n",
            "2019-07-22 03:47:26,750 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 03:47:27,002 epoch 1 - iter 0/1065 - loss 0.68184566\n",
            "2019-07-22 03:47:44,084 epoch 1 - iter 106/1065 - loss 0.38421781\n",
            "2019-07-22 03:48:01,345 epoch 1 - iter 212/1065 - loss 0.38004329\n",
            "2019-07-22 03:48:18,681 epoch 1 - iter 318/1065 - loss 0.37059110\n",
            "2019-07-22 03:48:40,605 epoch 1 - iter 424/1065 - loss 0.36299340\n",
            "2019-07-22 03:48:58,240 epoch 1 - iter 530/1065 - loss 0.36130671\n",
            "2019-07-22 03:49:15,350 epoch 1 - iter 636/1065 - loss 0.35745760\n",
            "2019-07-22 03:49:35,200 epoch 1 - iter 742/1065 - loss 0.35480835\n",
            "2019-07-22 03:49:52,634 epoch 1 - iter 848/1065 - loss 0.35422706\n",
            "2019-07-22 03:50:09,576 epoch 1 - iter 954/1065 - loss 0.35197819\n",
            "2019-07-22 03:50:29,598 epoch 1 - iter 1060/1065 - loss 0.34931223\n",
            "2019-07-22 03:50:30,285 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 03:50:30,287 EPOCH 1 done: loss 0.3491 - lr 0.1000\n",
            "2019-07-22 03:50:50,033 DEV : loss 0.37265369296073914 - score 0.0176\n",
            "2019-07-22 03:50:58,064 BAD EPOCHS (no improvement): 0\n",
            "2019-07-22 03:51:02,400 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 03:51:02,470 epoch 2 - iter 0/1065 - loss 0.44348967\n",
            "2019-07-22 03:51:07,237 epoch 2 - iter 106/1065 - loss 0.32683076\n",
            "2019-07-22 03:51:12,008 epoch 2 - iter 212/1065 - loss 0.31553974\n",
            "2019-07-22 03:51:16,816 epoch 2 - iter 318/1065 - loss 0.31281633\n",
            "2019-07-22 03:51:21,639 epoch 2 - iter 424/1065 - loss 0.32315282\n",
            "2019-07-22 03:51:26,468 epoch 2 - iter 530/1065 - loss 0.32357276\n",
            "2019-07-22 03:51:31,398 epoch 2 - iter 636/1065 - loss 0.32344180\n",
            "2019-07-22 03:51:36,295 epoch 2 - iter 742/1065 - loss 0.32502988\n",
            "2019-07-22 03:51:41,216 epoch 2 - iter 848/1065 - loss 0.32669898\n",
            "2019-07-22 03:51:46,080 epoch 2 - iter 954/1065 - loss 0.32679016\n",
            "2019-07-22 03:51:51,041 epoch 2 - iter 1060/1065 - loss 0.32844628\n",
            "2019-07-22 03:51:51,212 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 03:51:51,214 EPOCH 2 done: loss 0.3286 - lr 0.1000\n",
            "2019-07-22 03:51:56,151 DEV : loss 0.39004209637641907 - score 0.4484\n",
            "2019-07-22 03:51:56,660 BAD EPOCHS (no improvement): 0\n",
            "2019-07-22 03:52:00,620 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 03:52:00,679 epoch 3 - iter 0/1065 - loss 0.47302920\n",
            "2019-07-22 03:52:05,213 epoch 3 - iter 106/1065 - loss 0.32606514\n",
            "2019-07-22 03:52:09,668 epoch 3 - iter 212/1065 - loss 0.32859944\n",
            "2019-07-22 03:52:14,184 epoch 3 - iter 318/1065 - loss 0.32607363\n",
            "2019-07-22 03:52:18,771 epoch 3 - iter 424/1065 - loss 0.32758413\n",
            "2019-07-22 03:52:23,307 epoch 3 - iter 530/1065 - loss 0.32604836\n",
            "2019-07-22 03:52:27,873 epoch 3 - iter 636/1065 - loss 0.32599391\n",
            "2019-07-22 03:52:32,400 epoch 3 - iter 742/1065 - loss 0.32655645\n",
            "2019-07-22 03:52:36,823 epoch 3 - iter 848/1065 - loss 0.32479959\n",
            "2019-07-22 03:52:41,393 epoch 3 - iter 954/1065 - loss 0.32504329\n",
            "2019-07-22 03:52:45,914 epoch 3 - iter 1060/1065 - loss 0.32367451\n",
            "2019-07-22 03:52:46,084 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 03:52:46,086 EPOCH 3 done: loss 0.3238 - lr 0.1000\n",
            "2019-07-22 03:52:50,802 DEV : loss 0.33652469515800476 - score 0.1038\n",
            "2019-07-22 03:52:51,277 BAD EPOCHS (no improvement): 1\n",
            "2019-07-22 03:52:51,278 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 03:52:51,326 epoch 4 - iter 0/1065 - loss 0.42045212\n",
            "2019-07-22 03:52:55,836 epoch 4 - iter 106/1065 - loss 0.32217883\n",
            "2019-07-22 03:53:00,251 epoch 4 - iter 212/1065 - loss 0.31505778\n",
            "2019-07-22 03:53:04,683 epoch 4 - iter 318/1065 - loss 0.32125966\n",
            "2019-07-22 03:53:09,115 epoch 4 - iter 424/1065 - loss 0.32327686\n",
            "2019-07-22 03:53:13,524 epoch 4 - iter 530/1065 - loss 0.32047176\n",
            "2019-07-22 03:53:17,894 epoch 4 - iter 636/1065 - loss 0.32139229\n",
            "2019-07-22 03:53:22,320 epoch 4 - iter 742/1065 - loss 0.32107320\n",
            "2019-07-22 03:53:26,672 epoch 4 - iter 848/1065 - loss 0.31978307\n",
            "2019-07-22 03:53:30,996 epoch 4 - iter 954/1065 - loss 0.32070599\n",
            "2019-07-22 03:53:35,464 epoch 4 - iter 1060/1065 - loss 0.32032568\n",
            "2019-07-22 03:53:35,626 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 03:53:35,628 EPOCH 4 done: loss 0.3201 - lr 0.1000\n",
            "2019-07-22 03:53:40,375 DEV : loss 0.34196674823760986 - score 0.0678\n",
            "2019-07-22 03:53:40,823 BAD EPOCHS (no improvement): 2\n",
            "2019-07-22 03:53:40,825 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 03:53:40,877 epoch 5 - iter 0/1065 - loss 0.43574569\n",
            "2019-07-22 03:53:45,299 epoch 5 - iter 106/1065 - loss 0.31828655\n",
            "2019-07-22 03:53:49,695 epoch 5 - iter 212/1065 - loss 0.31963812\n",
            "2019-07-22 03:53:54,166 epoch 5 - iter 318/1065 - loss 0.32250259\n",
            "2019-07-22 03:53:58,554 epoch 5 - iter 424/1065 - loss 0.32106598\n",
            "2019-07-22 03:54:03,007 epoch 5 - iter 530/1065 - loss 0.32025737\n",
            "2019-07-22 03:54:07,444 epoch 5 - iter 636/1065 - loss 0.31765589\n",
            "2019-07-22 03:54:11,872 epoch 5 - iter 742/1065 - loss 0.31920903\n",
            "2019-07-22 03:54:16,288 epoch 5 - iter 848/1065 - loss 0.31973884\n",
            "2019-07-22 03:54:20,695 epoch 5 - iter 954/1065 - loss 0.31955296\n",
            "2019-07-22 03:54:25,060 epoch 5 - iter 1060/1065 - loss 0.31824849\n",
            "2019-07-22 03:54:25,225 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 03:54:25,227 EPOCH 5 done: loss 0.3181 - lr 0.1000\n",
            "2019-07-22 03:54:29,931 DEV : loss 0.3223678171634674 - score 0.1771\n",
            "2019-07-22 03:54:30,407 BAD EPOCHS (no improvement): 3\n",
            "2019-07-22 03:54:30,409 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 03:54:30,456 epoch 6 - iter 0/1065 - loss 0.12489024\n",
            "2019-07-22 03:54:34,927 epoch 6 - iter 106/1065 - loss 0.30962621\n",
            "2019-07-22 03:54:39,324 epoch 6 - iter 212/1065 - loss 0.31051640\n",
            "2019-07-22 03:54:43,663 epoch 6 - iter 318/1065 - loss 0.31176834\n",
            "2019-07-22 03:54:48,105 epoch 6 - iter 424/1065 - loss 0.31432784\n",
            "2019-07-22 03:54:52,463 epoch 6 - iter 530/1065 - loss 0.31334368\n",
            "2019-07-22 03:54:56,840 epoch 6 - iter 636/1065 - loss 0.31363607\n",
            "2019-07-22 03:55:01,286 epoch 6 - iter 742/1065 - loss 0.31386995\n",
            "2019-07-22 03:55:05,743 epoch 6 - iter 848/1065 - loss 0.31541133\n",
            "2019-07-22 03:55:10,118 epoch 6 - iter 954/1065 - loss 0.31480838\n",
            "2019-07-22 03:55:14,498 epoch 6 - iter 1060/1065 - loss 0.31555212\n",
            "2019-07-22 03:55:14,654 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 03:55:14,655 EPOCH 6 done: loss 0.3157 - lr 0.1000\n",
            "2019-07-22 03:55:19,383 DEV : loss 0.318146288394928 - score 0.2518\n",
            "Epoch     5: reducing learning rate of group 0 to 5.0000e-02.\n",
            "2019-07-22 03:55:19,825 BAD EPOCHS (no improvement): 4\n",
            "2019-07-22 03:55:19,827 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 03:55:19,873 epoch 7 - iter 0/1065 - loss 0.26601648\n",
            "2019-07-22 03:55:24,372 epoch 7 - iter 106/1065 - loss 0.31835437\n",
            "2019-07-22 03:55:28,774 epoch 7 - iter 212/1065 - loss 0.31546714\n",
            "2019-07-22 03:55:33,222 epoch 7 - iter 318/1065 - loss 0.31309860\n",
            "2019-07-22 03:55:37,662 epoch 7 - iter 424/1065 - loss 0.30686858\n",
            "2019-07-22 03:55:42,089 epoch 7 - iter 530/1065 - loss 0.30579954\n",
            "2019-07-22 03:55:46,540 epoch 7 - iter 636/1065 - loss 0.30612647\n",
            "2019-07-22 03:55:51,055 epoch 7 - iter 742/1065 - loss 0.30720972\n",
            "2019-07-22 03:55:55,505 epoch 7 - iter 848/1065 - loss 0.30756212\n",
            "2019-07-22 03:55:59,841 epoch 7 - iter 954/1065 - loss 0.30941953\n",
            "2019-07-22 03:56:04,194 epoch 7 - iter 1060/1065 - loss 0.30857472\n",
            "2019-07-22 03:56:04,351 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 03:56:04,353 EPOCH 7 done: loss 0.3083 - lr 0.0500\n",
            "2019-07-22 03:56:09,062 DEV : loss 0.31720486283302307 - score 0.2278\n",
            "2019-07-22 03:56:09,567 BAD EPOCHS (no improvement): 1\n",
            "2019-07-22 03:56:09,568 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 03:56:09,617 epoch 8 - iter 0/1065 - loss 0.38415733\n",
            "2019-07-22 03:56:14,090 epoch 8 - iter 106/1065 - loss 0.31667772\n",
            "2019-07-22 03:56:18,615 epoch 8 - iter 212/1065 - loss 0.30980231\n",
            "2019-07-22 03:56:22,991 epoch 8 - iter 318/1065 - loss 0.30916575\n",
            "2019-07-22 03:56:27,365 epoch 8 - iter 424/1065 - loss 0.31111348\n",
            "2019-07-22 03:56:31,781 epoch 8 - iter 530/1065 - loss 0.30843759\n",
            "2019-07-22 03:56:36,232 epoch 8 - iter 636/1065 - loss 0.30705908\n",
            "2019-07-22 03:56:40,705 epoch 8 - iter 742/1065 - loss 0.30785625\n",
            "2019-07-22 03:56:45,129 epoch 8 - iter 848/1065 - loss 0.30678692\n",
            "2019-07-22 03:56:49,626 epoch 8 - iter 954/1065 - loss 0.30658904\n",
            "2019-07-22 03:56:54,136 epoch 8 - iter 1060/1065 - loss 0.30710384\n",
            "2019-07-22 03:56:54,304 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 03:56:54,306 EPOCH 8 done: loss 0.3070 - lr 0.0500\n",
            "2019-07-22 03:56:59,152 DEV : loss 0.3147706985473633 - score 0.3096\n",
            "2019-07-22 03:56:59,660 BAD EPOCHS (no improvement): 2\n",
            "2019-07-22 03:56:59,662 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 03:56:59,708 epoch 9 - iter 0/1065 - loss 0.40244189\n",
            "2019-07-22 03:57:04,211 epoch 9 - iter 106/1065 - loss 0.30463433\n",
            "2019-07-22 03:57:08,688 epoch 9 - iter 212/1065 - loss 0.30744208\n",
            "2019-07-22 03:57:13,100 epoch 9 - iter 318/1065 - loss 0.30912026\n",
            "2019-07-22 03:57:17,550 epoch 9 - iter 424/1065 - loss 0.31028799\n",
            "2019-07-22 03:57:22,032 epoch 9 - iter 530/1065 - loss 0.30869827\n",
            "2019-07-22 03:57:26,494 epoch 9 - iter 636/1065 - loss 0.30777967\n",
            "2019-07-22 03:57:30,989 epoch 9 - iter 742/1065 - loss 0.30688705\n",
            "2019-07-22 03:57:35,479 epoch 9 - iter 848/1065 - loss 0.30723536\n",
            "2019-07-22 03:57:40,006 epoch 9 - iter 954/1065 - loss 0.30823493\n",
            "2019-07-22 03:57:44,434 epoch 9 - iter 1060/1065 - loss 0.30707881\n",
            "2019-07-22 03:57:44,598 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 03:57:44,599 EPOCH 9 done: loss 0.3071 - lr 0.0500\n",
            "2019-07-22 03:57:49,548 DEV : loss 0.31398388743400574 - score 0.277\n",
            "2019-07-22 03:57:50,062 BAD EPOCHS (no improvement): 3\n",
            "2019-07-22 03:57:50,064 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 03:57:50,113 epoch 10 - iter 0/1065 - loss 0.29354569\n",
            "2019-07-22 03:57:54,628 epoch 10 - iter 106/1065 - loss 0.30070359\n",
            "2019-07-22 03:57:59,131 epoch 10 - iter 212/1065 - loss 0.29845202\n",
            "2019-07-22 03:58:03,595 epoch 10 - iter 318/1065 - loss 0.30489515\n",
            "2019-07-22 03:58:08,033 epoch 10 - iter 424/1065 - loss 0.30220119\n",
            "2019-07-22 03:58:12,483 epoch 10 - iter 530/1065 - loss 0.30570835\n",
            "2019-07-22 03:58:16,942 epoch 10 - iter 636/1065 - loss 0.30581418\n",
            "2019-07-22 03:58:21,392 epoch 10 - iter 742/1065 - loss 0.30576249\n",
            "2019-07-22 03:58:25,885 epoch 10 - iter 848/1065 - loss 0.30536298\n",
            "2019-07-22 03:58:30,363 epoch 10 - iter 954/1065 - loss 0.30535217\n",
            "2019-07-22 03:58:34,850 epoch 10 - iter 1060/1065 - loss 0.30503712\n",
            "2019-07-22 03:58:35,013 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 03:58:35,014 EPOCH 10 done: loss 0.3050 - lr 0.0500\n",
            "2019-07-22 03:58:39,945 DEV : loss 0.31301671266555786 - score 0.3472\n",
            "Epoch     9: reducing learning rate of group 0 to 2.5000e-02.\n",
            "2019-07-22 03:58:40,448 BAD EPOCHS (no improvement): 4\n",
            "2019-07-22 03:58:44,155 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 03:58:44,156 Testing using best model ...\n",
            "2019-07-22 03:58:44,158 loading file flair_pooled/best-model.pt\n",
            "2019-07-22 03:59:08,440 0.3801\t0.4457\t0.4103\n",
            "2019-07-22 03:59:08,441 \n",
            "MICRO_AVG: acc 0.7151 - f1-score 0.8339\n",
            "MACRO_AVG: acc 0.5409 - f1-score 0.6568\n",
            "0          tp: 4407 - fp: 408 - fn: 535 - tn: 328 - precision: 0.9153 - recall: 0.8917 - accuracy: 0.8237 - f1-score: 0.9033\n",
            "1          tp: 328 - fp: 535 - fn: 408 - tn: 4407 - precision: 0.3801 - recall: 0.4457 - accuracy: 0.2581 - f1-score: 0.4103\n",
            "2019-07-22 03:59:08,442 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dev_loss_history': [tensor(0.3727, device='cuda:0'),\n",
              "  tensor(0.3900, device='cuda:0'),\n",
              "  tensor(0.3365, device='cuda:0'),\n",
              "  tensor(0.3420, device='cuda:0'),\n",
              "  tensor(0.3224, device='cuda:0'),\n",
              "  tensor(0.3181, device='cuda:0'),\n",
              "  tensor(0.3172, device='cuda:0'),\n",
              "  tensor(0.3148, device='cuda:0'),\n",
              "  tensor(0.3140, device='cuda:0'),\n",
              "  tensor(0.3130, device='cuda:0')],\n",
              " 'dev_score_history': [0.0176,\n",
              "  0.4484,\n",
              "  0.1038,\n",
              "  0.0678,\n",
              "  0.1771,\n",
              "  0.2518,\n",
              "  0.2278,\n",
              "  0.3096,\n",
              "  0.277,\n",
              "  0.3472],\n",
              " 'test_score': 0.4103,\n",
              " 'train_loss_history': [0.3490674949098081,\n",
              "  0.32861952582995096,\n",
              "  0.3238305854055803,\n",
              "  0.3200767190523551,\n",
              "  0.31807704455975633,\n",
              "  0.3157115360206002,\n",
              "  0.30832492641999687,\n",
              "  0.30695674105639187,\n",
              "  0.30709897971628974,\n",
              "  0.3050481594924076]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxfs6DE-PsZx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d784c941-435b-4104-dca2-9a41a2b29c95"
      },
      "source": [
        "from flair.embeddings import DocumentRNNEmbeddings\n",
        "corpus = NLPTaskDataFetcher.load_classification_corpus(Path('./'),\n",
        "                                                       test_file='flair_test.csv',\n",
        "                                                       dev_file='flair_dev.csv',\n",
        "                                                       train_file='flair_train.csv')\n",
        "word_embeddings = [WordEmbeddings('glove'),\n",
        "                   FlairEmbeddings('news-forward-fast'),\n",
        "                   FlairEmbeddings('news-backward-fast')]\n",
        "document_embeddings = DocumentRNNEmbeddings(word_embeddings, hidden_size=512,\n",
        "                                             reproject_words=True, reproject_words_dimension=256)\n",
        "\n",
        "classifier = TextClassifier(document_embeddings,\n",
        "                            label_dictionary=corpus.make_label_dictionary(), multi_label=False)\n",
        "trainer = ModelTrainer(classifier, corpus)\n",
        "trainer.train(max_epochs=10, base_path = \"flair_rnn\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-07-22 04:00:11,940 Reading data from .\n",
            "2019-07-22 04:00:11,941 Train: flair_train.csv\n",
            "2019-07-22 04:00:11,943 Dev: flair_dev.csv\n",
            "2019-07-22 04:00:11,944 Test: flair_test.csv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated function (or staticmethod) load_classification_corpus. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/flair/data_fetcher.py:447: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
            "  max_tokens_per_doc=max_tokens_per_doc,\n",
            "/usr/local/lib/python3.6/dist-packages/flair/data_fetcher.py:454: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
            "  max_tokens_per_doc=max_tokens_per_doc,\n",
            "/usr/local/lib/python3.6/dist-packages/flair/data_fetcher.py:463: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
            "  max_tokens_per_doc=max_tokens_per_doc,\n",
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-07-22 04:00:29,254 Computing label dictionary. Progress:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 34066/34066 [00:00<00:00, 258607.37it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-07-22 04:00:29,390 [b'0', b'1']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-07-22 04:00:29,513 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 04:00:29,514 Model: \"TextClassifier(\n",
            "  (document_embeddings): DocumentRNNEmbeddings(\n",
            "    (embeddings): StackedEmbeddings(\n",
            "      (list_embedding_0): WordEmbeddings('glove')\n",
            "      (list_embedding_1): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.25)\n",
            "          (encoder): Embedding(275, 100)\n",
            "          (rnn): LSTM(100, 1024)\n",
            "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (list_embedding_2): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.25)\n",
            "          (encoder): Embedding(275, 100)\n",
            "          (rnn): LSTM(100, 1024)\n",
            "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (word_reprojection_map): Linear(in_features=2148, out_features=256, bias=True)\n",
            "    (rnn): GRU(256, 512)\n",
            "    (dropout): Dropout(p=0.5)\n",
            "  )\n",
            "  (decoder): Linear(in_features=512, out_features=2, bias=True)\n",
            "  (loss_function): CrossEntropyLoss()\n",
            ")\"\n",
            "2019-07-22 04:00:29,516 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 04:00:29,517 Corpus: \"Corpus: 34066 train + 5678 dev + 5678 test sentences\"\n",
            "2019-07-22 04:00:29,518 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 04:00:29,518 Parameters:\n",
            "2019-07-22 04:00:29,519  - learning_rate: \"0.1\"\n",
            "2019-07-22 04:00:29,521  - mini_batch_size: \"32\"\n",
            "2019-07-22 04:00:29,521  - patience: \"3\"\n",
            "2019-07-22 04:00:29,522  - anneal_factor: \"0.5\"\n",
            "2019-07-22 04:00:29,523  - max_epochs: \"10\"\n",
            "2019-07-22 04:00:29,524  - shuffle: \"True\"\n",
            "2019-07-22 04:00:29,525  - train_with_dev: \"False\"\n",
            "2019-07-22 04:00:29,525 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 04:00:29,526 Model training base path: \"flair_rnn\"\n",
            "2019-07-22 04:00:29,527 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 04:00:29,528 Device: cuda:0\n",
            "2019-07-22 04:00:29,529 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 04:00:29,530 Embedding storage mode: cpu\n",
            "2019-07-22 04:00:29,531 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 04:00:29,771 epoch 1 - iter 0/1065 - loss 0.71697867\n",
            "2019-07-22 04:00:46,573 epoch 1 - iter 106/1065 - loss 0.39584383\n",
            "2019-07-22 04:01:03,520 epoch 1 - iter 212/1065 - loss 0.38525563\n",
            "2019-07-22 04:01:36,681 epoch 1 - iter 318/1065 - loss 0.38102248\n",
            "2019-07-22 04:01:53,170 epoch 1 - iter 424/1065 - loss 0.37796114\n",
            "2019-07-22 04:02:11,695 epoch 1 - iter 530/1065 - loss 0.37297430\n",
            "2019-07-22 04:02:28,415 epoch 1 - iter 636/1065 - loss 0.37292372\n",
            "2019-07-22 04:02:46,593 epoch 1 - iter 742/1065 - loss 0.37001234\n",
            "2019-07-22 04:03:04,123 epoch 1 - iter 848/1065 - loss 0.36906210\n",
            "2019-07-22 04:03:24,429 epoch 1 - iter 954/1065 - loss 0.37027735\n",
            "2019-07-22 04:03:40,711 epoch 1 - iter 1060/1065 - loss 0.36767127\n",
            "2019-07-22 04:03:41,329 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 04:03:41,330 EPOCH 1 done: loss 0.3679 - lr 0.1000\n",
            "2019-07-22 04:04:00,505 DEV : loss 0.3532070815563202 - score 0.1001\n",
            "2019-07-22 04:04:07,975 BAD EPOCHS (no improvement): 0\n",
            "2019-07-22 04:04:11,524 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 04:04:11,566 epoch 2 - iter 0/1065 - loss 0.30223742\n",
            "2019-07-22 04:04:15,058 epoch 2 - iter 106/1065 - loss 0.36038454\n",
            "2019-07-22 04:04:18,506 epoch 2 - iter 212/1065 - loss 0.35472878\n",
            "2019-07-22 04:04:22,041 epoch 2 - iter 318/1065 - loss 0.35719530\n",
            "2019-07-22 04:04:25,482 epoch 2 - iter 424/1065 - loss 0.35433677\n",
            "2019-07-22 04:04:29,059 epoch 2 - iter 530/1065 - loss 0.35541551\n",
            "2019-07-22 04:04:32,545 epoch 2 - iter 636/1065 - loss 0.35463561\n",
            "2019-07-22 04:04:36,108 epoch 2 - iter 742/1065 - loss 0.35337699\n",
            "2019-07-22 04:04:39,556 epoch 2 - iter 848/1065 - loss 0.34951509\n",
            "2019-07-22 04:04:42,954 epoch 2 - iter 954/1065 - loss 0.34826944\n",
            "2019-07-22 04:04:46,461 epoch 2 - iter 1060/1065 - loss 0.34781102\n",
            "2019-07-22 04:04:46,608 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 04:04:46,609 EPOCH 2 done: loss 0.3475 - lr 0.1000\n",
            "2019-07-22 04:04:50,119 DEV : loss 0.34453338384628296 - score 0.0858\n",
            "2019-07-22 04:04:50,621 BAD EPOCHS (no improvement): 1\n",
            "2019-07-22 04:04:50,622 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 04:04:50,668 epoch 3 - iter 0/1065 - loss 0.08161123\n",
            "2019-07-22 04:04:54,268 epoch 3 - iter 106/1065 - loss 0.33274176\n",
            "2019-07-22 04:04:57,788 epoch 3 - iter 212/1065 - loss 0.33402880\n",
            "2019-07-22 04:05:01,212 epoch 3 - iter 318/1065 - loss 0.33780109\n",
            "2019-07-22 04:05:04,714 epoch 3 - iter 424/1065 - loss 0.33544124\n",
            "2019-07-22 04:05:08,190 epoch 3 - iter 530/1065 - loss 0.33574307\n",
            "2019-07-22 04:05:11,747 epoch 3 - iter 636/1065 - loss 0.33423237\n",
            "2019-07-22 04:05:15,286 epoch 3 - iter 742/1065 - loss 0.33644470\n",
            "2019-07-22 04:05:18,749 epoch 3 - iter 848/1065 - loss 0.33693728\n",
            "2019-07-22 04:05:22,284 epoch 3 - iter 954/1065 - loss 0.33755691\n",
            "2019-07-22 04:05:25,882 epoch 3 - iter 1060/1065 - loss 0.33598328\n",
            "2019-07-22 04:05:26,030 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 04:05:26,032 EPOCH 3 done: loss 0.3357 - lr 0.1000\n",
            "2019-07-22 04:05:29,769 DEV : loss 0.35708364844322205 - score 0.0587\n",
            "2019-07-22 04:05:30,247 BAD EPOCHS (no improvement): 2\n",
            "2019-07-22 04:05:30,248 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 04:05:30,285 epoch 4 - iter 0/1065 - loss 0.47227418\n",
            "2019-07-22 04:05:33,879 epoch 4 - iter 106/1065 - loss 0.32297500\n",
            "2019-07-22 04:05:37,494 epoch 4 - iter 212/1065 - loss 0.33161216\n",
            "2019-07-22 04:05:41,027 epoch 4 - iter 318/1065 - loss 0.32630636\n",
            "2019-07-22 04:05:44,640 epoch 4 - iter 424/1065 - loss 0.32840556\n",
            "2019-07-22 04:05:48,153 epoch 4 - iter 530/1065 - loss 0.33165247\n",
            "2019-07-22 04:05:51,563 epoch 4 - iter 636/1065 - loss 0.33042862\n",
            "2019-07-22 04:05:55,035 epoch 4 - iter 742/1065 - loss 0.33239045\n",
            "2019-07-22 04:05:58,562 epoch 4 - iter 848/1065 - loss 0.33086279\n",
            "2019-07-22 04:06:02,035 epoch 4 - iter 954/1065 - loss 0.33097519\n",
            "2019-07-22 04:06:05,767 epoch 4 - iter 1060/1065 - loss 0.33091111\n",
            "2019-07-22 04:06:05,924 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 04:06:05,925 EPOCH 4 done: loss 0.3308 - lr 0.1000\n",
            "2019-07-22 04:06:09,714 DEV : loss 0.32863762974739075 - score 0.3167\n",
            "2019-07-22 04:06:10,228 BAD EPOCHS (no improvement): 0\n",
            "2019-07-22 04:06:13,783 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 04:06:13,832 epoch 5 - iter 0/1065 - loss 0.35133940\n",
            "2019-07-22 04:06:17,569 epoch 5 - iter 106/1065 - loss 0.30968454\n",
            "2019-07-22 04:06:21,109 epoch 5 - iter 212/1065 - loss 0.31722393\n",
            "2019-07-22 04:06:24,678 epoch 5 - iter 318/1065 - loss 0.31818248\n",
            "2019-07-22 04:06:28,226 epoch 5 - iter 424/1065 - loss 0.31867800\n",
            "2019-07-22 04:06:31,656 epoch 5 - iter 530/1065 - loss 0.32416169\n",
            "2019-07-22 04:06:35,126 epoch 5 - iter 636/1065 - loss 0.32439272\n",
            "2019-07-22 04:06:38,680 epoch 5 - iter 742/1065 - loss 0.32482870\n",
            "2019-07-22 04:06:42,250 epoch 5 - iter 848/1065 - loss 0.32500438\n",
            "2019-07-22 04:06:45,737 epoch 5 - iter 954/1065 - loss 0.32518803\n",
            "2019-07-22 04:06:49,382 epoch 5 - iter 1060/1065 - loss 0.32646913\n",
            "2019-07-22 04:06:49,531 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 04:06:49,532 EPOCH 5 done: loss 0.3266 - lr 0.1000\n",
            "2019-07-22 04:06:53,275 DEV : loss 0.3483636677265167 - score 0.0202\n",
            "2019-07-22 04:06:53,789 BAD EPOCHS (no improvement): 1\n",
            "2019-07-22 04:06:53,790 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 04:06:53,829 epoch 6 - iter 0/1065 - loss 0.29777828\n",
            "2019-07-22 04:06:57,424 epoch 6 - iter 106/1065 - loss 0.31616796\n",
            "2019-07-22 04:07:00,928 epoch 6 - iter 212/1065 - loss 0.30954436\n",
            "2019-07-22 04:07:04,455 epoch 6 - iter 318/1065 - loss 0.31853026\n",
            "2019-07-22 04:07:07,981 epoch 6 - iter 424/1065 - loss 0.31777798\n",
            "2019-07-22 04:07:11,640 epoch 6 - iter 530/1065 - loss 0.32031835\n",
            "2019-07-22 04:07:15,106 epoch 6 - iter 636/1065 - loss 0.32171163\n",
            "2019-07-22 04:07:18,559 epoch 6 - iter 742/1065 - loss 0.32217125\n",
            "2019-07-22 04:07:22,018 epoch 6 - iter 848/1065 - loss 0.32130660\n",
            "2019-07-22 04:07:25,525 epoch 6 - iter 954/1065 - loss 0.32290519\n",
            "2019-07-22 04:07:29,125 epoch 6 - iter 1060/1065 - loss 0.32211131\n",
            "2019-07-22 04:07:29,278 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 04:07:29,279 EPOCH 6 done: loss 0.3221 - lr 0.1000\n",
            "2019-07-22 04:07:33,007 DEV : loss 0.31842419505119324 - score 0.3051\n",
            "2019-07-22 04:07:33,476 BAD EPOCHS (no improvement): 2\n",
            "2019-07-22 04:07:33,478 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 04:07:33,516 epoch 7 - iter 0/1065 - loss 0.23396115\n",
            "2019-07-22 04:07:37,151 epoch 7 - iter 106/1065 - loss 0.32623226\n",
            "2019-07-22 04:07:40,780 epoch 7 - iter 212/1065 - loss 0.32532029\n",
            "2019-07-22 04:07:44,448 epoch 7 - iter 318/1065 - loss 0.31917765\n",
            "2019-07-22 04:07:48,045 epoch 7 - iter 424/1065 - loss 0.31860317\n",
            "2019-07-22 04:07:51,474 epoch 7 - iter 530/1065 - loss 0.31785295\n",
            "2019-07-22 04:07:54,909 epoch 7 - iter 636/1065 - loss 0.32079883\n",
            "2019-07-22 04:07:58,421 epoch 7 - iter 742/1065 - loss 0.31885311\n",
            "2019-07-22 04:08:01,981 epoch 7 - iter 848/1065 - loss 0.32024579\n",
            "2019-07-22 04:08:05,526 epoch 7 - iter 954/1065 - loss 0.32087414\n",
            "2019-07-22 04:08:09,195 epoch 7 - iter 1060/1065 - loss 0.31946803\n",
            "2019-07-22 04:08:09,369 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 04:08:09,370 EPOCH 7 done: loss 0.3195 - lr 0.1000\n",
            "2019-07-22 04:08:13,133 DEV : loss 0.3209840953350067 - score 0.2009\n",
            "2019-07-22 04:08:13,650 BAD EPOCHS (no improvement): 3\n",
            "2019-07-22 04:08:13,651 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 04:08:13,688 epoch 8 - iter 0/1065 - loss 0.08575824\n",
            "2019-07-22 04:08:17,344 epoch 8 - iter 106/1065 - loss 0.32727436\n",
            "2019-07-22 04:08:20,930 epoch 8 - iter 212/1065 - loss 0.31455543\n",
            "2019-07-22 04:08:24,453 epoch 8 - iter 318/1065 - loss 0.31370052\n",
            "2019-07-22 04:08:28,033 epoch 8 - iter 424/1065 - loss 0.31409459\n",
            "2019-07-22 04:08:31,609 epoch 8 - iter 530/1065 - loss 0.31674290\n",
            "2019-07-22 04:08:35,156 epoch 8 - iter 636/1065 - loss 0.31534873\n",
            "2019-07-22 04:08:38,682 epoch 8 - iter 742/1065 - loss 0.31474659\n",
            "2019-07-22 04:08:42,291 epoch 8 - iter 848/1065 - loss 0.31443979\n",
            "2019-07-22 04:08:45,847 epoch 8 - iter 954/1065 - loss 0.31605055\n",
            "2019-07-22 04:08:49,535 epoch 8 - iter 1060/1065 - loss 0.31534385\n",
            "2019-07-22 04:08:49,690 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 04:08:49,692 EPOCH 8 done: loss 0.3155 - lr 0.1000\n",
            "2019-07-22 04:08:53,484 DEV : loss 0.31844088435173035 - score 0.1502\n",
            "Epoch     7: reducing learning rate of group 0 to 5.0000e-02.\n",
            "2019-07-22 04:08:53,995 BAD EPOCHS (no improvement): 4\n",
            "2019-07-22 04:08:53,997 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 04:08:54,038 epoch 9 - iter 0/1065 - loss 0.41295421\n",
            "2019-07-22 04:08:57,633 epoch 9 - iter 106/1065 - loss 0.30033069\n",
            "2019-07-22 04:09:01,247 epoch 9 - iter 212/1065 - loss 0.30407640\n",
            "2019-07-22 04:09:04,798 epoch 9 - iter 318/1065 - loss 0.31099269\n",
            "2019-07-22 04:09:08,287 epoch 9 - iter 424/1065 - loss 0.30671896\n",
            "2019-07-22 04:09:11,841 epoch 9 - iter 530/1065 - loss 0.30556380\n",
            "2019-07-22 04:09:15,316 epoch 9 - iter 636/1065 - loss 0.30644969\n",
            "2019-07-22 04:09:18,821 epoch 9 - iter 742/1065 - loss 0.30621005\n",
            "2019-07-22 04:09:22,346 epoch 9 - iter 848/1065 - loss 0.30313624\n",
            "2019-07-22 04:09:25,916 epoch 9 - iter 954/1065 - loss 0.30370158\n",
            "2019-07-22 04:09:29,603 epoch 9 - iter 1060/1065 - loss 0.30425255\n",
            "2019-07-22 04:09:29,751 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 04:09:29,752 EPOCH 9 done: loss 0.3038 - lr 0.0500\n",
            "2019-07-22 04:09:33,561 DEV : loss 0.32166430354118347 - score 0.195\n",
            "2019-07-22 04:09:34,073 BAD EPOCHS (no improvement): 1\n",
            "2019-07-22 04:09:34,075 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 04:09:34,120 epoch 10 - iter 0/1065 - loss 0.37681454\n",
            "2019-07-22 04:09:37,768 epoch 10 - iter 106/1065 - loss 0.29064316\n",
            "2019-07-22 04:09:41,443 epoch 10 - iter 212/1065 - loss 0.29390306\n",
            "2019-07-22 04:09:44,971 epoch 10 - iter 318/1065 - loss 0.29577083\n",
            "2019-07-22 04:09:48,572 epoch 10 - iter 424/1065 - loss 0.29963113\n",
            "2019-07-22 04:09:52,083 epoch 10 - iter 530/1065 - loss 0.30291720\n",
            "2019-07-22 04:09:55,671 epoch 10 - iter 636/1065 - loss 0.30074662\n",
            "2019-07-22 04:09:59,266 epoch 10 - iter 742/1065 - loss 0.30041449\n",
            "2019-07-22 04:10:02,797 epoch 10 - iter 848/1065 - loss 0.30100073\n",
            "2019-07-22 04:10:06,344 epoch 10 - iter 954/1065 - loss 0.30327278\n",
            "2019-07-22 04:10:09,898 epoch 10 - iter 1060/1065 - loss 0.30173496\n",
            "2019-07-22 04:10:10,046 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 04:10:10,047 EPOCH 10 done: loss 0.3021 - lr 0.0500\n",
            "2019-07-22 04:10:13,654 DEV : loss 0.3139718472957611 - score 0.4215\n",
            "2019-07-22 04:10:14,090 BAD EPOCHS (no improvement): 0\n",
            "2019-07-22 04:10:20,893 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 04:10:20,894 Testing using best model ...\n",
            "2019-07-22 04:10:20,895 loading file flair_rnn/best-model.pt\n",
            "2019-07-22 04:10:42,912 0.5032\t0.3179\t0.3896\n",
            "2019-07-22 04:10:42,914 \n",
            "MICRO_AVG: acc 0.7713 - f1-score 0.8709\n",
            "MACRO_AVG: acc 0.5537 - f1-score 0.6587\n",
            "0          tp: 4711 - fp: 502 - fn: 231 - tn: 234 - precision: 0.9037 - recall: 0.9533 - accuracy: 0.8654 - f1-score: 0.9278\n",
            "1          tp: 234 - fp: 231 - fn: 502 - tn: 4711 - precision: 0.5032 - recall: 0.3179 - accuracy: 0.2420 - f1-score: 0.3896\n",
            "2019-07-22 04:10:42,914 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dev_loss_history': [tensor(0.3532, device='cuda:0'),\n",
              "  tensor(0.3445, device='cuda:0'),\n",
              "  tensor(0.3571, device='cuda:0'),\n",
              "  tensor(0.3286, device='cuda:0'),\n",
              "  tensor(0.3484, device='cuda:0'),\n",
              "  tensor(0.3184, device='cuda:0'),\n",
              "  tensor(0.3210, device='cuda:0'),\n",
              "  tensor(0.3184, device='cuda:0'),\n",
              "  tensor(0.3217, device='cuda:0'),\n",
              "  tensor(0.3140, device='cuda:0')],\n",
              " 'dev_score_history': [0.1001,\n",
              "  0.0858,\n",
              "  0.0587,\n",
              "  0.3167,\n",
              "  0.0202,\n",
              "  0.3051,\n",
              "  0.2009,\n",
              "  0.1502,\n",
              "  0.195,\n",
              "  0.4215],\n",
              " 'test_score': 0.3896,\n",
              " 'train_loss_history': [0.36786057157135904,\n",
              "  0.34752518860666964,\n",
              "  0.33568752971893184,\n",
              "  0.3308070373787007,\n",
              "  0.3266023180084609,\n",
              "  0.3220671186984425,\n",
              "  0.3195135344781786,\n",
              "  0.31547420419787575,\n",
              "  0.3038143427718973,\n",
              "  0.3021200100790727]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gh_FtqT24k_f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3de1a975-f5d6-4212-b549-8f015d11bbbe"
      },
      "source": [
        "from flair.embeddings import BertEmbeddings, ELMoEmbeddings\n",
        "\n",
        "corpus = NLPTaskDataFetcher.load_classification_corpus(Path('./'),\n",
        "                                                       test_file='flair_test.csv',\n",
        "                                                       dev_file='flair_dev.csv',\n",
        "                                                       train_file='flair_train.csv')\n",
        "word_embeddings = [BertEmbeddings(),\n",
        "                   WordEmbeddings(\"news\")] # bert and fasttext\n",
        "document_embeddings = DocumentPoolEmbeddings(word_embeddings)\n",
        "\n",
        "print(\"Create Classifier *************************\")\n",
        "classifier = TextClassifier(document_embeddings,\n",
        "                            label_dictionary=corpus.make_label_dictionary(), multi_label=False)\n",
        "print(\"Create Trainer *******************************\")\n",
        "trainer = ModelTrainer(classifier, corpus)\n",
        "print(\"Begin Training *******************************\")\n",
        "trainer.train(max_epochs=10, base_path = \"bert_pooled\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-07-22 04:18:48,501 Reading data from .\n",
            "2019-07-22 04:18:48,503 Train: flair_train.csv\n",
            "2019-07-22 04:18:48,505 Dev: flair_dev.csv\n",
            "2019-07-22 04:18:48,506 Test: flair_test.csv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated function (or staticmethod) load_classification_corpus. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/flair/data_fetcher.py:447: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
            "  max_tokens_per_doc=max_tokens_per_doc,\n",
            "/usr/local/lib/python3.6/dist-packages/flair/data_fetcher.py:454: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
            "  max_tokens_per_doc=max_tokens_per_doc,\n",
            "/usr/local/lib/python3.6/dist-packages/flair/data_fetcher.py:463: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
            "  max_tokens_per_doc=max_tokens_per_doc,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-07-22 04:19:11,107 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings-v0.3/en-fasttext-news-300d-1M.vectors.npy not found in cache, downloading to /tmp/tmp5zwdzkig\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1200000128/1200000128 [00:55<00:00, 21805313.83B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-07-22 04:20:06,686 copying /tmp/tmp5zwdzkig to cache at /root/.flair/embeddings/en-fasttext-news-300d-1M.vectors.npy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-07-22 04:20:10,205 removing temp file /tmp/tmp5zwdzkig\n",
            "2019-07-22 04:20:10,846 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings-v0.3/en-fasttext-news-300d-1M not found in cache, downloading to /tmp/tmpbxo231jf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 54600983/54600983 [00:03<00:00, 15995985.82B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-07-22 04:20:14,772 copying /tmp/tmpbxo231jf to cache at /root/.flair/embeddings/en-fasttext-news-300d-1M\n",
            "2019-07-22 04:20:14,825 removing temp file /tmp/tmpbxo231jf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Create Classifier *************************\n",
            "2019-07-22 04:20:25,247 Computing label dictionary. Progress:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 34066/34066 [00:00<00:00, 253155.35it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-07-22 04:20:25,386 [b'0', b'1']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Create Trainer *******************************\n",
            "Begin Training *******************************\n",
            "2019-07-22 04:20:25,528 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 04:20:25,531 Model: \"TextClassifier(\n",
            "  (document_embeddings): DocumentPoolEmbeddings(\n",
            "    fine_tune_mode=linear, pooling=mean\n",
            "    (embeddings): StackedEmbeddings(\n",
            "      (list_embedding_0): BertEmbeddings(\n",
            "        (model): BertModel(\n",
            "          (embeddings): BertEmbeddings(\n",
            "            (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "            (position_embeddings): Embedding(512, 768)\n",
            "            (token_type_embeddings): Embedding(2, 768)\n",
            "            (LayerNorm): BertLayerNorm()\n",
            "            (dropout): Dropout(p=0.1)\n",
            "          )\n",
            "          (encoder): BertEncoder(\n",
            "            (layer): ModuleList(\n",
            "              (0): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): BertLayerNorm()\n",
            "                    (dropout): Dropout(p=0.1)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): BertLayerNorm()\n",
            "                  (dropout): Dropout(p=0.1)\n",
            "                )\n",
            "              )\n",
            "              (1): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): BertLayerNorm()\n",
            "                    (dropout): Dropout(p=0.1)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): BertLayerNorm()\n",
            "                  (dropout): Dropout(p=0.1)\n",
            "                )\n",
            "              )\n",
            "              (2): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): BertLayerNorm()\n",
            "                    (dropout): Dropout(p=0.1)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): BertLayerNorm()\n",
            "                  (dropout): Dropout(p=0.1)\n",
            "                )\n",
            "              )\n",
            "              (3): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): BertLayerNorm()\n",
            "                    (dropout): Dropout(p=0.1)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): BertLayerNorm()\n",
            "                  (dropout): Dropout(p=0.1)\n",
            "                )\n",
            "              )\n",
            "              (4): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): BertLayerNorm()\n",
            "                    (dropout): Dropout(p=0.1)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): BertLayerNorm()\n",
            "                  (dropout): Dropout(p=0.1)\n",
            "                )\n",
            "              )\n",
            "              (5): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): BertLayerNorm()\n",
            "                    (dropout): Dropout(p=0.1)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): BertLayerNorm()\n",
            "                  (dropout): Dropout(p=0.1)\n",
            "                )\n",
            "              )\n",
            "              (6): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): BertLayerNorm()\n",
            "                    (dropout): Dropout(p=0.1)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): BertLayerNorm()\n",
            "                  (dropout): Dropout(p=0.1)\n",
            "                )\n",
            "              )\n",
            "              (7): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): BertLayerNorm()\n",
            "                    (dropout): Dropout(p=0.1)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): BertLayerNorm()\n",
            "                  (dropout): Dropout(p=0.1)\n",
            "                )\n",
            "              )\n",
            "              (8): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): BertLayerNorm()\n",
            "                    (dropout): Dropout(p=0.1)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): BertLayerNorm()\n",
            "                  (dropout): Dropout(p=0.1)\n",
            "                )\n",
            "              )\n",
            "              (9): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): BertLayerNorm()\n",
            "                    (dropout): Dropout(p=0.1)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): BertLayerNorm()\n",
            "                  (dropout): Dropout(p=0.1)\n",
            "                )\n",
            "              )\n",
            "              (10): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): BertLayerNorm()\n",
            "                    (dropout): Dropout(p=0.1)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): BertLayerNorm()\n",
            "                  (dropout): Dropout(p=0.1)\n",
            "                )\n",
            "              )\n",
            "              (11): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): BertLayerNorm()\n",
            "                    (dropout): Dropout(p=0.1)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): BertLayerNorm()\n",
            "                  (dropout): Dropout(p=0.1)\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (pooler): BertPooler(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (activation): Tanh()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (list_embedding_1): WordEmbeddings('news')\n",
            "    )\n",
            "    (embedding_flex): Linear(in_features=3372, out_features=3372, bias=False)\n",
            "  )\n",
            "  (decoder): Linear(in_features=3372, out_features=2, bias=True)\n",
            "  (loss_function): CrossEntropyLoss()\n",
            ")\"\n",
            "2019-07-22 04:20:25,532 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 04:20:25,533 Corpus: \"Corpus: 34066 train + 5678 dev + 5678 test sentences\"\n",
            "2019-07-22 04:20:25,534 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 04:20:25,535 Parameters:\n",
            "2019-07-22 04:20:25,536  - learning_rate: \"0.1\"\n",
            "2019-07-22 04:20:25,537  - mini_batch_size: \"32\"\n",
            "2019-07-22 04:20:25,538  - patience: \"3\"\n",
            "2019-07-22 04:20:25,539  - anneal_factor: \"0.5\"\n",
            "2019-07-22 04:20:25,541  - max_epochs: \"10\"\n",
            "2019-07-22 04:20:25,542  - shuffle: \"True\"\n",
            "2019-07-22 04:20:25,543  - train_with_dev: \"False\"\n",
            "2019-07-22 04:20:25,545 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 04:20:25,546 Model training base path: \"bert_pooled\"\n",
            "2019-07-22 04:20:25,547 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 04:20:25,549 Device: cuda:0\n",
            "2019-07-22 04:20:25,550 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 04:20:25,551 Embedding storage mode: cpu\n",
            "2019-07-22 04:20:25,554 ----------------------------------------------------------------------------------------------------\n",
            "2019-07-22 04:20:31,123 epoch 1 - iter 0/1065 - loss 1.05054939\n",
            "2019-07-22 04:32:58,977 epoch 1 - iter 106/1065 - loss 0.57855065\n",
            "2019-07-22 04:44:50,365 epoch 1 - iter 212/1065 - loss 0.47787506\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}