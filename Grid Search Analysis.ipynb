{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis with Grid Search\n",
    "\n",
    "Using grid search to determine the best parameters for the count vectorizer, the selecting of the best features, and the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import compress\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "from nltk.stem import snowball, WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer \n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline, make_union, FeatureUnion, Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile, chi2, f_classif\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8131, 53)\n",
      "(8127, 53)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "file_name = \"Isla Vista - All Excerpts - 1_2_2019.xlsx\"\n",
    "data = pd.read_excel(file_name, sheet_name='Dedoose Excerpts Export')\n",
    "print(data.shape)\n",
    "data = data.dropna(axis=0)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original: A 22-year-old student last Friday killed six people and wounded 13 more in Isla Vista before turning his gun on himself. Commenters \n",
      "blamed the killer�s crimes on everything from misogynistic �pickup artist philosophy� to easy access to guns and no-fault divorce. Even \n",
      "�nerd culture� has come under scrutiny. \n",
      "\n",
      "Is American culture to blame for mass murder? \n",
      "a student last friday kill six peopl and wound more in isla vista befor turn his gun on himself comment blame the crime on everyth from misogynist artist to easi access to gun and divorc even has come under scrutini is american cultur to blame for mass murder\n"
     ]
    }
   ],
   "source": [
    "excerpts = list(data['Excerpt'])\n",
    "def stem_tokenizer(doc):\n",
    "    tokens = word_tokenize(doc) \n",
    "    stemmer = snowball.SnowballStemmer(\"english\")\n",
    "    stemmed_tokens = [stemmer.stem(word) for word in tokens]\n",
    "    list_tokens = [tok.lower() for tok in stemmed_tokens if tok.isalpha()]\n",
    "    return(' '.join(list_tokens))\n",
    "print(\"original: \"+str(excerpts[3]))\n",
    "print(stem_tokenizer(excerpts[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# stem + count\n",
    "docs = [stem_tokenizer(doc) for doc in excerpts]\n",
    "vectorizer = CountVectorizer(max_features=1500, min_df=5, max_df=0.7, \n",
    "                             stop_words=stopwords.words('english'), ngram_range=(1, 3))  \n",
    "stem_count_X = vectorizer.fit_transform(docs).toarray() \n",
    "data_df = pd.DataFrame(stem_count_X)\n",
    "data_df.columns = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = data.ACCOUNT\n",
    "X_indices = np.arange(stem_count_X.shape[-1])\n",
    "#selector = SelectPercentile(f_classif, percentile=0.1)\n",
    "selector = SelectKBest(chi2, k=100)\n",
    "X_new = selector.fit_transform(data_df, y)\n",
    "best_feats = list(compress(data_df.columns, selector.get_support()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X is the list of raw docs\n",
    "class TextCleaner(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def stem_tokenizer(doc):\n",
    "        tokens = word_tokenize(doc) \n",
    "        stemmer = snowball.SnowballStemmer(\"english\")\n",
    "        stemmed_tokens = [stemmer.stem(word) for word in tokens]\n",
    "        list_tokens = [tok.lower() for tok in stemmed_tokens if tok.isalpha()]\n",
    "        return(' '.join(list_tokens))\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_out= [stem_tokenizer(doc) for doc in X]\n",
    "        return X_out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "for excerpt in excerpts:\n",
    "    doc = excerpt\n",
    "    tokens = word_tokenize(doc) \n",
    "    tokens = [tok for tok in tokens if tok.isalnum() or tok in string.punctuation]\n",
    "    tags = pos_tag(tokens)\n",
    "    list_tags = [tag for tok, tag in tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Pos(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def pos_tagger(self, doc):\n",
    "        tokens = word_tokenize(doc) \n",
    "        tokens = [tok for tok in tokens if tok.isalnum() or tok in string.punctuation]\n",
    "        tags = pos_tag(tokens)\n",
    "        list_tags = [tag for tok, tag in tags]\n",
    "        return(' '.join(list_tags))\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_out= [self.pos_tagger(doc) for doc in X]\n",
    "        return X_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class WordCounter():\n",
    "\n",
    "    def count(self, doc):\n",
    "        tokens = word_tokenize(doc) \n",
    "        return(len(tokens))\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_out= [self.count(doc) for doc in X]\n",
    "        return X_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_counts = Pipeline([\n",
    "                ('prepro', TextCleaner()),\n",
    "                ('vector', CountVectorizer(max_features=1500, min_df=5, max_df=0.7, \n",
    "                             stop_words=stopwords.words('english'), ngram_range=(1, 3)))\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_counts = Pipeline([\n",
    "                ('pos', Pos()),\n",
    "                ('pos_vector', CountVectorizer(max_features=1500, max_df=0.9, ngram_range=(1, 5)))\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_words = Pipeline([('word_count', WordCounter())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_output = ngram_counts.fit_transform(excerpts)\n",
    "pos_output = pos_counts.fit_transform(excerpts)\n",
    "num_words_output = num_words.fit_transform(excerpts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = FeatureUnion([('ngram_counts', ngram_counts), \n",
    "                      #('num_words', num_words),\n",
    "                      ('pos_counts', pos_counts)])\n",
    "                      \n",
    "#feature_processing = Pipeline([('feats', feats)])\n",
    "#feature_processing.fit_transform(excerpts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = \\\n",
    "            train_test_split(excerpts, data['ACCOUNT'].values, random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('features',feats),\n",
    "    (\"selectk\", SelectKBest(k=100, score_func=f_classif)),\n",
    "    ('classifier', RandomForestClassifier(random_state = 42)),\n",
    "])\n",
    "\n",
    "pipe_output = pipeline.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9655511811023622"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = pipeline.predict(x_test)\n",
    "np.mean(preds == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1567   18]\n",
      " [  52  395]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      1585\n",
      "           1       0.96      0.88      0.92       447\n",
      "\n",
      "    accuracy                           0.97      2032\n",
      "   macro avg       0.96      0.94      0.95      2032\n",
      "weighted avg       0.97      0.97      0.97      2032\n",
      "\n",
      "0.9655511811023622\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, preds))  \n",
    "print(classification_report(y_test, preds))  \n",
    "print(accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1174  411]\n",
      " [  67  380]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.74      0.83      1585\n",
      "           1       0.48      0.85      0.61       447\n",
      "\n",
      "    accuracy                           0.76      2032\n",
      "   macro avg       0.71      0.80      0.72      2032\n",
      "weighted avg       0.84      0.76      0.78      2032\n",
      "\n",
      "0.764763779527559\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('features',feats),\n",
    "    (\"selectk\", SelectKBest(k=1000)),\n",
    "    ('classifier', MultinomialNB()),\n",
    "])\n",
    "\n",
    "pipe_output = pipeline.fit(x_train, y_train)\n",
    "\n",
    "preds = pipeline.predict(x_test)\n",
    "np.mean(preds == y_test)\n",
    "\n",
    "print(confusion_matrix(y_test, preds))  \n",
    "print(classification_report(y_test, preds))  \n",
    "print(accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'verbose', 'features', 'selectk', 'classifier', 'features__n_jobs', 'features__transformer_list', 'features__transformer_weights', 'features__verbose', 'features__ngram_counts', 'features__pos_counts', 'features__ngram_counts__memory', 'features__ngram_counts__steps', 'features__ngram_counts__verbose', 'features__ngram_counts__prepro', 'features__ngram_counts__vector', 'features__ngram_counts__vector__analyzer', 'features__ngram_counts__vector__binary', 'features__ngram_counts__vector__decode_error', 'features__ngram_counts__vector__dtype', 'features__ngram_counts__vector__encoding', 'features__ngram_counts__vector__input', 'features__ngram_counts__vector__lowercase', 'features__ngram_counts__vector__max_df', 'features__ngram_counts__vector__max_features', 'features__ngram_counts__vector__min_df', 'features__ngram_counts__vector__ngram_range', 'features__ngram_counts__vector__preprocessor', 'features__ngram_counts__vector__stop_words', 'features__ngram_counts__vector__strip_accents', 'features__ngram_counts__vector__token_pattern', 'features__ngram_counts__vector__tokenizer', 'features__ngram_counts__vector__vocabulary', 'features__pos_counts__memory', 'features__pos_counts__steps', 'features__pos_counts__verbose', 'features__pos_counts__pos', 'features__pos_counts__pos_vector', 'features__pos_counts__pos_vector__analyzer', 'features__pos_counts__pos_vector__binary', 'features__pos_counts__pos_vector__decode_error', 'features__pos_counts__pos_vector__dtype', 'features__pos_counts__pos_vector__encoding', 'features__pos_counts__pos_vector__input', 'features__pos_counts__pos_vector__lowercase', 'features__pos_counts__pos_vector__max_df', 'features__pos_counts__pos_vector__max_features', 'features__pos_counts__pos_vector__min_df', 'features__pos_counts__pos_vector__ngram_range', 'features__pos_counts__pos_vector__preprocessor', 'features__pos_counts__pos_vector__stop_words', 'features__pos_counts__pos_vector__strip_accents', 'features__pos_counts__pos_vector__token_pattern', 'features__pos_counts__pos_vector__tokenizer', 'features__pos_counts__pos_vector__vocabulary', 'selectk__k', 'selectk__score_func', 'classifier__alpha', 'classifier__class_prior', 'classifier__fit_prior'])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    # 'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    # 'vect__max_features': (None, 5000, 10000, 50000),\n",
    "    'features__ngram_counts__vector__ngram_range': ((1, 1), (1, 3)),  # unigrams or trigrams\n",
    "    # 'tfidf__use_idf': (True, False),\n",
    "    # 'tfidf__norm': ('l1', 'l2'),\n",
    "    'selectk__score_func':(f_classif, chi2),\n",
    "    'selectk__k':(100, 1000)\n",
    "    #'clf__max_iter': (20,),\n",
    "    #'clf__alpha': (0.00001, 0.000001),\n",
    "    #'clf__penalty': ('l2', 'elasticnet'),\n",
    "    # 'clf__max_iter': (10, 50, 80),\n",
    "}\n",
    "grid_search = GridSearchCV(pipeline, parameters, cv=5,\n",
    "                           n_jobs=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "t0 = time()\n",
    "grid_search.fit(excerpts, data.ACCOUNT)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
