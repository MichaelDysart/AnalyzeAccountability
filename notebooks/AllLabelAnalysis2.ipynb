{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['San Bernardino - All Excerpts - 7_15_2019.xlsx_sentences_tfidf_cv_results_labels.csv',\n",
       " 'Vegas - All Excerpts - 7_15_2019.xlsx_sentences_tfidf_cv_results_labels.csv',\n",
       " 'Isla Vista - All Excerpts - 1_2_2019.xlsx_sentences_tfidf_cv_results_labels.csv',\n",
       " 'Marysville - All Excerpts - Final - 1_2_2019.xlsx_excerpts_tfidf_cv_results_labels.csv',\n",
       " 'Newtown - All Excerpts - 1-2-2019.xlsx_excerpts_tfidf_cv_results_labels.csv',\n",
       " 'Orlando - All Excerpts - 7_15_2019.xlsx_sentences_tfidf_cv_results_labels.csv',\n",
       " 'Marysville - All Excerpts - Final - 1_2_2019.xlsx_sentences_tfidf_cv_results_labels.csv',\n",
       " 'Charleston - All Excerpts - 7_15_2019.xlsx_excerpts_tfidf_cv_results_labels.csv',\n",
       " 'Vegas - All Excerpts - 7_15_2019.xlsx_excerpts_tfidf_cv_results_labels.csv',\n",
       " 'Isla Vista - All Excerpts - 1_2_2019.xlsx_excerpts_tfidf_cv_results_labels.csv',\n",
       " 'Charleston - All Excerpts - 7_15_2019.xlsx_sentences_tfidf_cv_results_labels.csv',\n",
       " 'Newtown - All Excerpts - 1-2-2019.xlsx_sentences_tfidf_cv_results_labels.csv',\n",
       " 'fulldata_excerpts_tfidf_cv_results_labels - fulldata_excerpts_tfidf_cv_results_labels.csv',\n",
       " 'Orlando - All Excerpts - 7_15_2019.xlsx_excerpts_tfidf_cv_results_labels.csv',\n",
       " 'San Bernardino - All Excerpts - 7_15_2019.xlsx_excerpts_tfidf_cv_results_labels.csv']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "from pivottablejs import pivot_ui\n",
    "path = 'classifier_cv_results/'\n",
    "file_names = os.listdir(path)\n",
    "[file_name for file_name in file_names if 'labels' in file_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Based Results For Each Event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "San Bernardino - All Excerpts - 7_15_2019.xlsx_sentences_tfidf_cv_results_labels.csv\n",
      "Vegas - All Excerpts - 7_15_2019.xlsx_sentences_tfidf_cv_results_labels.csv\n",
      "Isla Vista - All Excerpts - 1_2_2019.xlsx_sentences_tfidf_cv_results_labels.csv\n",
      "Orlando - All Excerpts - 7_15_2019.xlsx_sentences_tfidf_cv_results_labels.csv\n",
      "Marysville - All Excerpts - Final - 1_2_2019.xlsx_sentences_tfidf_cv_results_labels.csv\n",
      "Charleston - All Excerpts - 7_15_2019.xlsx_sentences_tfidf_cv_results_labels.csv\n",
      "Newtown - All Excerpts - 1-2-2019.xlsx_sentences_tfidf_cv_results_labels.csv\n"
     ]
    }
   ],
   "source": [
    "sentence_results_df = pd.DataFrame()\n",
    "\n",
    "for file_name in file_names:\n",
    "    if 'sentences' in file_name and 'labels' in file_name and 'fulldata' not in file_name:\n",
    "        print(file_name)\n",
    "        event_df = pd.read_csv(path+file_name)\n",
    "        event_df['event'] = file_name.split(' - ')[0]        \n",
    "        sentence_results_df = pd.concat([sentence_results_df, event_df], ignore_index=True)\n",
    "\n",
    "# get mean of cross val\n",
    "df1 = sentence_results_df.loc[:, ['label', 'event', 'vectorizer', 'classifier', \n",
    "                                 'recall', 'precision', 'fscore',\n",
    "                                 'num_test_exs', 'num_train_exs']]\n",
    "df_cv_mean = df1.groupby(['label', 'event', 'vectorizer', 'classifier']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get max of each classification method\n",
    "fmax_df = pd.DataFrame()\n",
    "for grp in df_cv_mean.groupby(['label', 'event']):\n",
    "    fmax_ids = grp[1].fscore == grp[1].fscore.max()\n",
    "    fmax_row = pd.DataFrame(grp[1].loc[fmax_ids,:]).reset_index()\n",
    "    if grp[1].fscore.max() >0:\n",
    "        fmax_df = fmax_df.append(fmax_row.loc[0,:], ignore_index = True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"500\"\n",
       "            src=\"sentences_pivottablejs.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1174c5828>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = fmax_df.loc[:, ['label', 'event', 'recall', 'precision', 'fscore',\n",
    "                                 'num_test_exs', 'num_train_exs']]\n",
    "\n",
    "pivot_ui(df,outfile_path='sentences_pivottablejs.html')\n",
    "#HTML(‘pivottablejs.html’)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excerpt Based Results for Each Event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marysville - All Excerpts - Final - 1_2_2019.xlsx_excerpts_tfidf_cv_results_labels.csv\n",
      "Newtown - All Excerpts - 1-2-2019.xlsx_excerpts_tfidf_cv_results_labels.csv\n",
      "Charleston - All Excerpts - 7_15_2019.xlsx_excerpts_tfidf_cv_results_labels.csv\n",
      "Vegas - All Excerpts - 7_15_2019.xlsx_excerpts_tfidf_cv_results_labels.csv\n",
      "Isla Vista - All Excerpts - 1_2_2019.xlsx_excerpts_tfidf_cv_results_labels.csv\n",
      "Orlando - All Excerpts - 7_15_2019.xlsx_excerpts_tfidf_cv_results_labels.csv\n",
      "San Bernardino - All Excerpts - 7_15_2019.xlsx_excerpts_tfidf_cv_results_labels.csv\n"
     ]
    }
   ],
   "source": [
    "excerpt_results_df = pd.DataFrame()\n",
    "\n",
    "for file_name in file_names:\n",
    "    if 'sentences' not in file_name and 'labels' in file_name and 'fulldata' not in file_name:\n",
    "        print(file_name)\n",
    "        event_df = pd.read_csv(path+file_name)\n",
    "        event_df['event'] = file_name.split(' - ')[0]        \n",
    "        excerpt_results_df = pd.concat([excerpt_results_df, event_df], ignore_index=True)\n",
    "\n",
    "df = excerpt_results_df.loc[:, ['label', 'event', 'vectorizer', 'classifier', \n",
    "                                'recall', 'precision', 'fscore',\n",
    "                                'num_test_exs', 'num_train_exs']]\n",
    "df_cv_mean = df.groupby(['label', 'event', 'vectorizer', 'classifier']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get max of each classification method\n",
    "excerpt_fmax_df = pd.DataFrame()\n",
    "for grp in df_cv_mean.groupby(['label', 'event']):\n",
    "    fmax_ids = grp[1].fscore == grp[1].fscore.max()\n",
    "    fmax_row = pd.DataFrame(grp[1].loc[fmax_ids,:]).reset_index()\n",
    "    if grp[1].fscore.max() >0:\n",
    "        excerpt_fmax_df = excerpt_fmax_df.append(fmax_row.loc[0,:], ignore_index = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"500\"\n",
       "            src=\"excerpts_pivottablejs.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x117c805c0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = excerpt_fmax_df.loc[:, ['label', 'event', 'recall', 'precision', 'fscore',\n",
    "                                 'num_test_exs', 'num_train_exs']]\n",
    "\n",
    "pivot_ui(df,outfile_path='excerpts_pivottablejs.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Events\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excerpt Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fulldata_excerpts_tfidf_cv_results_labels - fulldata_excerpts_tfidf_cv_results_labels.csv\n"
     ]
    }
   ],
   "source": [
    "for file_name in file_names:\n",
    "    if 'sentences' not in file_name and 'labels' in file_name and 'fulldata' in file_name:\n",
    "        print(file_name)\n",
    "        event_df = pd.read_csv(path+file_name)      \n",
    "        #event_results_df = pd.concat([event_results_df, event_df], ignore_index=True)\n",
    "        #print(event_df.columns)\n",
    "\n",
    "df = event_df.loc[:, ['label', 'vectorizer', 'classifier', 'recall', 'precision', 'fscore']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>fscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACCOUNT</td>\n",
       "      <td>0.701298</td>\n",
       "      <td>0.600271</td>\n",
       "      <td>0.646427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EVENT</td>\n",
       "      <td>0.855760</td>\n",
       "      <td>0.760016</td>\n",
       "      <td>0.804812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GRIEF</td>\n",
       "      <td>0.691717</td>\n",
       "      <td>0.730314</td>\n",
       "      <td>0.710274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HERO</td>\n",
       "      <td>0.601905</td>\n",
       "      <td>0.657407</td>\n",
       "      <td>0.623459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INVESTIGATION</td>\n",
       "      <td>0.700388</td>\n",
       "      <td>0.600388</td>\n",
       "      <td>0.646376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>JOURNEY</td>\n",
       "      <td>0.499084</td>\n",
       "      <td>0.512640</td>\n",
       "      <td>0.505202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LEGAL</td>\n",
       "      <td>0.684539</td>\n",
       "      <td>0.545679</td>\n",
       "      <td>0.607149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MEDIA</td>\n",
       "      <td>0.469642</td>\n",
       "      <td>0.646586</td>\n",
       "      <td>0.543683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MISCELLANEOUS</td>\n",
       "      <td>0.097963</td>\n",
       "      <td>0.358333</td>\n",
       "      <td>0.153100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MOURNING</td>\n",
       "      <td>0.745644</td>\n",
       "      <td>0.729050</td>\n",
       "      <td>0.737217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PERPETRATOR</td>\n",
       "      <td>0.666198</td>\n",
       "      <td>0.607743</td>\n",
       "      <td>0.635561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PHOTO</td>\n",
       "      <td>0.791482</td>\n",
       "      <td>0.962235</td>\n",
       "      <td>0.867822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>POLICY</td>\n",
       "      <td>0.809883</td>\n",
       "      <td>0.719699</td>\n",
       "      <td>0.761980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RACECULTURE</td>\n",
       "      <td>0.577077</td>\n",
       "      <td>0.485271</td>\n",
       "      <td>0.526538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RESOURCES</td>\n",
       "      <td>0.710595</td>\n",
       "      <td>0.720465</td>\n",
       "      <td>0.714699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SAFETY</td>\n",
       "      <td>0.711840</td>\n",
       "      <td>0.688813</td>\n",
       "      <td>0.699861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SOCIALSUPPORT</td>\n",
       "      <td>0.487058</td>\n",
       "      <td>0.596018</td>\n",
       "      <td>0.534268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>THREAT</td>\n",
       "      <td>0.366263</td>\n",
       "      <td>0.478500</td>\n",
       "      <td>0.412299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>TRAUMA</td>\n",
       "      <td>0.628757</td>\n",
       "      <td>0.578450</td>\n",
       "      <td>0.601620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            label    recall  precision    fscore\n",
       "0         ACCOUNT  0.701298   0.600271  0.646427\n",
       "1           EVENT  0.855760   0.760016  0.804812\n",
       "2           GRIEF  0.691717   0.730314  0.710274\n",
       "3            HERO  0.601905   0.657407  0.623459\n",
       "4   INVESTIGATION  0.700388   0.600388  0.646376\n",
       "5         JOURNEY  0.499084   0.512640  0.505202\n",
       "6           LEGAL  0.684539   0.545679  0.607149\n",
       "7           MEDIA  0.469642   0.646586  0.543683\n",
       "8   MISCELLANEOUS  0.097963   0.358333  0.153100\n",
       "9        MOURNING  0.745644   0.729050  0.737217\n",
       "10    PERPETRATOR  0.666198   0.607743  0.635561\n",
       "11          PHOTO  0.791482   0.962235  0.867822\n",
       "12         POLICY  0.809883   0.719699  0.761980\n",
       "13    RACECULTURE  0.577077   0.485271  0.526538\n",
       "14      RESOURCES  0.710595   0.720465  0.714699\n",
       "15         SAFETY  0.711840   0.688813  0.699861\n",
       "16  SOCIALSUPPORT  0.487058   0.596018  0.534268\n",
       "17         THREAT  0.366263   0.478500  0.412299\n",
       "18         TRAUMA  0.628757   0.578450  0.601620"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cv_mean = df.groupby(['label', 'vectorizer', 'classifier']).mean()\n",
    "# get max of each classification method\n",
    "fmax_df = pd.DataFrame()\n",
    "for grp in df_cv_mean.groupby(['label']):\n",
    "    fmax_ids = grp[1].fscore == grp[1].fscore.max()\n",
    "    fmax_row = pd.DataFrame(grp[1].loc[fmax_ids,:]).reset_index()\n",
    "    if grp[1].fscore.max() >0:\n",
    "        fmax_df = fmax_df.append(fmax_row.loc[0,:], ignore_index = True)\n",
    "        \n",
    "df = fmax_df.loc[:, ['label', 'recall', 'precision', 'fscore']]\n",
    "\n",
    "#pivot_ui(df,outfile_path='fulldata_excerpts_pivottablejs.html')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in file_names:\n",
    "    if 'sentences' in file_name and 'labels' in file_name and 'fulldata' in file_name:\n",
    "        print(file_name)\n",
    "        event_df = pd.read_csv(path+file_name)      \n",
    "        #event_results_df = pd.concat([event_results_df, event_df], ignore_index=True)\n",
    "        #print(event_df.columns)\n",
    "\n",
    "df = event_df.loc[:, ['label', 'vectorizer', 'classifier', 'recall', 'precision', 'fscore']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv_mean = df.groupby(['label', 'vectorizer', 'classifier']).mean()\n",
    "# get max of each classification method\n",
    "fmax_df = pd.DataFrame()\n",
    "for grp in df_cv_mean.groupby(['label']):\n",
    "    fmax_ids = grp[1].fscore == grp[1].fscore.max()\n",
    "    fmax_row = pd.DataFrame(grp[1].loc[fmax_ids,:]).reset_index()\n",
    "    if grp[1].fscore.max() >0:\n",
    "        fmax_df = fmax_df.append(fmax_row.loc[0,:], ignore_index = True)\n",
    "        \n",
    "df = fmax_df.loc[:, ['label', 'recall', 'precision', 'fscore']]\n",
    "\n",
    "#pivot_ui(df,outfile_path='fulldata_excerpts_pivottablejs.html')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
