{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Sentence Classifier\n",
    "\n",
    "This notebook will demonstrate baseline binary text classification approaches to classify the excerpts from the given datasets into classes 1 (accountability) or 0 (not accountability). The given datasets are new articles excerpts from news articles about three shooting events. Accountability class refers to if the excerpt is talking about accountability for the crime.\n",
    "\n",
    "The excerpts were processed into labelled single sentences, in order to test the effectiveness as a sentence based classifier. Three variations of the data will be tested:\n",
    "\n",
    "    1) Only testing excerpts that were originally single sentences\n",
    "    2) Testing labelled sentences from excerpts that were less than five sentences\n",
    "    3) Testing labelled sentences from the full dataset of excerpts\n",
    "    \n",
    "This notebook will also assess the affects of class imbalance, and run the same classifiers with balanced classes using the sklearn function:\n",
    "```python\n",
    "    n_samples / (n_classes * np.bincount(y))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Classifiers\n",
    "\n",
    "\n",
    "### Single Sentence Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "from classifiers.binary_classifier import *\n",
    "from witwidget.notebook.visualization import WitWidget, WitConfigBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing classifier: SVC\n",
      "Classifier: SVC f1: [0.5406698564593301, 0.5243902439024389]\n",
      "count vector SVC results:\n",
      "[[1611  135]\n",
      " [  57  113]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.94      1746\n",
      "           1       0.46      0.66      0.54       170\n",
      "\n",
      "    accuracy                           0.90      1916\n",
      "   macro avg       0.71      0.79      0.74      1916\n",
      "weighted avg       0.92      0.90      0.91      1916\n",
      "\n",
      "Processing classifier: LogisticRegression\n",
      "Classifier: LogisticRegression f1: [0.5393258426966292, 0.5301204819277109]\n",
      "count vector LogisticRegression results:\n",
      "[[1591  155]\n",
      " [  50  120]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94      1746\n",
      "           1       0.44      0.71      0.54       170\n",
      "\n",
      "    accuracy                           0.89      1916\n",
      "   macro avg       0.70      0.81      0.74      1916\n",
      "weighted avg       0.92      0.89      0.90      1916\n",
      "\n",
      "Processing classifier: RandomForestClassifier\n",
      "Classifier: RandomForestClassifier f1: [0.4426229508196722, 0.41803278688524587]\n",
      "count vector RandomForestClassifier results:\n",
      "[[1726   20]\n",
      " [ 116   54]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96      1746\n",
      "           1       0.73      0.32      0.44       170\n",
      "\n",
      "    accuracy                           0.93      1916\n",
      "   macro avg       0.83      0.65      0.70      1916\n",
      "weighted avg       0.92      0.93      0.92      1916\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Single Sentences\n",
    "single_sents_results = find_best_classifier([\"data/single_sents_df.csv\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing classifier: SVC\n",
    "Classifier: SVC f1: [0.5406698564593301, 0.5243902439024389]\n",
    "count vector SVC results:\n",
    "[[1611  135]\n",
    " [  57  113]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.97      0.92      0.94      1746\n",
    "           1       0.46      0.66      0.54       170\n",
    "\n",
    "    accuracy                           0.90      1916\n",
    "   macro avg       0.71      0.79      0.74      1916\n",
    "weighted avg       0.92      0.90      0.91      1916\n",
    "\n",
    "Processing classifier: LogisticRegression\n",
    "Classifier: LogisticRegression f1: [0.5393258426966292, 0.5301204819277109]\n",
    "count vector LogisticRegression results:\n",
    "[[1591  155]\n",
    " [  50  120]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.97      0.91      0.94      1746\n",
    "           1       0.44      0.71      0.54       170\n",
    "\n",
    "    accuracy                           0.89      1916\n",
    "   macro avg       0.70      0.81      0.74      1916\n",
    "weighted avg       0.92      0.89      0.90      1916\n",
    "\n",
    "Processing classifier: RandomForestClassifier\n",
    "Classifier: RandomForestClassifier f1: [0.4426229508196722, 0.41803278688524587]\n",
    "count vector RandomForestClassifier results:\n",
    "[[1726   20]\n",
    " [ 116   54]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.94      0.99      0.96      1746\n",
    "           1       0.73      0.32      0.44       170\n",
    "\n",
    "    accuracy                           0.93      1916\n",
    "   macro avg       0.83      0.65      0.70      1916\n",
    "weighted avg       0.92      0.93      0.92      1916"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short Excerpts Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing classifier: SVC\n",
      "Classifier: SVC f1: [0.45367412140575086, 0.46356809417495437]\n",
      "tfidf vector SVC results:\n",
      "[[7571 2305]\n",
      " [ 338 1142]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.77      0.85      9876\n",
      "           1       0.33      0.77      0.46      1480\n",
      "\n",
      "    accuracy                           0.77     11356\n",
      "   macro avg       0.64      0.77      0.66     11356\n",
      "weighted avg       0.88      0.77      0.80     11356\n",
      "\n",
      "Processing classifier: LogisticRegression\n",
      "Classifier: LogisticRegression f1: [0.46609172873382987, 0.47326978864484043]\n",
      "tfidf vector LogisticRegression results:\n",
      "[[7672 2204]\n",
      " [ 338 1142]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.78      0.86      9876\n",
      "           1       0.34      0.77      0.47      1480\n",
      "\n",
      "    accuracy                           0.78     11356\n",
      "   macro avg       0.65      0.77      0.67     11356\n",
      "weighted avg       0.88      0.78      0.81     11356\n",
      "\n",
      "Processing classifier: RandomForestClassifier\n",
      "Classifier: RandomForestClassifier f1: [0.5255366395262768, 0.5346831646044244]\n",
      "tfidf vector RandomForestClassifier results:\n",
      "[[9402  474]\n",
      " [ 767  713]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.94      9876\n",
      "           1       0.60      0.48      0.53      1480\n",
      "\n",
      "    accuracy                           0.89     11356\n",
      "   macro avg       0.76      0.72      0.74     11356\n",
      "weighted avg       0.88      0.89      0.89     11356\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sentences from excerpts less than five sentences\n",
    "short_ex_results = find_best_classifier([\"data/short_excerpts_df.csv\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing classifier: SVC\n",
    "Classifier: SVC f1: [0.45367412140575086, 0.46356809417495437]\n",
    "tfidf vector SVC results:\n",
    "[[7571 2305]\n",
    " [ 338 1142]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.96      0.77      0.85      9876\n",
    "           1       0.33      0.77      0.46      1480\n",
    "\n",
    "    accuracy                           0.77     11356\n",
    "   macro avg       0.64      0.77      0.66     11356\n",
    "weighted avg       0.88      0.77      0.80     11356\n",
    "\n",
    "Processing classifier: LogisticRegression\n",
    "Classifier: LogisticRegression f1: [0.46609172873382987, 0.47326978864484043]\n",
    "tfidf vector LogisticRegression results:\n",
    "[[7672 2204]\n",
    " [ 338 1142]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.96      0.78      0.86      9876\n",
    "           1       0.34      0.77      0.47      1480\n",
    "\n",
    "    accuracy                           0.78     11356\n",
    "   macro avg       0.65      0.77      0.67     11356\n",
    "weighted avg       0.88      0.78      0.81     11356\n",
    "\n",
    "Processing classifier: RandomForestClassifier\n",
    "Classifier: RandomForestClassifier f1: [0.5255366395262768, 0.5346831646044244]\n",
    "tfidf vector RandomForestClassifier results:\n",
    "[[9402  474]\n",
    " [ 767  713]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.92      0.95      0.94      9876\n",
    "           1       0.60      0.48      0.53      1480\n",
    "\n",
    "    accuracy                           0.89     11356\n",
    "   macro avg       0.76      0.72      0.74     11356\n",
    "weighted avg       0.88      0.89      0.89     11356"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test With Label Noise Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>StoryID</th>\n",
       "      <th>Excerpts</th>\n",
       "      <th>ACCOUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/short_excerpts_df.csv</td>\n",
       "      <td>NI2599</td>\n",
       "      <td>Are guns the problem, video\\ngames, the increa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/short_excerpts_df.csv</td>\n",
       "      <td>NI2599</td>\n",
       "      <td>Can the increase in gun violence in our school...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/short_excerpts_df.csv</td>\n",
       "      <td>NI2951</td>\n",
       "      <td>A 22-year-old student last Friday killed six p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/short_excerpts_df.csv</td>\n",
       "      <td>NI2951</td>\n",
       "      <td>A 22-year-old student last Friday killed six p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/short_excerpts_df.csv</td>\n",
       "      <td>NI2951</td>\n",
       "      <td>Commenters \\nblamed the killer�s crimes on eve...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         file StoryID  \\\n",
       "0  data/short_excerpts_df.csv  NI2599   \n",
       "1  data/short_excerpts_df.csv  NI2599   \n",
       "2  data/short_excerpts_df.csv  NI2951   \n",
       "3  data/short_excerpts_df.csv  NI2951   \n",
       "4  data/short_excerpts_df.csv  NI2951   \n",
       "\n",
       "                                            Excerpts  ACCOUNT  \n",
       "0  Are guns the problem, video\\ngames, the increa...        1  \n",
       "1  Can the increase in gun violence in our school...        1  \n",
       "2  A 22-year-old student last Friday killed six p...        0  \n",
       "3  A 22-year-old student last Friday killed six p...        1  \n",
       "4  Commenters \\nblamed the killer�s crimes on eve...        1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_df = load_data(['data/short_excerpts_df.csv'])\n",
    "sentences_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: DeprecationWarning: invalid escape sequence '\\ '\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "df2 = sentences_df[['ACCOUNT', 'Excerpts']]\n",
    "\n",
    "# Remove non ascii characters\n",
    "comments = df2['Excerpts'].values\n",
    "proc_comments = []\n",
    "for c in comments:\n",
    "    try:\n",
    "        if sys.version_info >= (3, 0):\n",
    "            c = bytes(c, 'utf-8')\n",
    "        c = c.decode('unicode_escape')\n",
    "        if sys.version_info < (3, 0):\n",
    "            c = c.encode('ascii', 'ignore')\n",
    "        proc_comments.append(c.strip())\n",
    "    except:\n",
    "        proc_comments.append('')\n",
    "\n",
    "df3 = df2.assign(Excerpts=proc_comments)\n",
    "\n",
    "label_column = 'ACCOUNT'\n",
    "#make_label_column_numeric(df3, label_column, lambda val: val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Converts a dataframe into a list of tf.Example protos.\n",
    "def df_to_examples(df, columns=None):\n",
    "    examples = []\n",
    "    if columns == None:\n",
    "        columns = df.columns.values.tolist()\n",
    "    for index, row in df.iterrows():\n",
    "        example = tf.train.Example()\n",
    "        for col in columns:\n",
    "            if df[col].dtype is np.dtype(np.int64):\n",
    "                example.features.feature[col].int64_list.value.append(int(row[col]))\n",
    "            elif df[col].dtype is np.dtype(np.float64):\n",
    "                example.features.feature[col].float_list.value.append(row[col])\n",
    "            elif row[col] == row[col]:\n",
    "                example.features.feature[col].bytes_list.value.append(row[col].encode('utf-8'))\n",
    "        examples.append(example)\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes_list {\n",
       "  value: \"Can the increase in gun violence in our schools\\nbe a reflection of the generation on children we are raising or a result of the political unrest in our country?\"\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = df_to_examples(df3)\n",
    "examples[1].features.feature['Excerpts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=1000,\n",
       "          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,\n",
       "          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train simple classifier\n",
    "excerpts = df3['Excerpts']\n",
    "docs = [stem_tokenizer(doc) for doc in excerpts]\n",
    "count_vectorizer = CountVectorizer(max_features=1000, min_df=10, max_df=0.7,\n",
    "                                    stop_words=stopwords.words('english'))\n",
    "stem_count_X = count_vectorizer.fit_transform(docs).toarray()\n",
    "\n",
    "logreg = LogisticRegression(solver='lbfgs', max_iter=1000, class_weight='balanced')\n",
    "\n",
    "docs_train, docs_test, y_train, y_test \\\n",
    "= train_test_split(pd.DataFrame(stem_count_X), df3['ACCOUNT'],\n",
    "                    test_size=0.25, random_state=50)\n",
    "\n",
    "logreg.fit(docs_train, y_train)\n",
    "#y_pred = logreg.predict(docs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get raw string out of tf.Example and prepare it for keras model input\n",
    "def examples_to_model_in(examples, tokenizer):\n",
    "    texts = [ex.features.feature['Excerpts'].bytes_list.value[0] for ex in examples]\n",
    "    if sys.version_info >= (3, 0):\n",
    "        texts = [t.decode('utf-8') for t in texts]\n",
    "    # Tokenize string into fixed length sequence of integer based on tokenizer \n",
    "    # and model padding\n",
    "    #text_sequences = tokenizer.texts_to_sequences(texts)\n",
    "    #model_ins = pad_sequences(text_sequences, maxlen=PADDING_LEN)\n",
    "    return model_ins\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# WIT predict functions:\n",
    "def custom_predict(examples_to_infer):\n",
    "    model_ins = examples_to_model_in(examples_to_infer, tokenizer1)\n",
    "    preds = logreg.predict(model_ins)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_datapoints = 1000  #@param {type: \"number\"}\n",
    "tool_height_in_px = 720  #@param {type: \"number\"}\n",
    "\n",
    "# Setup the tool with the test examples and the trained classifier\n",
    "config_builder = WitConfigBuilder(examples[0:10]).set_custom_predict_fn(\n",
    "  custom_predict)#.set_compare_custom_predict_fn(custom_predict_2)\n",
    "\n",
    "wv = WitWidget(config_builder, height=tool_height_in_px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c464e5452c864e488ad746af44e86fb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "WitWidget(config={'model_type': 'classification', 'label_vocab': [], 'are_sequence_examples': False, 'inferenc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "WitWidget(config_builder, height=tool_height_in_px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f10bcd8accc40d2ac764915faa19ac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "WitWidget(config={'model_type': 'classification', 'label_vocab': [], 'are_sequence_examples': False, 'inferenc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__del__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_add_notifiers',\n",
       " '_call_widget_constructed',\n",
       " '_comm_changed',\n",
       " '_compare',\n",
       " '_cross_validation_lock',\n",
       " '_default_keys',\n",
       " '_delete_example',\n",
       " '_display_callbacks',\n",
       " '_dom_classes',\n",
       " '_duplicate_example',\n",
       " '_gen_repr_from_keys',\n",
       " '_generate_sprite',\n",
       " '_get_element_html',\n",
       " '_get_eligible_features',\n",
       " '_get_embed_state',\n",
       " '_handle_custom_msg',\n",
       " '_handle_displayed',\n",
       " '_handle_msg',\n",
       " '_holding_sync',\n",
       " '_infer',\n",
       " '_infer_mutants',\n",
       " '_ipython_display_',\n",
       " '_is_numpy',\n",
       " '_json_from_tf_examples',\n",
       " '_lock_property',\n",
       " '_log_default',\n",
       " '_model_id',\n",
       " '_model_module',\n",
       " '_model_module_version',\n",
       " '_model_name',\n",
       " '_msg_callbacks',\n",
       " '_notify_trait',\n",
       " '_predict_aip_compare_model',\n",
       " '_predict_aip_impl',\n",
       " '_predict_aip_model',\n",
       " '_property_lock',\n",
       " '_register_validator',\n",
       " '_remove_notifiers',\n",
       " '_report_error',\n",
       " '_repr_keys',\n",
       " '_send',\n",
       " '_should_send_property',\n",
       " '_states_to_send',\n",
       " '_trait_default_generators',\n",
       " '_trait_from_json',\n",
       " '_trait_notifiers',\n",
       " '_trait_to_json',\n",
       " '_trait_validators',\n",
       " '_trait_values',\n",
       " '_update_example',\n",
       " '_view_count',\n",
       " '_view_module',\n",
       " '_view_module_version',\n",
       " '_view_name',\n",
       " '_widget_construction_callback',\n",
       " 'add_class',\n",
       " 'add_traits',\n",
       " 'adjust_example_fn',\n",
       " 'adjust_prediction_fn',\n",
       " 'class_own_trait_events',\n",
       " 'class_own_traits',\n",
       " 'class_trait_names',\n",
       " 'class_traits',\n",
       " 'close',\n",
       " 'close_all',\n",
       " 'comm',\n",
       " 'compare_adjust_example_fn',\n",
       " 'compare_adjust_prediction_fn',\n",
       " 'compare_custom_predict_fn',\n",
       " 'compare_estimator_and_spec',\n",
       " 'config',\n",
       " 'create_sprite',\n",
       " 'cross_validation_lock',\n",
       " 'custom_predict_fn',\n",
       " 'delete_example',\n",
       " 'duplicate_example',\n",
       " 'eligible_features',\n",
       " 'error',\n",
       " 'error_counter',\n",
       " 'estimator_and_spec',\n",
       " 'examples',\n",
       " 'get_eligible_features',\n",
       " 'get_eligible_features_impl',\n",
       " 'get_manager_state',\n",
       " 'get_state',\n",
       " 'get_view_spec',\n",
       " 'handle_comm_opened',\n",
       " 'has_trait',\n",
       " 'hold_sync',\n",
       " 'hold_trait_notifications',\n",
       " 'infer',\n",
       " 'infer_impl',\n",
       " 'infer_mutants',\n",
       " 'infer_mutants_impl',\n",
       " 'inferences',\n",
       " 'json_to_proto',\n",
       " 'keys',\n",
       " 'layout',\n",
       " 'log',\n",
       " 'model_id',\n",
       " 'mutant_charts',\n",
       " 'mutant_charts_counter',\n",
       " 'notify_change',\n",
       " 'observe',\n",
       " 'on_displayed',\n",
       " 'on_msg',\n",
       " 'on_trait_change',\n",
       " 'on_widget_constructed',\n",
       " 'open',\n",
       " 'remove_class',\n",
       " 'send',\n",
       " 'send_state',\n",
       " 'set_examples',\n",
       " 'set_state',\n",
       " 'set_trait',\n",
       " 'setup_instance',\n",
       " 'sprite',\n",
       " 'trait_events',\n",
       " 'trait_metadata',\n",
       " 'trait_names',\n",
       " 'traits',\n",
       " 'unobserve',\n",
       " 'unobserve_all',\n",
       " 'update_example',\n",
       " 'updated_example_indices',\n",
       " 'widget_types',\n",
       " 'widgets']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
