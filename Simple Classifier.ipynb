{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.stem import snowball, WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer \n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import FreqDist\n",
    "from itertools import compress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8131, 53)\n",
      "(8127, 53)\n",
      "Index(['StoryID', 'Excerpt', 'CodesApplied_Combined', 'ACCOUNT',\n",
      "       'ACCOUNT_Cultural', 'ACCOUNT_Individual', 'ACCOUNT_Other',\n",
      "       'COMMUNITYRECOVERY', 'EVENT', 'GRIEF', 'GRIEF_Individual',\n",
      "       'GRIEF_Community', 'GRIEF_Societal', 'HERO', 'INVESTIGATION', 'JOURNEY',\n",
      "       'JOURNEY_Mental', 'JOURNEY_Physical', 'LEGAL', 'MEDIA', 'MISCELLANEOUS',\n",
      "       'MOURNING', 'MOURNING_Individual', 'MOURNING_Community',\n",
      "       'MOURNING_Societal', 'PERPETRATOR', 'PHOTO', 'POLICY', 'POLICY_Guns',\n",
      "       'POLICY_InfoSharing', 'POLICY_MentalHealth', 'POLICY_Other',\n",
      "       'POLICY_VictimAdv', 'POLICY_OtherAdv', 'POLICY_Practice',\n",
      "       'PRIVATESECTOR', 'RACECULTURE', 'RESOURCES', 'SAFETY',\n",
      "       'SAFETY_Community', 'SAFETY_Individual', 'SAFETY_SchoolOrg',\n",
      "       'SAFETY_Societal', 'SOCIALSUPPORT', 'THREAT', 'THREAT_Assessment',\n",
      "       'TRAUMA', 'TRAUMA_Physical', 'TRAUMA_Psychological',\n",
      "       'TRAUMA_Individual', 'TRAUMA_Community', 'TRAUMA_Societal', 'VICTIMS'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "file_name = \"Isla Vista - All Excerpts - 1_2_2019.xlsx\"\n",
    "data = pd.read_excel(file_name, sheet_name='Dedoose Excerpts Export')\n",
    "print(data.shape)\n",
    "data = data.dropna(axis=0)\n",
    "print(data.shape)\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a student last friday kill six peopl and wound more in isla vista before turn his gun on himself comment blame the crime on everyth from misogynist artist to easi access to gun and divorc even has come under scrutini is american cultur to blame for mass murder'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "excerpts = list(data['Excerpt'])\n",
    "def stem_tokenizer(doc):\n",
    "    tokens = word_tokenize(doc) \n",
    "    stemmer = snowball.SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "    stemmed_tokens = [stemmer.stem(word) for word in tokens]\n",
    "    list_tokens = [tok.lower() for tok in stemmed_tokens if tok.isalpha()]\n",
    "    return(' '.join(list_tokens))\n",
    "stem_tokenizer(excerpts[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docs = [stem_tokenizer(doc) for doc in excerpts]\n",
    "vectorizer = CountVectorizer(max_features=1500, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))  \n",
    "X = vectorizer.fit_transform(docs).toarray() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docs_train, docs_test, y_train, y_test = train_test_split(X, list(data['ACCOUNT']), test_size=0.2, random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=1000, random_state=0)  \n",
    "classifier.fit(docs_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(docs_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1220   26]\n",
      " [  86  294]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96      1246\n",
      "           1       0.92      0.77      0.84       380\n",
      "\n",
      "    accuracy                           0.93      1626\n",
      "   macro avg       0.93      0.88      0.90      1626\n",
      "weighted avg       0.93      0.93      0.93      1626\n",
      "\n",
      "0.931119311193112\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred))  \n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(classifier.feature_importances_) == len(vectorizer.get_feature_names()))\n",
    "top_feats = np.argsort(classifier.feature_importances_)[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['student', 'culture', 'gun', 'april', 'sex', 'blamed', 'manifesto', 'rodger', 'mental', 'video']\n"
     ]
    }
   ],
   "source": [
    "feat_names = [vectorizer.get_feature_names()[feat] for feat in top_feats]\n",
    "print(feat_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class: [0]\n"
     ]
    }
   ],
   "source": [
    "test_doc = np.zeros(len(docs_test[1]))\n",
    "test_doc[top_feats[0]] = 1\n",
    "print(\"class: \"+str(classifier.predict([test_doc])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a svm Classifier\n",
    "clf = svm.SVC(kernel='linear') # Linear Kernel\n",
    "#Train the model using the training sets\n",
    "clf.fit(docs_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1173   73]\n",
      " [  73  307]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94      1246\n",
      "           1       0.81      0.81      0.81       380\n",
      "\n",
      "    accuracy                           0.91      1626\n",
      "   macro avg       0.87      0.87      0.87      1626\n",
      "weighted avg       0.91      0.91      0.91      1626\n",
      "\n",
      "0.9102091020910209\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(docs_test)\n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred))  \n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1188   58]\n",
      " [  75  305]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95      1246\n",
      "           1       0.84      0.80      0.82       380\n",
      "\n",
      "    accuracy                           0.92      1626\n",
      "   macro avg       0.89      0.88      0.88      1626\n",
      "weighted avg       0.92      0.92      0.92      1626\n",
      "\n",
      "0.9182041820418204\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(docs_train, y_train)\n",
    "\n",
    "y_pred = logreg.predict(docs_test)\n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred))  \n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docs = [stem_tokenizer(doc) for doc in excerpts]\n",
    "tfidfconverter = TfidfVectorizer(max_features=1500, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))  \n",
    " X = tfidfconverter.fit_transform(docs).toarray() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1224   22]\n",
      " [  87  293]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96      1246\n",
      "           1       0.93      0.77      0.84       380\n",
      "\n",
      "    accuracy                           0.93      1626\n",
      "   macro avg       0.93      0.88      0.90      1626\n",
      "weighted avg       0.93      0.93      0.93      1626\n",
      "\n",
      "0.9329643296432965\n"
     ]
    }
   ],
   "source": [
    "docs_train, docs_test, y_train, y_test = train_test_split(X, list(data['ACCOUNT']), test_size=0.2, random_state=0) \n",
    "classifier = RandomForestClassifier(n_estimators=1000, random_state=0)  \n",
    "classifier.fit(docs_train, y_train) \n",
    "y_pred = classifier.predict(docs_test)  \n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred))  \n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'student last friday killed six people wounded isla vista turning gun commenters blamed crime everything misogynistic artist easy access gun divorce even come scrutiny american culture blame mass murder'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "excerpts = list(data['Excerpt'])\n",
    "def lem_tokenizer(doc):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = word_tokenize(doc) \n",
    "    lemmer = WordNetLemmatizer()\n",
    "    lemmed_tokens = [lemmer.lemmatize(word) for word in tokens if word.lower() not in stop_words]\n",
    "    list_tokens = [tok.lower() for tok in lemmed_tokens if tok.isalpha()]\n",
    "    return(' '.join(list_tokens))\n",
    "lem_tokenizer(excerpts[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docs = [lem_tokenizer(doc) for doc in excerpts]\n",
    "vectorizer = CountVectorizer(max_features=1500, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))  \n",
    "X = vectorizer.fit_transform(docs).toarray() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1218   28]\n",
      " [  86  294]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96      1246\n",
      "           1       0.91      0.77      0.84       380\n",
      "\n",
      "    accuracy                           0.93      1626\n",
      "   macro avg       0.92      0.88      0.90      1626\n",
      "weighted avg       0.93      0.93      0.93      1626\n",
      "\n",
      "0.9298892988929889\n"
     ]
    }
   ],
   "source": [
    "docs_train, docs_test, y_train, y_test = train_test_split(X, list(data['ACCOUNT']), test_size=0.2, random_state=0) \n",
    "classifier = RandomForestClassifier(n_estimators=1000, random_state=0)  \n",
    "classifier.fit(docs_train, y_train) \n",
    "y_pred = classifier.predict(docs_test)  \n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred))  \n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
