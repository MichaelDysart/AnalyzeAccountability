{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Text Classifiers\n",
    "\n",
    "This notebook will show a simple approach to text classification. Without any complicated pre-processing, linear and ensemble classification models will be tested. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "from nltk.stem import snowball, WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer \n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8131, 53)\n",
      "(8127, 53)\n",
      "Index(['StoryID', 'Excerpt', 'CodesApplied_Combined', 'ACCOUNT',\n",
      "       'ACCOUNT_Cultural', 'ACCOUNT_Individual', 'ACCOUNT_Other',\n",
      "       'COMMUNITYRECOVERY', 'EVENT', 'GRIEF', 'GRIEF_Individual',\n",
      "       'GRIEF_Community', 'GRIEF_Societal', 'HERO', 'INVESTIGATION', 'JOURNEY',\n",
      "       'JOURNEY_Mental', 'JOURNEY_Physical', 'LEGAL', 'MEDIA', 'MISCELLANEOUS',\n",
      "       'MOURNING', 'MOURNING_Individual', 'MOURNING_Community',\n",
      "       'MOURNING_Societal', 'PERPETRATOR', 'PHOTO', 'POLICY', 'POLICY_Guns',\n",
      "       'POLICY_InfoSharing', 'POLICY_MentalHealth', 'POLICY_Other',\n",
      "       'POLICY_VictimAdv', 'POLICY_OtherAdv', 'POLICY_Practice',\n",
      "       'PRIVATESECTOR', 'RACECULTURE', 'RESOURCES', 'SAFETY',\n",
      "       'SAFETY_Community', 'SAFETY_Individual', 'SAFETY_SchoolOrg',\n",
      "       'SAFETY_Societal', 'SOCIALSUPPORT', 'THREAT', 'THREAT_Assessment',\n",
      "       'TRAUMA', 'TRAUMA_Physical', 'TRAUMA_Psychological',\n",
      "       'TRAUMA_Individual', 'TRAUMA_Community', 'TRAUMA_Societal', 'VICTIMS'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "file_name = \"Isla Vista - All Excerpts - 1_2_2019.xlsx\"\n",
    "data = pd.read_excel(file_name, sheet_name='Dedoose Excerpts Export')\n",
    "print(data.shape)\n",
    "data = data.dropna(axis=0)\n",
    "print(data.shape)\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Tokenizers\n",
    "\n",
    "Two tokenizers will be tested, one with the most simple approach of stemming words. The second has some added complexity, using the WordNet lemmatizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original: A 22-year-old student last Friday killed six people and wounded 13 more in Isla Vista before turning his gun on himself. Commenters \n",
      "blamed the killer�s crimes on everything from misogynistic �pickup artist philosophy� to easy access to guns and no-fault divorce. Even \n",
      "�nerd culture� has come under scrutiny. \n",
      "\n",
      "Is American culture to blame for mass murder? \n",
      "a student last friday kill six peopl and wound more in isla vista before turn his gun on himself comment blame the crime on everyth from misogynist artist to easi access to gun and divorc even has come under scrutini is american cultur to blame for mass murder\n"
     ]
    }
   ],
   "source": [
    "excerpts = list(data['Excerpt'])\n",
    "def stem_tokenizer(doc):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = word_tokenize(doc) \n",
    "    stemmer = snowball.SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "    stemmed_tokens = [stemmer.stem(word) for word in tokens]\n",
    "    list_tokens = [tok.lower() for tok in stemmed_tokens if tok.isalpha()]\n",
    "    return(' '.join(list_tokens))\n",
    "print(\"original: \"+str(excerpts[3]))\n",
    "print(stem_tokenizer(excerpts[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original: \n",
      "A 22-year-old student last Friday killed six people and wounded 13 more in Isla Vista before turning his gun on himself. Commenters \n",
      "blamed the killer�s crimes on everything from misogynistic �pickup artist philosophy� to easy access to guns and no-fault divorce. Even \n",
      "�nerd culture� has come under scrutiny. \n",
      "\n",
      "Is American culture to blame for mass murder? \n",
      "\n",
      "student last friday killed six people wounded isla vista turning gun commenters blamed crime everything misogynistic artist easy access gun divorce even come scrutiny american culture blame mass murder\n"
     ]
    }
   ],
   "source": [
    "excerpts = list(data['Excerpt'])\n",
    "def lem_tokenizer(doc):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = word_tokenize(doc) \n",
    "    lemmer = WordNetLemmatizer()\n",
    "    lemmed_tokens = [lemmer.lemmatize(word) for word in tokens if word.lower() not in stop_words]\n",
    "    list_tokens = [tok.lower() for tok in lemmed_tokens if tok.isalpha()]\n",
    "    return(' '.join(list_tokens))\n",
    "print(\"original: \\n\"+str(excerpts[3])+str(\"\\n\"))\n",
    "print(lem_tokenizer(excerpts[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Vectorizers\n",
    "\n",
    "The two tokenizers can then be used to create vectorized representation. Two vectorizers will be used. First the count vectorizer, then the tfidf vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# stem + count\n",
    "docs = [stem_tokenizer(doc) for doc in excerpts]\n",
    "vectorizer = CountVectorizer(max_features=1500, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))  \n",
    "stem_count_X = vectorizer.fit_transform(docs).toarray() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lem + count\n",
    "docs = [lem_tokenizer(doc) for doc in excerpts]\n",
    "vectorizer = CountVectorizer(max_features=1500, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))  \n",
    "lem_count_X = vectorizer.fit_transform(docs).toarray() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# stem + tfidf\n",
    "docs = [stem_tokenizer(doc) for doc in excerpts]\n",
    "vectorizer = TfidfVectorizer(max_features=1500, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))  \n",
    "stem_tfidf_X = vectorizer.fit_transform(docs).toarray() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lem + tfidf\n",
    "docs = [lem_tokenizer(doc) for doc in excerpts]\n",
    "vectorizer = TfidfVectorizer(max_features=1500, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))  \n",
    "lem_tfidf_X = vectorizer.fit_transform(docs).toarray() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Classifiers\n",
    "\n",
    "Test each vectorized representation with simple classifiers.\n",
    "\n",
    "### Linear\n",
    "\n",
    "First compare two linear models: svm and logistic regression\n",
    "\n",
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1177   69]\n",
      " [  66  314]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95      1246\n",
      "           1       0.82      0.83      0.82       380\n",
      "\n",
      "    accuracy                           0.92      1626\n",
      "   macro avg       0.88      0.89      0.88      1626\n",
      "weighted avg       0.92      0.92      0.92      1626\n",
      "\n",
      "0.9169741697416974\n"
     ]
    }
   ],
   "source": [
    "docs_train, docs_test, y_train, y_test = train_test_split(stem_count_X, list(data['ACCOUNT']),\n",
    "                                                          test_size=0.2, random_state=0) \n",
    "#Create a svm Classifier\n",
    "clf = svm.SVC(kernel='linear') # Linear Kernel\n",
    "#Train the model using the training sets\n",
    "clf.fit(docs_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(docs_test)\n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred))  \n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1193   53]\n",
      " [  77  303]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95      1246\n",
      "           1       0.85      0.80      0.82       380\n",
      "\n",
      "    accuracy                           0.92      1626\n",
      "   macro avg       0.90      0.88      0.89      1626\n",
      "weighted avg       0.92      0.92      0.92      1626\n",
      "\n",
      "0.9200492004920049\n"
     ]
    }
   ],
   "source": [
    "docs_train, docs_test, y_train, y_test = train_test_split(stem_tfidf_X, list(data['ACCOUNT']),\n",
    "                                                          test_size=0.2, random_state=0) \n",
    "#Create a svm Classifier\n",
    "clf = svm.SVC(kernel='linear') # Linear Kernel\n",
    "#Train the model using the training sets\n",
    "clf.fit(docs_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(docs_test)\n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred))  \n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1173   73]\n",
      " [  73  307]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94      1246\n",
      "           1       0.81      0.81      0.81       380\n",
      "\n",
      "    accuracy                           0.91      1626\n",
      "   macro avg       0.87      0.87      0.87      1626\n",
      "weighted avg       0.91      0.91      0.91      1626\n",
      "\n",
      "0.9102091020910209\n"
     ]
    }
   ],
   "source": [
    "docs_train, docs_test, y_train, y_test = train_test_split(lem_count_X, list(data['ACCOUNT']),\n",
    "                                                          test_size=0.2, random_state=0) \n",
    "#Create a svm Classifier\n",
    "clf = svm.SVC(kernel='linear') # Linear Kernel\n",
    "#Train the model using the training sets\n",
    "clf.fit(docs_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(docs_test)\n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred))  \n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1188   58]\n",
      " [  75  305]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95      1246\n",
      "           1       0.84      0.80      0.82       380\n",
      "\n",
      "    accuracy                           0.92      1626\n",
      "   macro avg       0.89      0.88      0.88      1626\n",
      "weighted avg       0.92      0.92      0.92      1626\n",
      "\n",
      "0.9182041820418204\n"
     ]
    }
   ],
   "source": [
    "docs_train, docs_test, y_train, y_test = train_test_split(lem_tfidf_X, list(data['ACCOUNT']),\n",
    "                                                          test_size=0.2, random_state=0) \n",
    "#Create a svm Classifier\n",
    "clf = svm.SVC(kernel='linear') # Linear Kernel\n",
    "#Train the model using the training sets\n",
    "clf.fit(docs_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(docs_test)\n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred))  \n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression\n",
    "\n",
    "Since all the setups gave equivalent f1-scores, the simples approach will be chosen to test with logisitic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1185   61]\n",
      " [  68  312]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95      1246\n",
      "           1       0.84      0.82      0.83       380\n",
      "\n",
      "    accuracy                           0.92      1626\n",
      "   macro avg       0.89      0.89      0.89      1626\n",
      "weighted avg       0.92      0.92      0.92      1626\n",
      "\n",
      "0.9206642066420664\n"
     ]
    }
   ],
   "source": [
    "docs_train, docs_test, y_train, y_test = train_test_split(stem_count_X, list(data['ACCOUNT']), \n",
    "                                                          test_size=0.2, random_state=0) \n",
    "\n",
    "logreg = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "logreg.fit(docs_train, y_train)\n",
    "\n",
    "y_pred = logreg.predict(docs_test)\n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred))  \n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Model\n",
    "\n",
    "Test the ensemble models random forest.\n",
    "\n",
    "#### Count Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_train, docs_test, y_train, y_test = train_test_split(stem_count_X, list(data['ACCOUNT']), #test_size=0.2,\n",
    "                                                         random_state=0) \n",
    "classifier = RandomForestClassifier(n_estimators=1000, random_state=0)  \n",
    "classifier.fit(docs_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1521   38]\n",
      " [ 110  363]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95      1559\n",
      "           1       0.91      0.77      0.83       473\n",
      "\n",
      "    accuracy                           0.93      2032\n",
      "   macro avg       0.92      0.87      0.89      2032\n",
      "weighted avg       0.93      0.93      0.92      2032\n",
      "\n",
      "0.9271653543307087\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(docs_test)  \n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred))  \n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "['studying', 'requires', 'around', 'woodland', 'shifman', 'born', 'men', 'safe', 'month', 'village']\n"
     ]
    }
   ],
   "source": [
    "print(len(classifier.feature_importances_) == len(vectorizer.get_feature_names()))\n",
    "top_feats = np.argsort(classifier.feature_importances_)[-10:]\n",
    "feat_names = [vectorizer.get_feature_names()[feat] for feat in top_feats]\n",
    "print(feat_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class: [0]\n"
     ]
    }
   ],
   "source": [
    "test_doc = np.zeros(len(docs_test[1]))\n",
    "test_doc[top_feats[6]] = 1\n",
    "print(\"class: \"+str(classifier.predict([test_doc])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ensemble model shows the best performance, though it is important to note that the ensemble has a more complex decision boundary, and can be more prone to over-fitting. This would require evaluation through cross-validation to confirm the performance increase. It is also interesting to note the term \"blame\" was one of the top contributing terms to the model, and it results in the decision to classify a document as \"account\" (class label =1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tfidf Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# stem + tfidf\n",
    "docs = [stem_tokenizer(doc) for doc in excerpts]\n",
    "vectorizer = TfidfVectorizer(max_features=1500, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))  \n",
    "stem_tfidf_X = vectorizer.fit_transform(docs).toarray() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1523   36]\n",
      " [ 102  371]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96      1559\n",
      "           1       0.91      0.78      0.84       473\n",
      "\n",
      "    accuracy                           0.93      2032\n",
      "   macro avg       0.92      0.88      0.90      2032\n",
      "weighted avg       0.93      0.93      0.93      2032\n",
      "\n",
      "0.9320866141732284\n"
     ]
    }
   ],
   "source": [
    "docs_train, docs_test, y_train, y_test = train_test_split(pd.DataFrame(stem_tfidf_X), \n",
    "                                                          list(data['ACCOUNT']), #test_size=0.2,\n",
    "                                                         random_state=0) \n",
    "classifier = RandomForestClassifier(n_estimators=1000, random_state=0)  \n",
    "classifier.fit(docs_train, y_train) \n",
    "\n",
    "y_pred = classifier.predict(docs_test)  \n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred))  \n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "['date', 'around', 'woodland', 'requires', 'shifman', 'born', 'safe', 'men', 'month', 'village']\n"
     ]
    }
   ],
   "source": [
    "print(len(classifier.feature_importances_) == len(vectorizer.get_feature_names()))\n",
    "top_feats = np.argsort(classifier.feature_importances_)[-10:]\n",
    "feat_names = [vectorizer.get_feature_names()[feat] for feat in top_feats]\n",
    "print(feat_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of Errors\n",
    "\n",
    "Which documents were predicted incorrectly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# documents incorrectly predicted with label 1\n",
    "incorrect1_ids = [list(docs_test.index)[idx] for idx in range(0,len(docs_test)) \n",
    "              if (y_test[idx]==0 and y_pred[idx] == 1)]\n",
    "incorrect1 = [docs[idx] for idx in incorrect1_ids]\n",
    "\n",
    "# documents incorrectly predicted with label 0\n",
    "incorrect0_ids = [list(docs_test.index)[idx] for idx in range(0,len(docs_test)) \n",
    "              if y_test[idx]==1 and y_pred[idx] == 0]\n",
    "incorrect0 = [docs[idx] for idx in incorrect0_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'in a youtub video and an onlin manifesto that rodger publish before the spasm of violenc he spoke of take reveng on blond soror girl and the whose compani they prefer to his own while he wrote at length of clash with past roommat he did not seem to have as mani conflict with hong and chen but he wrote that he would have to kill his housem secur the entir apart for myself ad that he would knock them out with a hammer before slit their throat'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# documents incorrectly predicted with label 1\n",
    "incorrect1_ids = [list(docs_test.index)[idx] for idx in range(0,len(docs_test)) \n",
    "              if (y_test[idx]==0 and y_pred[idx] == 1)]\n",
    "incorrect1 = [excerpts[idx] for idx in incorrect1_ids]\n",
    "\n",
    "# documents incorrectly predicted with label 0\n",
    "incorrect0_ids = [list(docs_test.index)[idx] for idx in range(0,len(docs_test)) \n",
    "              if y_test[idx]==1 and y_pred[idx] == 0]\n",
    "incorrect0 = [excerpts[idx] for idx in incorrect0_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Only weeks earlier, in late April, deputies from the Santa Barbara County Sheriff's Office had stopped by Mr. Rodger's apartment at the request of state mental health officials, acting on an expression of concern by his mother. They left after a calm and polite Mr. Rodger assured them that there was nothing to worry about. The officers reported that Mr. Rodger was shy and had told them that he was having difficulties in his social life.\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rodger left a long trail across the Internet, both with YouTube videos and online message board postings, that appear to explain why he\\nlaunched his \"Day of Retribution.\" As short and mixed-race (Asian and Anglo), Rodger was perpetually insecure about his looks. Yet his\\nvideos repeatedly speak to a sense of entitlement with women – he deserved their love and was anguished at their lack of interest despite\\nhis jet-setting lifestyle as the son of a Hollywood director. (His father was an assistant director for the first \"Hunger Games.\")\\nThis perceived slight became the fuel for his anger. In a YouTube video that has since been removed, he vowed: \"I\\'m going to enter the\\nhottest sorority house of [the University of California at Santa Barbara] and I will slaughter every single spoilt, stuck-up, blonde ... that I\\nsee inside there.\"'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect0[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "\n",
    "These simple tests show that it should be possible to acheive a fairly high performance classifier, since these very basic pre-processing methods and simple linear classifier were able to achieve a fairly high f-score above 0.9. There is still room for improvement in the classification of the account class label, and one issue that can be seen is the class imbalance. It is not a major imbalance, but it will contribute to the lower f-score for class 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
