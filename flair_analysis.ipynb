{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "flair analysis.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anjapago/AnalyzeAccountability/blob/master/flair_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtgjqStCtTF8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0f9b1aab-8d5f-4425-f8c7-fa0f0d229e6f"
      },
      "source": [
        "pip install git+https://github.com/anjapago/flair"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/anjapago/flair\n",
            "  Cloning https://github.com/anjapago/flair to /tmp/pip-req-build-8cbisttt\n",
            "  Running command git clone -q https://github.com/anjapago/flair /tmp/pip-req-build-8cbisttt\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: gensim>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (3.6.0)\n",
            "Collecting bpemb>=0.2.9 (from flair==0.4.2)\n",
            "  Downloading https://files.pythonhosted.org/packages/bc/70/468a9652095b370f797ed37ff77e742b11565c6fd79eaeca5f2e50b164a7/bpemb-0.3.0-py3-none-any.whl\n",
            "Collecting langdetect (from flair==0.4.2)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/59/4bc44158a767a6d66de18c4136c8aa90491d56cc951c10b74dd1e13213c9/langdetect-1.0.7.zip (998kB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 14.5MB/s \n",
            "\u001b[?25hCollecting mpld3==0.3 (from flair==0.4.2)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/95/a52d3a83d0a29ba0d6898f6727e9858fe7a43f6c2ce81a5fe7e05f0f4912/mpld3-0.3.tar.gz (788kB)\n",
            "\u001b[K     |████████████████████████████████| 798kB 50.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.25,>=1.20 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (1.24.3)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (1.1.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (0.8.3)\n",
            "Requirement already satisfied: pytest>=3.6.4 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (3.6.4)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (0.0)\n",
            "Collecting regex (from flair==0.4.2)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/4e/1b178c38c9a1a184288f72065a65ca01f3154df43c6ad898624149b8b4e0/regex-2019.06.08.tar.gz (651kB)\n",
            "\u001b[K     |████████████████████████████████| 655kB 51.5MB/s \n",
            "\u001b[?25hCollecting pytorch-pretrained-bert>=0.6.1 (from flair==0.4.2)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 50.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (4.28.1)\n",
            "Collecting sqlitedict>=1.6.0 (from flair==0.4.2)\n",
            "  Downloading https://files.pythonhosted.org/packages/0f/1c/c757b93147a219cf1e25cef7e1ad9b595b7f802159493c45ce116521caff/sqlitedict-1.6.0.tar.gz\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (3.0.3)\n",
            "Collecting deprecated>=1.2.4 (from flair==0.4.2)\n",
            "  Downloading https://files.pythonhosted.org/packages/88/0e/9d5a1a8cd7130c49334cce7b8167ceda63d6a329c8ea65b626116bc9e9e6/Deprecated-1.2.6-py2.py3-none-any.whl\n",
            "Requirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.2) (0.1.2)\n",
            "Collecting segtok>=1.5.7 (from flair==0.4.2)\n",
            "  Downloading https://files.pythonhosted.org/packages/1d/59/6ed78856ab99d2da04084b59e7da797972baa0efecb71546b16d48e49d9b/segtok-1.5.7.tar.gz\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair==0.4.2) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair==0.4.2) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair==0.4.2) (1.16.4)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair==0.4.2) (1.8.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from bpemb>=0.2.9->flair==0.4.2) (2.21.0)\n",
            "Collecting sentencepiece (from bpemb>=0.2.9->flair==0.4.2)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/95/7f357995d5eb1131aa2092096dca14a6fc1b1d2860bd99c22a612e1d1019/sentencepiece-0.1.82-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 59.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair==0.4.2) (1.3.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair==0.4.2) (0.7.1)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair==0.4.2) (7.2.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair==0.4.2) (19.1.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair==0.4.2) (1.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair==0.4.2) (41.0.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->flair==0.4.2) (0.21.3)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert>=0.6.1->flair==0.4.2) (1.9.199)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.4.2) (2.5.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.4.2) (2.4.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.4.2) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.4.2) (1.1.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.6/dist-packages (from deprecated>=1.2.4->flair==0.4.2) (1.11.2)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair==0.4.2) (3.8.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair==0.4.2) (2.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair==0.4.2) (0.16.0)\n",
            "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.4.0->flair==0.4.2) (2.49.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb>=0.2.9->flair==0.4.2) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb>=0.2.9->flair==0.4.2) (2019.6.16)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb>=0.2.9->flair==0.4.2) (2.8)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->flair==0.4.2) (0.13.2)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert>=0.6.1->flair==0.4.2) (0.2.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert>=0.6.1->flair==0.4.2) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.199 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert>=0.6.1->flair==0.4.2) (1.12.199)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt>=0.1.1->flair==0.4.2) (4.4.0)\n",
            "Requirement already satisfied: docutils<0.15,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.199->boto3->pytorch-pretrained-bert>=0.6.1->flair==0.4.2) (0.14)\n",
            "Building wheels for collected packages: flair\n",
            "  Building wheel for flair (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flair: filename=flair-0.4.2-cp36-none-any.whl size=99216 sha256=5f185e87e1a829f3a237760d816e7548e7237c0bbf0ef8775d4768f2a937b816\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-wih22pyh/wheels/7f/d7/5a/291cb0d8fe7f5f4db43d32dd7560c29dbc2a508cb1a8248138\n",
            "Successfully built flair\n",
            "Building wheels for collected packages: langdetect, mpld3, regex, sqlitedict, segtok\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.7-cp36-none-any.whl size=993460 sha256=4aabb004344c115a9a9a4bf85e539831b71a9539deed29eb549d3082ac5a3b25\n",
            "  Stored in directory: /root/.cache/pip/wheels/ec/0c/a9/1647275e7ef5014e7b83ff30105180e332867d65e7617ddafe\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpld3: filename=mpld3-0.3-cp36-none-any.whl size=116679 sha256=1b81115c33a234bf410305e4430492c13cf5a1cdb92828312700bfd5af4642a5\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/47/fb/8a64f89aecfe0059830479308ad42d62e898a3e3cefdf6ba28\n",
            "  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for regex: filename=regex-2019.6.8-cp36-cp36m-linux_x86_64.whl size=604157 sha256=d4c8de1d08c20fa715ffa53ec62e046afaead4a0f40d783cbe14ddc4b46124f6\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/e4/80/abf3b33ba89cf65cd262af8a22a5a999cc28fbfabea6b38473\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-1.6.0-cp36-none-any.whl size=14689 sha256=8e3c94b0092dc521daad8ace17a10a3c4774976c07307cf8e5c8f303eadcb912\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/57/d3/907c3ee02d35e66f674ad0106e61f06eeeb98f6ee66a6cc3fe\n",
            "  Building wheel for segtok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for segtok: filename=segtok-1.5.7-cp36-none-any.whl size=23257 sha256=0dc205b1259827f4f6586e8da6ab0141596cfaf672aa511e220f2bd66bfadded\n",
            "  Stored in directory: /root/.cache/pip/wheels/15/ee/a8/6112173f1386d33eebedb3f73429cfa41a4c3084556bcee254\n",
            "Successfully built langdetect mpld3 regex sqlitedict segtok\n",
            "Installing collected packages: sentencepiece, bpemb, langdetect, mpld3, regex, pytorch-pretrained-bert, sqlitedict, deprecated, segtok, flair\n",
            "Successfully installed bpemb-0.3.0 deprecated-1.2.6 flair-0.4.2 langdetect-1.0.7 mpld3-0.3 pytorch-pretrained-bert-0.6.2 regex-2019.6.8 segtok-1.5.7 sentencepiece-0.1.82 sqlitedict-1.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqQO-31b5OtG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "40fb82fc-7abf-44a8-a863-44d9f23e728d"
      },
      "source": [
        "!git clone https://github.com/anjapago/AnalyzeAccountability.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'AnalyzeAccountability'...\n",
            "remote: Enumerating objects: 160, done.\u001b[K\n",
            "remote: Counting objects: 100% (160/160), done.\u001b[K\n",
            "remote: Compressing objects: 100% (96/96), done.\u001b[K\n",
            "remote: Total 450 (delta 92), reused 115 (delta 60), pack-reused 290\u001b[K\n",
            "Receiving objects: 100% (450/450), 1.98 MiB | 3.98 MiB/s, done.\n",
            "Resolving deltas: 100% (247/247), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TRRdKwG7r_L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from AnalyzeAccountability.notebooks import load_data\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NWPG_CsrwpS",
        "colab_type": "code",
        "outputId": "016fd4a6-f0d1-4b6f-e91a-8558fb04ac43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAnF37T4255v",
        "colab_type": "text"
      },
      "source": [
        "## Prepare Data for Flair"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMXEPcFFFDRa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prep_flair_data(file_list, \n",
        "                    file_path = './drive/My Drive/Colab Notebooks/data/',\n",
        "                    flair_data_path = './drive/My Drive/Colab Notebooks/flair data/',\n",
        "                    ptest=0.25, merged = False):\n",
        "  \n",
        "  #load each data file, save in the output format for flair as sentences and exs\n",
        "  if not merged:\n",
        "    for file_name in file_list:\n",
        "      file_excerpts_df = load_data.load_xlsx_data([file_path+file_name], \n",
        "                                     max_sentences=5, as_sentences = False)\n",
        "      file_sentences_df = load_data.load_xlsx_data([file_path+file_name], \n",
        "                                         max_sentences=5, as_sentences = True)\n",
        "\n",
        "      ptest = 0.25\n",
        "\n",
        "      # sentences: save train.csv/test.csv/dev.csv\n",
        "      data_train, data_test_dev = train_test_split(file_sentences_df,\n",
        "                                               test_size=ptest, random_state=0)\n",
        "      data_test, data_dev = train_test_split(data_test_dev,\n",
        "                                             test_size=0.5, random_state=1)\n",
        "\n",
        "      event_name = file_name.split(' - ')[0]\n",
        "      outdir = flair_data_path+event_name+\"-sentences/\"\n",
        "      if not os.path.exists(outdir):\n",
        "          os.mkdir(outdir)\n",
        "\n",
        "      data_train.to_csv(outdir+\"train.csv\")\n",
        "      data_test.to_csv(outdir+\"test.csv\")\n",
        "      data_dev.to_csv(outdir+\"dev.csv\")\n",
        "\n",
        "      # excerpts: save train.csv/test.csv/dev.csv\n",
        "      data_train, data_test_dev = train_test_split(file_excerpts_df,\n",
        "                                               test_size=ptest, random_state=0)\n",
        "      data_test, data_dev = train_test_split(data_test_dev,\n",
        "                                             test_size=0.5, random_state=1)\n",
        "\n",
        "      flair_data_path = './drive/My Drive/Colab Notebooks/flair data/'\n",
        "      event_name = file_name.split(' - ')[0]\n",
        "      outdir = flair_data_path+event_name+\"-excerpts/\"\n",
        "      if not os.path.exists(outdir):\n",
        "          os.mkdir(outdir)\n",
        "\n",
        "\n",
        "      data_train.to_csv(outdir+\"train.csv\")\n",
        "      data_test.to_csv(outdir+\"test.csv\")\n",
        "      data_dev.to_csv(outdir+\"dev.csv\")\n",
        "  else:\n",
        "    file_names_list = [file_path+file_name for file_name in file_list]\n",
        "    file_excerpts_df = load_data.load_xlsx_data(file_names_list,\n",
        "                                                max_sentences=5,\n",
        "                                                as_sentences = False)\n",
        "    file_sentences_df = load_data.load_xlsx_data(file_names_list,\n",
        "                                                 max_sentences=5,\n",
        "                                                 as_sentences = True)\n",
        "\n",
        "    ptest = 0.25\n",
        "\n",
        "    # sentences: save train.csv/test.csv/dev.csv\n",
        "    data_train, data_test_dev = train_test_split(file_sentences_df,\n",
        "                                             test_size=ptest, random_state=0)\n",
        "    data_test, data_dev = train_test_split(data_test_dev,\n",
        "                                           test_size=0.5, random_state=1)\n",
        "\n",
        "    event_name = 'merged'\n",
        "    outdir = flair_data_path+event_name+\"-sentences/\"\n",
        "    if not os.path.exists(outdir):\n",
        "        os.mkdir(outdir)\n",
        "\n",
        "    data_train.to_csv(outdir+\"train.csv\")\n",
        "    data_test.to_csv(outdir+\"test.csv\")\n",
        "    data_dev.to_csv(outdir+\"dev.csv\")\n",
        "\n",
        "    # excerpts: save train.csv/test.csv/dev.csv\n",
        "    data_train, data_test_dev = train_test_split(file_excerpts_df,\n",
        "                                             test_size=ptest, random_state=0)\n",
        "    data_test, data_dev = train_test_split(data_test_dev,\n",
        "                                           test_size=0.5, random_state=1)\n",
        "\n",
        "    flair_data_path = './drive/My Drive/Colab Notebooks/flair data/'\n",
        "    outdir = flair_data_path+event_name+\"-excerpts/\"\n",
        "    if not os.path.exists(outdir):\n",
        "        os.mkdir(outdir)\n",
        "\n",
        "    data_train.to_csv(outdir+\"train.csv\")\n",
        "    data_test.to_csv(outdir+\"test.csv\")\n",
        "    data_dev.to_csv(outdir+\"dev.csv\")\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ctv3GqVHBih",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "outputId": "5187373c-22ff-4f5a-d792-3ce7d8deace8"
      },
      "source": [
        "# prepare files for all events for flair\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "file_names = os.listdir('drive/My Drive/Colab Notebooks/data')\n",
        "xlsx_files = [file_name for file_name in file_names if 'xlsx' in file_name]\n",
        "prep_flair_data(xlsx_files, \n",
        "                file_path = './drive/My Drive/Colab Notebooks/data/',\n",
        "                flair_data_path = './drive/My Drive/Colab Notebooks/flair data/',\n",
        "                ptest=0.25, merged = False)\n",
        "prep_flair_data(xlsx_files, \n",
        "                file_path = './drive/My Drive/Colab Notebooks/data/',\n",
        "                flair_data_path = './drive/My Drive/Colab Notebooks/flair data/',\n",
        "                ptest=0.25, merged = True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "num excerpts loaded: 903\n",
            "903903903\n",
            "num excerpts loaded: 903\n",
            "903903903\n",
            "num excerpts loaded: 1263\n",
            "126312631263\n",
            "num excerpts loaded: 1263\n",
            "126312631263\n",
            "num excerpts loaded: 1713\n",
            "171317131713\n",
            "num excerpts loaded: 1713\n",
            "171317131713\n",
            "num excerpts loaded: 1403\n",
            "140314031403\n",
            "num excerpts loaded: 1403\n",
            "140314031403\n",
            "num excerpts loaded: 2293\n",
            "229322932293\n",
            "num excerpts loaded: 2293\n",
            "229322932293\n",
            "num excerpts loaded: 5606\n",
            "560656065606\n",
            "num excerpts loaded: 5606\n",
            "560656065606\n",
            "num excerpts loaded: 8138\n",
            "813881388138\n",
            "num excerpts loaded: 8138\n",
            "813881388138\n",
            "num excerpts loaded: 21319\n",
            "213192131921319\n",
            "num excerpts loaded: 21319\n",
            "213192131921319\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_czk_PzoT6A",
        "colab_type": "text"
      },
      "source": [
        "## Load Corpus and Train Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTUZOnioEPqU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from flair.data import Corpus\n",
        "from flair.datasets import CSVClassificationCorpus\n",
        "#train a classifier\n",
        "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentRNNEmbeddings\n",
        "from flair.models import TextClassifier\n",
        "from flair.trainers import ModelTrainer\n",
        "from flair.visual.training_curves import Plotter\n",
        "\n",
        "def train_classifier(event_name):\n",
        "  # this is the folder in which train, test and dev files reside\n",
        "  flair_data_path = './drive/My Drive/Colab Notebooks/flair data/'\n",
        "  full_results_df = pd.DataFrame()\n",
        "  #event_name = 'Marysville'\n",
        "  for text_type in ['sentences', 'excerpts']:\n",
        "    text_type = 'sentences'\n",
        "    data_folder = flair_data_path+event_name+'-'+text_type\n",
        "\n",
        "    # column format indicating which columns hold the text and label(s)\n",
        "    column_name_map = {3: \"text\", 4: \"label_topic\"}\n",
        "\n",
        "    # 1. load corpus containing training, test and dev data and if CSV has a header, you can skip it\n",
        "    corpus: Corpus = CSVClassificationCorpus(data_folder, column_name_map,\n",
        "                                             test_file='test.csv',\n",
        "                                             dev_file='dev.csv',\n",
        "                                             train_file='train.csv',\n",
        "                                             skip_header=True)  \n",
        "      \n",
        "    # 2. create the label dictionary\n",
        "    label_dict = corpus.make_label_dictionary()\n",
        "\n",
        "    # 3. make a list of word embeddings\n",
        "    word_embeddings = [WordEmbeddings('glove')\n",
        "                       # FlairEmbeddings('news-forward'),\n",
        "                       # FlairEmbeddings('news-backward'),\n",
        "                       ]\n",
        "\n",
        "    # 4. initialize document embedding by passing list of word embeddings\n",
        "    # Can choose between many RNN types (GRU by default, to change use rnn_type parameter)\n",
        "    document_embeddings: DocumentRNNEmbeddings = DocumentRNNEmbeddings(word_embeddings,\n",
        "                                                                         hidden_size=512,\n",
        "                                                                         reproject_words=True,\n",
        "                                                                         reproject_words_dimension=256,\n",
        "                                                                         )\n",
        "\n",
        "    # 5. create the text classifier\n",
        "    classifier = TextClassifier(document_embeddings, label_dictionary=label_dict)\n",
        "\n",
        "    # 6. initialize the text classifier trainer\n",
        "    trainer = ModelTrainer(classifier, corpus)\n",
        "\n",
        "    # 7. start the training, set directory for outputs\n",
        "    wdir = './drive/My Drive/Colab Notebooks/flair-results/'+event_name+'-'+text_type\n",
        "    if not os.path.exists(wdir):\n",
        "        os.mkdir(wdir)\n",
        "    results = trainer.train(wdir,\n",
        "                  learning_rate=0.1,\n",
        "                  mini_batch_size=32,\n",
        "                  anneal_factor=0.5,\n",
        "                  patience=5,\n",
        "                  max_epochs=100,\n",
        "                  monitor_test = True)\n",
        "\n",
        "    # 8. plot training curves (optional)\n",
        "    # (requires monitor_test = True, and param_selection_mode = false)\n",
        "    plotter = Plotter()\n",
        "    plotter.plot_training_curves(wdir+'/loss.tsv')\n",
        "    plotter.plot_weights(wdir+'/weights.txt')\n",
        "    results_df =pd.DataFrame(results)\n",
        "    results_df.to_csv(wdir+'/train-history.csv')\n",
        "    #print(\"Test score: \"+str(results['test_score']))\n",
        "    final_scores_df = pd.DataFrame({'text_type':[text_type],\n",
        "                                    'event_name':[event_name],\n",
        "                                    'final_score':[results['test_score']]})\n",
        "    print(final_scores_df)\n",
        "    full_results_df = pd.concat([full_results_df, final_scores_df],\n",
        "                                ignore_index=True)\n",
        "  return full_results_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51rn5_l2FpoV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "flair_data_folders = [d.split('-')[0] for d in \n",
        "                      os.listdir( './drive/My Drive/Colab Notebooks/flair data/')\n",
        "                      if 'csv' not in d]\n",
        "event_names = set(flair_data_folders)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eutP5Y-DFb-X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "810dbcea-c7d4-4cb0-ffb7-30ef2df59a47"
      },
      "source": [
        "# run on all events:\n",
        "full_results_df = pd.DataFrame()\n",
        "for event_name in event_names:\n",
        "  results_df = train_classifier(event_name)\n",
        "  full_results_df = pd.concat([full_results_df, results_df], ignore_index=True)\n",
        "  full_results_df.to_csv('./drive/My Drive/Colab Notebooks/flair-results/flair-event-analysis.csv')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-08-03 18:19:14,383 Reading data from drive/My Drive/Colab Notebooks/flair data/Isla Vista-sentences\n",
            "2019-08-03 18:19:14,385 Train: drive/My Drive/Colab Notebooks/flair data/Isla Vista-sentences/train.csv\n",
            "2019-08-03 18:19:14,387 Dev: drive/My Drive/Colab Notebooks/flair data/Isla Vista-sentences/dev.csv\n",
            "2019-08-03 18:19:14,389 Test: drive/My Drive/Colab Notebooks/flair data/Isla Vista-sentences/test.csv\n",
            "2019-08-03 18:19:14,453 Computing label dictionary. Progress:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 9178/9178 [00:04<00:00, 2186.16it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-08-03 18:19:19,250 [b'0', b'1']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-08-03 18:19:20,819 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 18:19:20,821 Model: \"TextClassifier(\n",
            "  (document_embeddings): DocumentRNNEmbeddings(\n",
            "    (embeddings): StackedEmbeddings(\n",
            "      (list_embedding_0): WordEmbeddings('glove')\n",
            "    )\n",
            "    (word_reprojection_map): Linear(in_features=100, out_features=256, bias=True)\n",
            "    (rnn): GRU(256, 512)\n",
            "    (dropout): Dropout(p=0.5)\n",
            "  )\n",
            "  (decoder): Linear(in_features=512, out_features=2, bias=True)\n",
            "  (loss_function): CrossEntropyLoss()\n",
            ")\"\n",
            "2019-08-03 18:19:20,823 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 18:19:20,824 Corpus: \"Corpus: 9178 train + 1530 dev + 1530 test sentences\"\n",
            "2019-08-03 18:19:20,826 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 18:19:20,828 Parameters:\n",
            "2019-08-03 18:19:20,830  - learning_rate: \"0.1\"\n",
            "2019-08-03 18:19:20,832  - mini_batch_size: \"32\"\n",
            "2019-08-03 18:19:20,834  - patience: \"5\"\n",
            "2019-08-03 18:19:20,835  - anneal_factor: \"0.5\"\n",
            "2019-08-03 18:19:20,837  - max_epochs: \"100\"\n",
            "2019-08-03 18:19:20,838  - shuffle: \"True\"\n",
            "2019-08-03 18:19:20,840  - train_with_dev: \"False\"\n",
            "2019-08-03 18:19:20,841 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 18:19:20,843 Model training base path: \"drive/My Drive/Colab Notebooks/flair-results/Isla Vista-sentences\"\n",
            "2019-08-03 18:19:20,844 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 18:19:20,846 Device: cuda:0\n",
            "2019-08-03 18:19:20,848 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 18:19:20,849 Embeddings storage mode: cpu\n",
            "2019-08-03 18:19:20,857 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 18:19:21,742 epoch 1 - iter 0/287 - loss 0.72782308 throughput (samples/sec): 7917.32\n",
            "2019-08-03 18:19:25,143 epoch 1 - iter 28/287 - loss 0.60278170 throughput (samples/sec): 389.61\n",
            "2019-08-03 18:19:27,662 epoch 1 - iter 56/287 - loss 0.57284775 throughput (samples/sec): 402.50\n",
            "2019-08-03 18:19:30,168 epoch 1 - iter 84/287 - loss 0.55386997 throughput (samples/sec): 412.63\n",
            "2019-08-03 18:19:33,532 epoch 1 - iter 112/287 - loss 0.54323218 throughput (samples/sec): 406.38\n",
            "2019-08-03 18:19:38,039 epoch 1 - iter 140/287 - loss 0.53126318 throughput (samples/sec): 410.92\n",
            "2019-08-03 18:19:40,808 epoch 1 - iter 168/287 - loss 0.52381029 throughput (samples/sec): 395.81\n",
            "2019-08-03 18:19:43,302 epoch 1 - iter 196/287 - loss 0.52266483 throughput (samples/sec): 397.95\n",
            "2019-08-03 18:19:47,018 epoch 1 - iter 224/287 - loss 0.51829762 throughput (samples/sec): 413.92\n",
            "2019-08-03 18:19:49,527 epoch 1 - iter 252/287 - loss 0.51420535 throughput (samples/sec): 407.67\n",
            "2019-08-03 18:19:52,022 epoch 1 - iter 280/287 - loss 0.51165129 throughput (samples/sec): 404.17\n",
            "2019-08-03 18:19:52,805 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 18:19:52,813 EPOCH 1 done: loss 0.5088 - lr 0.1000\n",
            "2019-08-03 18:19:56,935 DEV : loss 0.4568660259246826 - score 0.1576\n",
            "2019-08-03 18:20:03,933 TEST : loss 0.4800116717815399 - score 0.1724\n",
            "2019-08-03 18:20:05,112 BAD EPOCHS (no improvement): 0\n",
            "2019-08-03 18:20:09,102 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 18:20:09,922 epoch 2 - iter 0/287 - loss 0.45335147 throughput (samples/sec): 8243.46\n",
            "2019-08-03 18:20:12,667 epoch 2 - iter 28/287 - loss 0.47717418 throughput (samples/sec): 365.57\n",
            "2019-08-03 18:20:16,826 epoch 2 - iter 56/287 - loss 0.48111965 throughput (samples/sec): 233.41\n",
            "2019-08-03 18:20:19,224 epoch 2 - iter 84/287 - loss 0.47429298 throughput (samples/sec): 422.90\n",
            "2019-08-03 18:20:21,679 epoch 2 - iter 112/287 - loss 0.47956984 throughput (samples/sec): 410.98\n",
            "2019-08-03 18:20:24,034 epoch 2 - iter 140/287 - loss 0.47867171 throughput (samples/sec): 428.11\n",
            "2019-08-03 18:20:27,537 epoch 2 - iter 168/287 - loss 0.47347789 throughput (samples/sec): 405.83\n",
            "2019-08-03 18:20:29,971 epoch 2 - iter 196/287 - loss 0.46938956 throughput (samples/sec): 412.13\n",
            "2019-08-03 18:20:32,423 epoch 2 - iter 224/287 - loss 0.46970374 throughput (samples/sec): 411.24\n",
            "2019-08-03 18:20:34,821 epoch 2 - iter 252/287 - loss 0.47096158 throughput (samples/sec): 422.27\n",
            "2019-08-03 18:20:38,435 epoch 2 - iter 280/287 - loss 0.47054217 throughput (samples/sec): 399.17\n",
            "2019-08-03 18:20:39,261 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 18:20:39,265 EPOCH 2 done: loss 0.4702 - lr 0.1000\n",
            "2019-08-03 18:20:43,348 DEV : loss 0.4595528244972229 - score 0.114\n",
            "2019-08-03 18:20:49,965 TEST : loss 0.48618918657302856 - score 0.1295\n",
            "2019-08-03 18:20:51,124 BAD EPOCHS (no improvement): 1\n",
            "2019-08-03 18:20:51,130 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 18:20:51,885 epoch 3 - iter 0/287 - loss 0.42135864 throughput (samples/sec): 7010.22\n",
            "2019-08-03 18:20:54,458 epoch 3 - iter 28/287 - loss 0.41841383 throughput (samples/sec): 395.24\n",
            "2019-08-03 18:20:57,006 epoch 3 - iter 56/287 - loss 0.43132938 throughput (samples/sec): 403.47\n",
            "2019-08-03 18:20:59,545 epoch 3 - iter 84/287 - loss 0.44585333 throughput (samples/sec): 406.05\n",
            "2019-08-03 18:21:03,580 epoch 3 - iter 112/287 - loss 0.45333179 throughput (samples/sec): 392.14\n",
            "2019-08-03 18:21:05,916 epoch 3 - iter 140/287 - loss 0.44922462 throughput (samples/sec): 430.73\n",
            "2019-08-03 18:21:08,394 epoch 3 - iter 168/287 - loss 0.44998194 throughput (samples/sec): 409.30\n",
            "2019-08-03 18:21:10,813 epoch 3 - iter 196/287 - loss 0.45097171 throughput (samples/sec): 416.30\n",
            "2019-08-03 18:21:14,523 epoch 3 - iter 224/287 - loss 0.44838892 throughput (samples/sec): 419.23\n",
            "2019-08-03 18:21:16,913 epoch 3 - iter 252/287 - loss 0.45088402 throughput (samples/sec): 423.78\n",
            "2019-08-03 18:21:19,255 epoch 3 - iter 280/287 - loss 0.44693289 throughput (samples/sec): 428.55\n",
            "2019-08-03 18:21:20,084 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 18:21:20,090 EPOCH 3 done: loss 0.4469 - lr 0.1000\n",
            "2019-08-03 18:21:25,645 DEV : loss 0.440489262342453 - score 0.0182\n",
            "2019-08-03 18:21:31,152 TEST : loss 0.4681653678417206 - score 0.0386\n",
            "2019-08-03 18:21:32,304 BAD EPOCHS (no improvement): 2\n",
            "2019-08-03 18:21:32,309 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 18:21:32,968 epoch 4 - iter 0/287 - loss 0.35700744 throughput (samples/sec): 8472.86\n",
            "2019-08-03 18:21:35,485 epoch 4 - iter 28/287 - loss 0.46971826 throughput (samples/sec): 404.53\n",
            "2019-08-03 18:21:39,610 epoch 4 - iter 56/287 - loss 0.44948243 throughput (samples/sec): 402.22\n",
            "2019-08-03 18:21:42,069 epoch 4 - iter 84/287 - loss 0.44107321 throughput (samples/sec): 412.39\n",
            "2019-08-03 18:21:44,511 epoch 4 - iter 112/287 - loss 0.43469761 throughput (samples/sec): 413.55\n",
            "2019-08-03 18:21:46,894 epoch 4 - iter 140/287 - loss 0.43824682 throughput (samples/sec): 418.31\n",
            "2019-08-03 18:21:50,568 epoch 4 - iter 168/287 - loss 0.43766117 throughput (samples/sec): 421.68\n",
            "2019-08-03 18:21:52,991 epoch 4 - iter 196/287 - loss 0.43646953 throughput (samples/sec): 418.98\n",
            "2019-08-03 18:21:55,465 epoch 4 - iter 224/287 - loss 0.43526724 throughput (samples/sec): 403.29\n",
            "2019-08-03 18:21:57,950 epoch 4 - iter 252/287 - loss 0.43571319 throughput (samples/sec): 407.06\n",
            "2019-08-03 18:22:01,740 epoch 4 - iter 280/287 - loss 0.43978425 throughput (samples/sec): 411.02\n",
            "2019-08-03 18:22:02,527 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 18:22:02,538 EPOCH 4 done: loss 0.4400 - lr 0.1000\n",
            "2019-08-03 18:22:06,709 DEV : loss 0.40211331844329834 - score 0.2911\n",
            "2019-08-03 18:22:12,090 TEST : loss 0.4260832965373993 - score 0.3291\n",
            "2019-08-03 18:22:14,272 BAD EPOCHS (no improvement): 0\n",
            "2019-08-03 18:22:18,207 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 18:22:19,018 epoch 5 - iter 0/287 - loss 0.26643005 throughput (samples/sec): 7256.97\n",
            "2019-08-03 18:22:21,720 epoch 5 - iter 28/287 - loss 0.42680201 throughput (samples/sec): 376.87\n",
            "2019-08-03 18:22:24,187 epoch 5 - iter 56/287 - loss 0.42826676 throughput (samples/sec): 416.29\n",
            "2019-08-03 18:22:26,814 epoch 5 - iter 84/287 - loss 0.42191546 throughput (samples/sec): 388.49\n",
            "2019-08-03 18:22:30,442 epoch 5 - iter 112/287 - loss 0.42258776 throughput (samples/sec): 393.55\n",
            "2019-08-03 18:22:32,811 epoch 5 - iter 140/287 - loss 0.42488454 throughput (samples/sec): 423.61\n",
            "2019-08-03 18:22:35,334 epoch 5 - iter 168/287 - loss 0.43136088 throughput (samples/sec): 400.64\n",
            "2019-08-03 18:22:37,821 epoch 5 - iter 196/287 - loss 0.43721350 throughput (samples/sec): 403.39\n",
            "2019-08-03 18:22:41,566 epoch 5 - iter 224/287 - loss 0.43320688 throughput (samples/sec): 421.94\n",
            "2019-08-03 18:22:44,015 epoch 5 - iter 252/287 - loss 0.43229178 throughput (samples/sec): 414.51\n",
            "2019-08-03 18:22:46,474 epoch 5 - iter 280/287 - loss 0.43201098 throughput (samples/sec): 413.21\n",
            "2019-08-03 18:22:47,292 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 18:22:47,302 EPOCH 5 done: loss 0.4326 - lr 0.1000\n",
            "2019-08-03 18:22:51,538 DEV : loss 0.4516262412071228 - score 0.2075\n",
            "2019-08-03 18:22:58,158 TEST : loss 0.49033695459365845 - score 0.2392\n",
            "2019-08-03 18:22:59,347 BAD EPOCHS (no improvement): 1\n",
            "2019-08-03 18:22:59,352 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 18:23:00,152 epoch 6 - iter 0/287 - loss 0.63090670 throughput (samples/sec): 8685.79\n",
            "2019-08-03 18:23:02,716 epoch 6 - iter 28/287 - loss 0.38426672 throughput (samples/sec): 394.97\n",
            "2019-08-03 18:23:06,698 epoch 6 - iter 56/287 - loss 0.41187054 throughput (samples/sec): 413.52\n",
            "2019-08-03 18:23:09,161 epoch 6 - iter 84/287 - loss 0.42023890 throughput (samples/sec): 410.50\n",
            "2019-08-03 18:23:11,529 epoch 6 - iter 112/287 - loss 0.42515102 throughput (samples/sec): 422.44\n",
            "2019-08-03 18:23:13,994 epoch 6 - iter 140/287 - loss 0.41900688 throughput (samples/sec): 409.45\n",
            "2019-08-03 18:23:17,408 epoch 6 - iter 168/287 - loss 0.41884456 throughput (samples/sec): 415.12\n",
            "2019-08-03 18:23:19,816 epoch 6 - iter 196/287 - loss 0.42161433 throughput (samples/sec): 414.32\n",
            "2019-08-03 18:23:22,273 epoch 6 - iter 224/287 - loss 0.41963621 throughput (samples/sec): 410.45\n",
            "2019-08-03 18:23:24,769 epoch 6 - iter 252/287 - loss 0.42290107 throughput (samples/sec): 404.65\n",
            "2019-08-03 18:23:28,624 epoch 6 - iter 280/287 - loss 0.42134079 throughput (samples/sec): 400.23\n",
            "2019-08-03 18:23:29,456 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 18:23:29,459 EPOCH 6 done: loss 0.4218 - lr 0.1000\n",
            "2019-08-03 18:23:33,589 DEV : loss 0.4965918958187103 - score 0.5787\n",
            "2019-08-03 18:23:40,396 TEST : loss 0.536162257194519 - score 0.5664\n",
            "2019-08-03 18:23:41,587 BAD EPOCHS (no improvement): 0\n",
            "2019-08-03 18:23:45,538 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 18:23:46,319 epoch 7 - iter 0/287 - loss 0.48568928 throughput (samples/sec): 8255.81\n",
            "2019-08-03 18:23:48,905 epoch 7 - iter 28/287 - loss 0.43663684 throughput (samples/sec): 397.85\n",
            "2019-08-03 18:23:51,488 epoch 7 - iter 56/287 - loss 0.42096113 throughput (samples/sec): 397.58\n",
            "2019-08-03 18:23:54,087 epoch 7 - iter 84/287 - loss 0.40763084 throughput (samples/sec): 393.99\n",
            "2019-08-03 18:23:58,074 epoch 7 - iter 112/287 - loss 0.41273568 throughput (samples/sec): 419.90\n",
            "2019-08-03 18:24:00,552 epoch 7 - iter 140/287 - loss 0.41568559 throughput (samples/sec): 410.45\n",
            "2019-08-03 18:24:03,044 epoch 7 - iter 168/287 - loss 0.41481446 throughput (samples/sec): 404.30\n",
            "2019-08-03 18:24:06,442 epoch 7 - iter 196/287 - loss 0.41643640 throughput (samples/sec): 415.04\n",
            "2019-08-03 18:24:08,784 epoch 7 - iter 224/287 - loss 0.41817984 throughput (samples/sec): 429.30\n",
            "2019-08-03 18:24:11,209 epoch 7 - iter 252/287 - loss 0.41940743 throughput (samples/sec): 417.34\n",
            "2019-08-03 18:24:13,561 epoch 7 - iter 280/287 - loss 0.41699438 throughput (samples/sec): 429.30\n",
            "2019-08-03 18:24:14,333 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 18:24:14,344 EPOCH 7 done: loss 0.4191 - lr 0.1000\n",
            "2019-08-03 18:24:20,177 DEV : loss 0.3898925483226776 - score 0.3529\n",
            "2019-08-03 18:24:25,727 TEST : loss 0.41774651408195496 - score 0.4184\n",
            "2019-08-03 18:24:26,927 BAD EPOCHS (no improvement): 1\n",
            "2019-08-03 18:24:26,934 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 18:24:27,668 epoch 8 - iter 0/287 - loss 0.40337530 throughput (samples/sec): 8974.11\n",
            "2019-08-03 18:24:30,157 epoch 8 - iter 28/287 - loss 0.38969516 throughput (samples/sec): 409.56\n",
            "2019-08-03 18:24:34,325 epoch 8 - iter 56/287 - loss 0.41315472 throughput (samples/sec): 401.89\n",
            "2019-08-03 18:24:36,885 epoch 8 - iter 84/287 - loss 0.41063895 throughput (samples/sec): 394.74\n",
            "2019-08-03 18:24:39,508 epoch 8 - iter 112/287 - loss 0.40525469 throughput (samples/sec): 400.94\n",
            "2019-08-03 18:24:43,473 epoch 8 - iter 140/287 - loss 0.40694064 throughput (samples/sec): 400.22\n",
            "2019-08-03 18:24:46,119 epoch 8 - iter 168/287 - loss 0.41954495 throughput (samples/sec): 392.91\n",
            "2019-08-03 18:24:48,576 epoch 8 - iter 196/287 - loss 0.42257045 throughput (samples/sec): 413.13\n",
            "2019-08-03 18:24:51,065 epoch 8 - iter 224/287 - loss 0.41707969 throughput (samples/sec): 401.15\n",
            "2019-08-03 18:24:54,880 epoch 8 - iter 252/287 - loss 0.41565673 throughput (samples/sec): 417.95\n",
            "2019-08-03 18:24:57,295 epoch 8 - iter 280/287 - loss 0.41276979 throughput (samples/sec): 414.33\n",
            "2019-08-03 18:24:58,063 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 18:24:58,065 EPOCH 8 done: loss 0.4127 - lr 0.1000\n",
            "2019-08-03 18:25:02,234 DEV : loss 0.39181947708129883 - score 0.4754\n",
            "2019-08-03 18:25:09,204 TEST : loss 0.4197007119655609 - score 0.5032\n",
            "2019-08-03 18:25:10,342 BAD EPOCHS (no improvement): 2\n",
            "2019-08-03 18:25:10,348 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 18:25:11,086 epoch 9 - iter 0/287 - loss 0.48900944 throughput (samples/sec): 9236.08\n",
            "2019-08-03 18:25:13,607 epoch 9 - iter 28/287 - loss 0.37108520 throughput (samples/sec): 412.53\n",
            "2019-08-03 18:25:16,296 epoch 9 - iter 56/287 - loss 0.38970726 throughput (samples/sec): 376.19\n",
            "2019-08-03 18:25:20,049 epoch 9 - iter 84/287 - loss 0.38818209 throughput (samples/sec): 422.85\n",
            "2019-08-03 18:25:22,518 epoch 9 - iter 112/287 - loss 0.39731266 throughput (samples/sec): 409.10\n",
            "2019-08-03 18:25:25,026 epoch 9 - iter 140/287 - loss 0.39388658 throughput (samples/sec): 403.60\n",
            "2019-08-03 18:25:27,520 epoch 9 - iter 168/287 - loss 0.39229270 throughput (samples/sec): 403.44\n",
            "2019-08-03 18:25:30,900 epoch 9 - iter 196/287 - loss 0.39113664 throughput (samples/sec): 413.79\n",
            "2019-08-03 18:25:33,312 epoch 9 - iter 224/287 - loss 0.39346594 throughput (samples/sec): 420.12\n",
            "2019-08-03 18:25:35,760 epoch 9 - iter 252/287 - loss 0.39920644 throughput (samples/sec): 409.77\n",
            "2019-08-03 18:25:38,209 epoch 9 - iter 280/287 - loss 0.40105115 throughput (samples/sec): 410.69\n",
            "2019-08-03 18:25:40,365 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 18:25:40,367 EPOCH 9 done: loss 0.4024 - lr 0.1000\n",
            "2019-08-03 18:25:44,529 DEV : loss 0.37744641304016113 - score 0.3686\n",
            "2019-08-03 18:25:49,947 TEST : loss 0.40656977891921997 - score 0.411\n",
            "2019-08-03 18:25:51,123 BAD EPOCHS (no improvement): 3\n",
            "2019-08-03 18:25:51,129 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 18:25:51,848 epoch 10 - iter 0/287 - loss 0.29971766 throughput (samples/sec): 8915.79\n",
            "2019-08-03 18:25:56,177 epoch 10 - iter 28/287 - loss 0.40894624 throughput (samples/sec): 377.24\n",
            "2019-08-03 18:25:58,694 epoch 10 - iter 56/287 - loss 0.40746605 throughput (samples/sec): 399.30\n",
            "2019-08-03 18:26:01,042 epoch 10 - iter 84/287 - loss 0.40395903 throughput (samples/sec): 427.94\n",
            "2019-08-03 18:26:03,476 epoch 10 - iter 112/287 - loss 0.39589211 throughput (samples/sec): 413.20\n",
            "2019-08-03 18:26:07,092 epoch 10 - iter 140/287 - loss 0.39810609 throughput (samples/sec): 396.87\n",
            "2019-08-03 18:26:09,523 epoch 10 - iter 168/287 - loss 0.40019713 throughput (samples/sec): 411.32\n",
            "2019-08-03 18:26:11,903 epoch 10 - iter 196/287 - loss 0.40063224 throughput (samples/sec): 424.27\n",
            "2019-08-03 18:26:15,645 epoch 10 - iter 224/287 - loss 0.39684601 throughput (samples/sec): 418.65\n",
            "2019-08-03 18:26:18,115 epoch 10 - iter 252/287 - loss 0.39772027 throughput (samples/sec): 411.93\n",
            "2019-08-03 18:26:20,541 epoch 10 - iter 280/287 - loss 0.39796372 throughput (samples/sec): 411.31\n",
            "2019-08-03 18:26:21,410 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 18:26:21,412 EPOCH 10 done: loss 0.3984 - lr 0.1000\n",
            "2019-08-03 18:26:26,736 DEV : loss 0.3717414140701294 - score 0.5233\n",
            "2019-08-03 18:26:32,331 TEST : loss 0.4121731221675873 - score 0.5125\n",
            "2019-08-03 18:26:33,523 BAD EPOCHS (no improvement): 4\n",
            "2019-08-03 18:26:33,529 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 18:26:34,286 epoch 11 - iter 0/287 - loss 0.38591677 throughput (samples/sec): 8267.69\n",
            "2019-08-03 18:26:36,896 epoch 11 - iter 28/287 - loss 0.37947100 throughput (samples/sec): 394.26\n",
            "2019-08-03 18:26:40,805 epoch 11 - iter 56/287 - loss 0.40209973 throughput (samples/sec): 401.76\n",
            "2019-08-03 18:26:43,214 epoch 11 - iter 84/287 - loss 0.38775409 throughput (samples/sec): 419.82\n",
            "2019-08-03 18:26:45,779 epoch 11 - iter 112/287 - loss 0.38805961 throughput (samples/sec): 396.82\n",
            "2019-08-03 18:26:48,316 epoch 11 - iter 140/287 - loss 0.39307648 throughput (samples/sec): 395.13\n",
            "2019-08-03 18:26:51,778 epoch 11 - iter 168/287 - loss 0.39271678 throughput (samples/sec): 408.86\n",
            "2019-08-03 18:26:54,195 epoch 11 - iter 196/287 - loss 0.39233661 throughput (samples/sec): 419.02\n",
            "2019-08-03 18:26:56,646 epoch 11 - iter 224/287 - loss 0.39344015 throughput (samples/sec): 411.62\n",
            "2019-08-03 18:26:59,104 epoch 11 - iter 252/287 - loss 0.39400990 throughput (samples/sec): 410.16\n",
            "2019-08-03 18:27:02,592 epoch 11 - iter 280/287 - loss 0.39396135 throughput (samples/sec): 409.43\n",
            "2019-08-03 18:27:03,396 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 18:27:03,398 EPOCH 11 done: loss 0.3923 - lr 0.1000\n",
            "2019-08-03 18:27:07,662 DEV : loss 0.3496048152446747 - score 0.5546\n",
            "2019-08-03 18:27:13,146 TEST : loss 0.38323506712913513 - score 0.5653\n",
            "2019-08-03 18:27:15,361 BAD EPOCHS (no improvement): 5\n",
            "2019-08-03 18:27:15,366 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 18:27:16,100 epoch 12 - iter 0/287 - loss 0.40281963 throughput (samples/sec): 7443.15\n",
            "2019-08-03 18:27:18,690 epoch 12 - iter 28/287 - loss 0.38136525 throughput (samples/sec): 396.33\n",
            "2019-08-03 18:27:21,287 epoch 12 - iter 56/287 - loss 0.39382095 throughput (samples/sec): 391.68\n",
            "2019-08-03 18:27:23,826 epoch 12 - iter 84/287 - loss 0.38489374 throughput (samples/sec): 404.66\n",
            "2019-08-03 18:27:27,555 epoch 12 - iter 112/287 - loss 0.38242700 throughput (samples/sec): 428.45\n",
            "2019-08-03 18:27:29,973 epoch 12 - iter 140/287 - loss 0.38963861 throughput (samples/sec): 417.47\n",
            "2019-08-03 18:27:32,437 epoch 12 - iter 168/287 - loss 0.39604613 throughput (samples/sec): 410.39\n",
            "2019-08-03 18:27:34,933 epoch 12 - iter 196/287 - loss 0.39447296 throughput (samples/sec): 407.04\n",
            "2019-08-03 18:27:38,660 epoch 12 - iter 224/287 - loss 0.39013428 throughput (samples/sec): 260.66\n",
            "2019-08-03 18:27:41,226 epoch 12 - iter 252/287 - loss 0.38974554 throughput (samples/sec): 392.48\n",
            "2019-08-03 18:27:43,732 epoch 12 - iter 280/287 - loss 0.39014012 throughput (samples/sec): 405.04\n",
            "2019-08-03 18:27:44,500 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 18:27:44,505 EPOCH 12 done: loss 0.3897 - lr 0.1000\n",
            "2019-08-03 18:27:50,560 DEV : loss 0.36295580863952637 - score 0.4701\n",
            "2019-08-03 18:27:56,052 TEST : loss 0.39807018637657166 - score 0.4799\n",
            "Epoch    11: reducing learning rate of group 0 to 5.0000e-02.\n",
            "2019-08-03 18:27:57,198 BAD EPOCHS (no improvement): 6\n",
            "2019-08-03 18:27:57,204 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 18:27:57,939 epoch 13 - iter 0/287 - loss 0.48014918 throughput (samples/sec): 9313.05\n",
            "2019-08-03 18:28:00,589 epoch 13 - iter 28/287 - loss 0.38031293 throughput (samples/sec): 386.28\n",
            "2019-08-03 18:28:03,162 epoch 13 - iter 56/287 - loss 0.35494301 throughput (samples/sec): 397.34\n",
            "2019-08-03 18:28:06,949 epoch 13 - iter 84/287 - loss 0.35820621 throughput (samples/sec): 409.51\n",
            "2019-08-03 18:28:09,418 epoch 13 - iter 112/287 - loss 0.35447397 throughput (samples/sec): 413.77\n",
            "2019-08-03 18:28:11,889 epoch 13 - iter 140/287 - loss 0.35515334 throughput (samples/sec): 410.81\n",
            "2019-08-03 18:28:15,377 epoch 13 - iter 168/287 - loss 0.35958234 throughput (samples/sec): 406.35\n",
            "2019-08-03 18:28:17,791 epoch 13 - iter 196/287 - loss 0.36383986 throughput (samples/sec): 421.60\n",
            "2019-08-03 18:28:20,197 epoch 13 - iter 224/287 - loss 0.36355221 throughput (samples/sec): 417.88\n",
            "2019-08-03 18:28:22,666 epoch 13 - iter 252/287 - loss 0.36227911 throughput (samples/sec): 403.74\n",
            "2019-08-03 18:28:26,276 epoch 13 - iter 280/287 - loss 0.36216274 throughput (samples/sec): 423.21\n",
            "2019-08-03 18:28:27,120 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 18:28:27,122 EPOCH 13 done: loss 0.3635 - lr 0.0500\n",
            "2019-08-03 18:28:31,300 DEV : loss 0.3586616516113281 - score 0.3919\n",
            "2019-08-03 18:28:38,418 TEST : loss 0.3901326358318329 - score 0.4511\n",
            "2019-08-03 18:28:39,593 BAD EPOCHS (no improvement): 1\n",
            "2019-08-03 18:28:39,598 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 18:28:40,369 epoch 14 - iter 0/287 - loss 0.37849778 throughput (samples/sec): 6655.33\n",
            "2019-08-03 18:28:43,007 epoch 14 - iter 28/287 - loss 0.37991744 throughput (samples/sec): 395.66\n",
            "2019-08-03 18:28:45,627 epoch 14 - iter 56/287 - loss 0.36565393 throughput (samples/sec): 392.30\n",
            "2019-08-03 18:28:48,136 epoch 14 - iter 84/287 - loss 0.36152942 throughput (samples/sec): 404.09\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fmckn3T3MJWW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3936c1e1-9d88-4fa5-db1c-39b451d33b08"
      },
      "source": [
        "# for each event, create a flair corpus object to prepare to train classifier\n",
        "from flair.data import Corpus\n",
        "from flair.datasets import CSVClassificationCorpus\n",
        "\n",
        "# this is the folder in which train, test and dev files reside\n",
        "flair_data_path = './drive/My Drive/Colab Notebooks/flair data/'\n",
        "event_name = 'Marysville'\n",
        "text_type = 'sentences'\n",
        "data_folder = flair_data_path+event_name+'-'+text_type\n",
        "\n",
        "# column format indicating which columns hold the text and label(s)\n",
        "column_name_map = {3: \"text\", 4: \"label_topic\"}\n",
        "\n",
        "# 1. load corpus containing training, test and dev data and if CSV has a header, you can skip it\n",
        "corpus: Corpus = CSVClassificationCorpus(data_folder, column_name_map,\n",
        "                                         test_file='test.csv',\n",
        "                                         dev_file='dev.csv',\n",
        "                                         train_file='train.csv',\n",
        "                                         skip_header=True) \n",
        "#train a classifier\n",
        "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentRNNEmbeddings\n",
        "from flair.models import TextClassifier\n",
        "from flair.trainers import ModelTrainer\n",
        "\n",
        "# 2. create the label dictionary\n",
        "label_dict = corpus.make_label_dictionary()\n",
        "\n",
        "# 3. make a list of word embeddings\n",
        "word_embeddings = [WordEmbeddings('glove')\n",
        "                   # FlairEmbeddings('news-forward'),\n",
        "                   # FlairEmbeddings('news-backward'),\n",
        "                   ]\n",
        "\n",
        "# 4. initialize document embedding by passing list of word embeddings\n",
        "# Can choose between many RNN types (GRU by default, to change use rnn_type parameter)\n",
        "document_embeddings: DocumentRNNEmbeddings = DocumentRNNEmbeddings(word_embeddings,\n",
        "                                                                     hidden_size=512,\n",
        "                                                                     reproject_words=True,\n",
        "                                                                     reproject_words_dimension=256,\n",
        "                                                                     )\n",
        "\n",
        "# 5. create the text classifier\n",
        "classifier = TextClassifier(document_embeddings, label_dictionary=label_dict)\n",
        "\n",
        "# 6. initialize the text classifier trainer\n",
        "trainer = ModelTrainer(classifier, corpus)\n",
        "\n",
        "# 7. start the training\n",
        "wdir = './drive/My Drive/Colab Notebooks/flair-results'\n",
        "if not os.path.exists(wdir):\n",
        "    os.mkdir(wdir)\n",
        "results = trainer.train(wdir,\n",
        "              learning_rate=0.1,\n",
        "              mini_batch_size=32,\n",
        "              anneal_factor=0.5,\n",
        "              patience=5,\n",
        "              max_epochs=100,\n",
        "              monitor_test = True)\n",
        "\n",
        "# 8. plot training curves (optional)\n",
        "# (requires monitor_test = True, and param_selection_mode = false)\n",
        "from flair.visual.training_curves import Plotter\n",
        "plotter = Plotter()\n",
        "plotter.plot_training_curves(wdir+'/loss.tsv')\n",
        "plotter.plot_weights(wdir+'/weights.txt')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-08-03 01:27:34,576 Computing label dictionary. Progress:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3763/3763 [00:01<00:00, 2369.99it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-08-03 01:27:36,586 [b'1', b'0']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-08-03 01:27:38,245 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:27:38,247 Model: \"TextClassifier(\n",
            "  (document_embeddings): DocumentRNNEmbeddings(\n",
            "    (embeddings): StackedEmbeddings(\n",
            "      (list_embedding_0): WordEmbeddings('glove')\n",
            "    )\n",
            "    (word_reprojection_map): Linear(in_features=100, out_features=256, bias=True)\n",
            "    (rnn): GRU(256, 512)\n",
            "    (dropout): Dropout(p=0.5)\n",
            "  )\n",
            "  (decoder): Linear(in_features=512, out_features=2, bias=True)\n",
            "  (loss_function): CrossEntropyLoss()\n",
            ")\"\n",
            "2019-08-03 01:27:38,250 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:27:38,251 Corpus: \"Corpus: 3763 train + 628 dev + 627 test sentences\"\n",
            "2019-08-03 01:27:38,253 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:27:38,254 Parameters:\n",
            "2019-08-03 01:27:38,255  - learning_rate: \"0.1\"\n",
            "2019-08-03 01:27:38,256  - mini_batch_size: \"32\"\n",
            "2019-08-03 01:27:38,257  - patience: \"5\"\n",
            "2019-08-03 01:27:38,259  - anneal_factor: \"0.5\"\n",
            "2019-08-03 01:27:38,260  - max_epochs: \"100\"\n",
            "2019-08-03 01:27:38,262  - shuffle: \"True\"\n",
            "2019-08-03 01:27:38,263  - train_with_dev: \"False\"\n",
            "2019-08-03 01:27:38,264 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:27:38,265 Model training base path: \"drive/My Drive/Colab Notebooks/flair-results\"\n",
            "2019-08-03 01:27:38,267 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:27:38,268 Device: cuda:0\n",
            "2019-08-03 01:27:38,269 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:27:38,271 Embedding storage mode: cpu\n",
            "2019-08-03 01:27:38,280 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:27:38,742 epoch 1 - iter 0/118 - loss 0.65941858\n",
            "2019-08-03 01:27:39,656 epoch 1 - iter 11/118 - loss 0.34520816\n",
            "2019-08-03 01:27:40,522 epoch 1 - iter 22/118 - loss 0.33090048\n",
            "2019-08-03 01:27:41,372 epoch 1 - iter 33/118 - loss 0.34571749\n",
            "2019-08-03 01:27:42,209 epoch 1 - iter 44/118 - loss 0.33796737\n",
            "2019-08-03 01:27:43,042 epoch 1 - iter 55/118 - loss 0.34618244\n",
            "2019-08-03 01:27:43,973 epoch 1 - iter 66/118 - loss 0.33481310\n",
            "2019-08-03 01:27:44,843 epoch 1 - iter 77/118 - loss 0.32993318\n",
            "2019-08-03 01:27:45,805 epoch 1 - iter 88/118 - loss 0.32941069\n",
            "2019-08-03 01:27:46,680 epoch 1 - iter 99/118 - loss 0.32307725\n",
            "2019-08-03 01:27:47,522 epoch 1 - iter 110/118 - loss 0.32804832\n",
            "2019-08-03 01:27:48,789 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:27:48,793 EPOCH 1 done: loss 0.3269 - lr 0.1000\n",
            "2019-08-03 01:27:50,135 DEV : loss 0.29871174693107605 - score 0.2438\n",
            "2019-08-03 01:27:51,841 TEST : loss 0.28092485666275024 - score 0.1715\n",
            "2019-08-03 01:27:52,240 BAD EPOCHS (no improvement): 0\n",
            "2019-08-03 01:27:56,313 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:27:56,766 epoch 2 - iter 0/118 - loss 0.04929680\n",
            "2019-08-03 01:27:58,194 epoch 2 - iter 11/118 - loss 0.34076868\n",
            "2019-08-03 01:27:59,081 epoch 2 - iter 22/118 - loss 0.33068923\n",
            "2019-08-03 01:27:59,961 epoch 2 - iter 33/118 - loss 0.30593859\n",
            "2019-08-03 01:28:00,946 epoch 2 - iter 44/118 - loss 0.30060219\n",
            "2019-08-03 01:28:01,894 epoch 2 - iter 55/118 - loss 0.29451185\n",
            "2019-08-03 01:28:03,169 epoch 2 - iter 66/118 - loss 0.30205275\n",
            "2019-08-03 01:28:04,127 epoch 2 - iter 77/118 - loss 0.30349749\n",
            "2019-08-03 01:28:05,036 epoch 2 - iter 88/118 - loss 0.30021129\n",
            "2019-08-03 01:28:06,020 epoch 2 - iter 99/118 - loss 0.30354379\n",
            "2019-08-03 01:28:06,913 epoch 2 - iter 110/118 - loss 0.30162912\n",
            "2019-08-03 01:28:07,616 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:28:07,618 EPOCH 2 done: loss 0.3059 - lr 0.1000\n",
            "2019-08-03 01:28:09,649 DEV : loss 0.2833748161792755 - score 0.3479\n",
            "2019-08-03 01:28:11,415 TEST : loss 0.281809002161026 - score 0.2962\n",
            "2019-08-03 01:28:11,834 BAD EPOCHS (no improvement): 0\n",
            "2019-08-03 01:28:15,624 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:28:16,161 epoch 3 - iter 0/118 - loss 0.30377945\n",
            "2019-08-03 01:28:17,146 epoch 3 - iter 11/118 - loss 0.24329626\n",
            "2019-08-03 01:28:18,500 epoch 3 - iter 22/118 - loss 0.30229070\n",
            "2019-08-03 01:28:19,429 epoch 3 - iter 33/118 - loss 0.29239045\n",
            "2019-08-03 01:28:20,301 epoch 3 - iter 44/118 - loss 0.30015712\n",
            "2019-08-03 01:28:21,247 epoch 3 - iter 55/118 - loss 0.30622824\n",
            "2019-08-03 01:28:22,126 epoch 3 - iter 66/118 - loss 0.29854143\n",
            "2019-08-03 01:28:23,616 epoch 3 - iter 77/118 - loss 0.30042215\n",
            "2019-08-03 01:28:24,714 epoch 3 - iter 88/118 - loss 0.29996267\n",
            "2019-08-03 01:28:25,707 epoch 3 - iter 99/118 - loss 0.29722529\n",
            "2019-08-03 01:28:26,685 epoch 3 - iter 110/118 - loss 0.29694354\n",
            "2019-08-03 01:28:27,445 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:28:27,451 EPOCH 3 done: loss 0.2952 - lr 0.1000\n",
            "2019-08-03 01:28:29,373 DEV : loss 0.2639007866382599 - score 0.4124\n",
            "2019-08-03 01:28:31,077 TEST : loss 0.25967690348625183 - score 0.3256\n",
            "2019-08-03 01:28:31,457 BAD EPOCHS (no improvement): 0\n",
            "2019-08-03 01:28:35,523 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:28:36,074 epoch 4 - iter 0/118 - loss 0.41286671\n",
            "2019-08-03 01:28:37,228 epoch 4 - iter 11/118 - loss 0.28385530\n",
            "2019-08-03 01:28:38,964 epoch 4 - iter 22/118 - loss 0.29069029\n",
            "2019-08-03 01:28:40,067 epoch 4 - iter 33/118 - loss 0.28894912\n",
            "2019-08-03 01:28:41,121 epoch 4 - iter 44/118 - loss 0.29459901\n",
            "2019-08-03 01:28:42,168 epoch 4 - iter 55/118 - loss 0.28357823\n",
            "2019-08-03 01:28:43,175 epoch 4 - iter 66/118 - loss 0.28591648\n",
            "2019-08-03 01:28:44,065 epoch 4 - iter 77/118 - loss 0.29016313\n",
            "2019-08-03 01:28:45,394 epoch 4 - iter 88/118 - loss 0.29008855\n",
            "2019-08-03 01:28:46,367 epoch 4 - iter 99/118 - loss 0.28983598\n",
            "2019-08-03 01:28:47,278 epoch 4 - iter 110/118 - loss 0.28454199\n",
            "2019-08-03 01:28:48,024 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:28:48,035 EPOCH 4 done: loss 0.2843 - lr 0.1000\n",
            "2019-08-03 01:28:49,517 DEV : loss 0.2696860134601593 - score 0.2438\n",
            "2019-08-03 01:28:51,951 TEST : loss 0.25881874561309814 - score 0.2\n",
            "2019-08-03 01:28:52,346 BAD EPOCHS (no improvement): 1\n",
            "2019-08-03 01:28:52,351 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:28:52,862 epoch 5 - iter 0/118 - loss 0.28377900\n",
            "2019-08-03 01:28:53,740 epoch 5 - iter 11/118 - loss 0.29748112\n",
            "2019-08-03 01:28:54,717 epoch 5 - iter 22/118 - loss 0.28002658\n",
            "2019-08-03 01:28:55,642 epoch 5 - iter 33/118 - loss 0.27508251\n",
            "2019-08-03 01:28:56,988 epoch 5 - iter 44/118 - loss 0.27455528\n",
            "2019-08-03 01:28:57,839 epoch 5 - iter 55/118 - loss 0.27317769\n",
            "2019-08-03 01:28:58,720 epoch 5 - iter 66/118 - loss 0.26309649\n",
            "2019-08-03 01:28:59,716 epoch 5 - iter 77/118 - loss 0.26368221\n",
            "2019-08-03 01:29:00,586 epoch 5 - iter 88/118 - loss 0.26788035\n",
            "2019-08-03 01:29:01,585 epoch 5 - iter 99/118 - loss 0.26896617\n",
            "2019-08-03 01:29:03,082 epoch 5 - iter 110/118 - loss 0.27084463\n",
            "2019-08-03 01:29:03,792 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:29:03,794 EPOCH 5 done: loss 0.2732 - lr 0.1000\n",
            "2019-08-03 01:29:05,212 DEV : loss 0.3082495629787445 - score 0.585\n",
            "2019-08-03 01:29:07,227 TEST : loss 0.3097357451915741 - score 0.448\n",
            "2019-08-03 01:29:07,617 BAD EPOCHS (no improvement): 0\n",
            "2019-08-03 01:29:11,671 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:29:12,078 epoch 6 - iter 0/118 - loss 0.25787950\n",
            "2019-08-03 01:29:13,504 epoch 6 - iter 11/118 - loss 0.26197813\n",
            "2019-08-03 01:29:14,526 epoch 6 - iter 22/118 - loss 0.25869587\n",
            "2019-08-03 01:29:15,474 epoch 6 - iter 33/118 - loss 0.25774879\n",
            "2019-08-03 01:29:16,365 epoch 6 - iter 44/118 - loss 0.26285099\n",
            "2019-08-03 01:29:17,252 epoch 6 - iter 55/118 - loss 0.26121782\n",
            "2019-08-03 01:29:18,595 epoch 6 - iter 66/118 - loss 0.27318232\n",
            "2019-08-03 01:29:19,525 epoch 6 - iter 77/118 - loss 0.27597307\n",
            "2019-08-03 01:29:20,428 epoch 6 - iter 88/118 - loss 0.27592071\n",
            "2019-08-03 01:29:21,295 epoch 6 - iter 99/118 - loss 0.27846441\n",
            "2019-08-03 01:29:22,290 epoch 6 - iter 110/118 - loss 0.27855404\n",
            "2019-08-03 01:29:23,024 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:29:23,025 EPOCH 6 done: loss 0.2763 - lr 0.1000\n",
            "2019-08-03 01:29:24,908 DEV : loss 0.25348368287086487 - score 0.3219\n",
            "2019-08-03 01:29:26,745 TEST : loss 0.24653260409832 - score 0.2973\n",
            "2019-08-03 01:29:27,163 BAD EPOCHS (no improvement): 1\n",
            "2019-08-03 01:29:27,168 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:29:27,663 epoch 7 - iter 0/118 - loss 0.24209270\n",
            "2019-08-03 01:29:28,700 epoch 7 - iter 11/118 - loss 0.26562521\n",
            "2019-08-03 01:29:30,394 epoch 7 - iter 22/118 - loss 0.25782358\n",
            "2019-08-03 01:29:31,371 epoch 7 - iter 33/118 - loss 0.26445898\n",
            "2019-08-03 01:29:32,222 epoch 7 - iter 44/118 - loss 0.27217946\n",
            "2019-08-03 01:29:33,080 epoch 7 - iter 55/118 - loss 0.27428705\n",
            "2019-08-03 01:29:33,955 epoch 7 - iter 66/118 - loss 0.26904465\n",
            "2019-08-03 01:29:35,234 epoch 7 - iter 77/118 - loss 0.27113759\n",
            "2019-08-03 01:29:36,169 epoch 7 - iter 88/118 - loss 0.27145316\n",
            "2019-08-03 01:29:37,046 epoch 7 - iter 99/118 - loss 0.27080072\n",
            "2019-08-03 01:29:37,933 epoch 7 - iter 110/118 - loss 0.26753284\n",
            "2019-08-03 01:29:38,623 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:29:38,629 EPOCH 7 done: loss 0.2708 - lr 0.1000\n",
            "2019-08-03 01:29:40,095 DEV : loss 0.24080374836921692 - score 0.5094\n",
            "2019-08-03 01:29:43,506 TEST : loss 0.24204878509044647 - score 0.3571\n",
            "2019-08-03 01:29:43,891 BAD EPOCHS (no improvement): 2\n",
            "2019-08-03 01:29:43,896 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:29:44,310 epoch 8 - iter 0/118 - loss 0.20694910\n",
            "2019-08-03 01:29:45,263 epoch 8 - iter 11/118 - loss 0.28205379\n",
            "2019-08-03 01:29:46,189 epoch 8 - iter 22/118 - loss 0.26589037\n",
            "2019-08-03 01:29:47,480 epoch 8 - iter 33/118 - loss 0.25818471\n",
            "2019-08-03 01:29:48,338 epoch 8 - iter 44/118 - loss 0.25669466\n",
            "2019-08-03 01:29:49,242 epoch 8 - iter 55/118 - loss 0.24959416\n",
            "2019-08-03 01:29:50,081 epoch 8 - iter 66/118 - loss 0.25507024\n",
            "2019-08-03 01:29:50,950 epoch 8 - iter 77/118 - loss 0.25882459\n",
            "2019-08-03 01:29:52,193 epoch 8 - iter 88/118 - loss 0.25844601\n",
            "2019-08-03 01:29:53,053 epoch 8 - iter 99/118 - loss 0.25759419\n",
            "2019-08-03 01:29:53,946 epoch 8 - iter 110/118 - loss 0.25845509\n",
            "2019-08-03 01:29:54,655 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:29:54,656 EPOCH 8 done: loss 0.2627 - lr 0.1000\n",
            "2019-08-03 01:29:56,055 DEV : loss 0.24167580902576447 - score 0.4211\n",
            "2019-08-03 01:29:58,134 TEST : loss 0.23524048924446106 - score 0.3171\n",
            "2019-08-03 01:29:58,557 BAD EPOCHS (no improvement): 3\n",
            "2019-08-03 01:29:58,563 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:29:59,104 epoch 9 - iter 0/118 - loss 0.27607471\n",
            "2019-08-03 01:30:00,136 epoch 9 - iter 11/118 - loss 0.30970878\n",
            "2019-08-03 01:30:00,995 epoch 9 - iter 22/118 - loss 0.27996186\n",
            "2019-08-03 01:30:01,940 epoch 9 - iter 33/118 - loss 0.25144280\n",
            "2019-08-03 01:30:03,392 epoch 9 - iter 44/118 - loss 0.24990014\n",
            "2019-08-03 01:30:04,333 epoch 9 - iter 55/118 - loss 0.25607782\n",
            "2019-08-03 01:30:05,351 epoch 9 - iter 66/118 - loss 0.26509072\n",
            "2019-08-03 01:30:06,228 epoch 9 - iter 77/118 - loss 0.26352718\n",
            "2019-08-03 01:30:07,119 epoch 9 - iter 88/118 - loss 0.26338061\n",
            "2019-08-03 01:30:08,371 epoch 9 - iter 99/118 - loss 0.26240656\n",
            "2019-08-03 01:30:09,305 epoch 9 - iter 110/118 - loss 0.26009313\n",
            "2019-08-03 01:30:10,068 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:30:10,071 EPOCH 9 done: loss 0.2599 - lr 0.1000\n",
            "2019-08-03 01:30:11,464 DEV : loss 0.2506946325302124 - score 0.265\n",
            "2019-08-03 01:30:14,133 TEST : loss 0.24455025792121887 - score 0.174\n",
            "2019-08-03 01:30:14,550 BAD EPOCHS (no improvement): 4\n",
            "2019-08-03 01:30:14,555 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:30:15,094 epoch 10 - iter 0/118 - loss 0.22705162\n",
            "2019-08-03 01:30:16,043 epoch 10 - iter 11/118 - loss 0.24725519\n",
            "2019-08-03 01:30:17,075 epoch 10 - iter 22/118 - loss 0.26163896\n",
            "2019-08-03 01:30:18,011 epoch 10 - iter 33/118 - loss 0.26476124\n",
            "2019-08-03 01:30:18,973 epoch 10 - iter 44/118 - loss 0.26282582\n",
            "2019-08-03 01:30:20,289 epoch 10 - iter 55/118 - loss 0.25920781\n",
            "2019-08-03 01:30:21,232 epoch 10 - iter 66/118 - loss 0.26552637\n",
            "2019-08-03 01:30:22,231 epoch 10 - iter 77/118 - loss 0.26434820\n",
            "2019-08-03 01:30:23,173 epoch 10 - iter 88/118 - loss 0.26121270\n",
            "2019-08-03 01:30:24,112 epoch 10 - iter 99/118 - loss 0.25856063\n",
            "2019-08-03 01:30:25,542 epoch 10 - iter 110/118 - loss 0.25560251\n",
            "2019-08-03 01:30:26,236 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:30:26,239 EPOCH 10 done: loss 0.2531 - lr 0.1000\n",
            "2019-08-03 01:30:27,672 DEV : loss 0.2390485256910324 - score 0.341\n",
            "2019-08-03 01:30:29,625 TEST : loss 0.23370890319347382 - score 0.2501\n",
            "2019-08-03 01:30:30,046 BAD EPOCHS (no improvement): 5\n",
            "2019-08-03 01:30:30,051 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:30:30,972 epoch 11 - iter 0/118 - loss 0.27386779\n",
            "2019-08-03 01:30:31,858 epoch 11 - iter 11/118 - loss 0.22134019\n",
            "2019-08-03 01:30:32,698 epoch 11 - iter 22/118 - loss 0.23787750\n",
            "2019-08-03 01:30:33,570 epoch 11 - iter 33/118 - loss 0.23984021\n",
            "2019-08-03 01:30:34,534 epoch 11 - iter 44/118 - loss 0.23810519\n",
            "2019-08-03 01:30:35,514 epoch 11 - iter 55/118 - loss 0.22963108\n",
            "2019-08-03 01:30:36,926 epoch 11 - iter 66/118 - loss 0.23141891\n",
            "2019-08-03 01:30:37,838 epoch 11 - iter 77/118 - loss 0.24081799\n",
            "2019-08-03 01:30:38,736 epoch 11 - iter 88/118 - loss 0.24728757\n",
            "2019-08-03 01:30:39,595 epoch 11 - iter 99/118 - loss 0.24411530\n",
            "2019-08-03 01:30:40,463 epoch 11 - iter 110/118 - loss 0.24693626\n",
            "2019-08-03 01:30:41,161 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:30:41,163 EPOCH 11 done: loss 0.2457 - lr 0.1000\n",
            "2019-08-03 01:30:43,260 DEV : loss 0.22401420772075653 - score 0.6179\n",
            "2019-08-03 01:30:45,254 TEST : loss 0.21815145015716553 - score 0.4583\n",
            "2019-08-03 01:30:45,643 BAD EPOCHS (no improvement): 0\n",
            "2019-08-03 01:30:49,388 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:30:49,908 epoch 12 - iter 0/118 - loss 0.23392409\n",
            "2019-08-03 01:30:50,863 epoch 12 - iter 11/118 - loss 0.22662154\n",
            "2019-08-03 01:30:51,770 epoch 12 - iter 22/118 - loss 0.23233498\n",
            "2019-08-03 01:30:53,234 epoch 12 - iter 33/118 - loss 0.23975236\n",
            "2019-08-03 01:30:54,187 epoch 12 - iter 44/118 - loss 0.24305775\n",
            "2019-08-03 01:30:55,122 epoch 12 - iter 55/118 - loss 0.24001413\n",
            "2019-08-03 01:30:56,056 epoch 12 - iter 66/118 - loss 0.25582540\n",
            "2019-08-03 01:30:57,077 epoch 12 - iter 77/118 - loss 0.25150051\n",
            "2019-08-03 01:30:58,544 epoch 12 - iter 88/118 - loss 0.24875092\n",
            "2019-08-03 01:30:59,429 epoch 12 - iter 99/118 - loss 0.25256049\n",
            "2019-08-03 01:31:00,330 epoch 12 - iter 110/118 - loss 0.25166334\n",
            "2019-08-03 01:31:01,021 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:31:01,028 EPOCH 12 done: loss 0.2492 - lr 0.1000\n",
            "2019-08-03 01:31:02,385 DEV : loss 0.245111346244812 - score 0.6082\n",
            "2019-08-03 01:31:04,844 TEST : loss 0.23711097240447998 - score 0.4857\n",
            "2019-08-03 01:31:05,233 BAD EPOCHS (no improvement): 1\n",
            "2019-08-03 01:31:05,239 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:31:05,659 epoch 13 - iter 0/118 - loss 0.25285050\n",
            "2019-08-03 01:31:06,617 epoch 13 - iter 11/118 - loss 0.29036616\n",
            "2019-08-03 01:31:07,534 epoch 13 - iter 22/118 - loss 0.25580516\n",
            "2019-08-03 01:31:08,461 epoch 13 - iter 33/118 - loss 0.25227520\n",
            "2019-08-03 01:31:09,794 epoch 13 - iter 44/118 - loss 0.25640576\n",
            "2019-08-03 01:31:10,636 epoch 13 - iter 55/118 - loss 0.25608379\n",
            "2019-08-03 01:31:11,488 epoch 13 - iter 66/118 - loss 0.25823265\n",
            "2019-08-03 01:31:12,505 epoch 13 - iter 77/118 - loss 0.25493602\n",
            "2019-08-03 01:31:13,433 epoch 13 - iter 88/118 - loss 0.25097751\n",
            "2019-08-03 01:31:14,675 epoch 13 - iter 99/118 - loss 0.24809717\n",
            "2019-08-03 01:31:15,694 epoch 13 - iter 110/118 - loss 0.24311488\n",
            "2019-08-03 01:31:16,357 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:31:16,360 EPOCH 13 done: loss 0.2404 - lr 0.1000\n",
            "2019-08-03 01:31:17,826 DEV : loss 0.23296725749969482 - score 0.341\n",
            "2019-08-03 01:31:20,403 TEST : loss 0.233622744679451 - score 0.2253\n",
            "2019-08-03 01:31:20,832 BAD EPOCHS (no improvement): 2\n",
            "2019-08-03 01:31:20,837 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:31:21,396 epoch 14 - iter 0/118 - loss 0.40933079\n",
            "2019-08-03 01:31:22,322 epoch 14 - iter 11/118 - loss 0.26533329\n",
            "2019-08-03 01:31:23,277 epoch 14 - iter 22/118 - loss 0.25466155\n",
            "2019-08-03 01:31:24,288 epoch 14 - iter 33/118 - loss 0.23522362\n",
            "2019-08-03 01:31:25,230 epoch 14 - iter 44/118 - loss 0.24480353\n",
            "2019-08-03 01:31:26,619 epoch 14 - iter 55/118 - loss 0.24438399\n",
            "2019-08-03 01:31:27,597 epoch 14 - iter 66/118 - loss 0.23236395\n",
            "2019-08-03 01:31:28,539 epoch 14 - iter 77/118 - loss 0.23968990\n",
            "2019-08-03 01:31:29,516 epoch 14 - iter 88/118 - loss 0.24005954\n",
            "2019-08-03 01:31:30,449 epoch 14 - iter 99/118 - loss 0.23779421\n",
            "2019-08-03 01:31:31,694 epoch 14 - iter 110/118 - loss 0.23806671\n",
            "2019-08-03 01:31:32,413 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:31:32,415 EPOCH 14 done: loss 0.2398 - lr 0.1000\n",
            "2019-08-03 01:31:33,934 DEV : loss 0.22075548768043518 - score 0.2989\n",
            "2019-08-03 01:31:35,825 TEST : loss 0.2210947722196579 - score 0.2191\n",
            "2019-08-03 01:31:36,602 BAD EPOCHS (no improvement): 3\n",
            "2019-08-03 01:31:36,608 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:31:37,185 epoch 15 - iter 0/118 - loss 0.39310870\n",
            "2019-08-03 01:31:38,144 epoch 15 - iter 11/118 - loss 0.24781899\n",
            "2019-08-03 01:31:39,183 epoch 15 - iter 22/118 - loss 0.23086092\n",
            "2019-08-03 01:31:40,200 epoch 15 - iter 33/118 - loss 0.22543029\n",
            "2019-08-03 01:31:41,151 epoch 15 - iter 44/118 - loss 0.23658378\n",
            "2019-08-03 01:31:42,675 epoch 15 - iter 55/118 - loss 0.22927001\n",
            "2019-08-03 01:31:43,697 epoch 15 - iter 66/118 - loss 0.22592294\n",
            "2019-08-03 01:31:44,756 epoch 15 - iter 77/118 - loss 0.22743597\n",
            "2019-08-03 01:31:45,758 epoch 15 - iter 88/118 - loss 0.22964669\n",
            "2019-08-03 01:31:46,775 epoch 15 - iter 99/118 - loss 0.22921006\n",
            "2019-08-03 01:31:48,044 epoch 15 - iter 110/118 - loss 0.23376756\n",
            "2019-08-03 01:31:48,790 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:31:48,792 EPOCH 15 done: loss 0.2330 - lr 0.1000\n",
            "2019-08-03 01:31:50,358 DEV : loss 0.23713596165180206 - score 0.2989\n",
            "2019-08-03 01:31:52,123 TEST : loss 0.24015143513679504 - score 0.2191\n",
            "2019-08-03 01:31:53,081 BAD EPOCHS (no improvement): 4\n",
            "2019-08-03 01:31:53,087 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:31:53,649 epoch 16 - iter 0/118 - loss 0.42267758\n",
            "2019-08-03 01:31:54,667 epoch 16 - iter 11/118 - loss 0.21613407\n",
            "2019-08-03 01:31:55,617 epoch 16 - iter 22/118 - loss 0.21231006\n",
            "2019-08-03 01:31:56,588 epoch 16 - iter 33/118 - loss 0.22587747\n",
            "2019-08-03 01:31:57,586 epoch 16 - iter 44/118 - loss 0.22198951\n",
            "2019-08-03 01:31:58,568 epoch 16 - iter 55/118 - loss 0.22647330\n",
            "2019-08-03 01:32:00,117 epoch 16 - iter 66/118 - loss 0.22750973\n",
            "2019-08-03 01:32:01,028 epoch 16 - iter 77/118 - loss 0.23088206\n",
            "2019-08-03 01:32:02,024 epoch 16 - iter 88/118 - loss 0.23080607\n",
            "2019-08-03 01:32:02,958 epoch 16 - iter 99/118 - loss 0.23272863\n",
            "2019-08-03 01:32:03,868 epoch 16 - iter 110/118 - loss 0.22981074\n",
            "2019-08-03 01:32:04,583 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:32:04,585 EPOCH 16 done: loss 0.2321 - lr 0.1000\n",
            "2019-08-03 01:32:06,436 DEV : loss 0.2335679531097412 - score 0.6228\n",
            "2019-08-03 01:32:08,266 TEST : loss 0.22236447036266327 - score 0.528\n",
            "2019-08-03 01:32:08,675 BAD EPOCHS (no improvement): 0\n",
            "2019-08-03 01:32:12,697 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:32:13,154 epoch 17 - iter 0/118 - loss 0.16675830\n",
            "2019-08-03 01:32:14,160 epoch 17 - iter 11/118 - loss 0.21065435\n",
            "2019-08-03 01:32:15,627 epoch 17 - iter 22/118 - loss 0.21353032\n",
            "2019-08-03 01:32:16,526 epoch 17 - iter 33/118 - loss 0.20948646\n",
            "2019-08-03 01:32:17,495 epoch 17 - iter 44/118 - loss 0.22917616\n",
            "2019-08-03 01:32:18,472 epoch 17 - iter 55/118 - loss 0.22659184\n",
            "2019-08-03 01:32:19,516 epoch 17 - iter 66/118 - loss 0.22514072\n",
            "2019-08-03 01:32:20,975 epoch 17 - iter 77/118 - loss 0.22149779\n",
            "2019-08-03 01:32:21,856 epoch 17 - iter 88/118 - loss 0.22579648\n",
            "2019-08-03 01:32:22,785 epoch 17 - iter 99/118 - loss 0.22607643\n",
            "2019-08-03 01:32:23,752 epoch 17 - iter 110/118 - loss 0.22504136\n",
            "2019-08-03 01:32:24,508 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:32:24,513 EPOCH 17 done: loss 0.2245 - lr 0.1000\n",
            "2019-08-03 01:32:26,361 DEV : loss 0.20228973031044006 - score 0.52\n",
            "2019-08-03 01:32:28,281 TEST : loss 0.20330171287059784 - score 0.2703\n",
            "2019-08-03 01:32:28,708 BAD EPOCHS (no improvement): 1\n",
            "2019-08-03 01:32:28,712 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:32:29,109 epoch 18 - iter 0/118 - loss 0.18392435\n",
            "2019-08-03 01:32:30,112 epoch 18 - iter 11/118 - loss 0.23237271\n",
            "2019-08-03 01:32:31,061 epoch 18 - iter 22/118 - loss 0.21936574\n",
            "2019-08-03 01:32:32,497 epoch 18 - iter 33/118 - loss 0.22779306\n",
            "2019-08-03 01:32:33,449 epoch 18 - iter 44/118 - loss 0.23448826\n",
            "2019-08-03 01:32:34,407 epoch 18 - iter 55/118 - loss 0.23508392\n",
            "2019-08-03 01:32:35,281 epoch 18 - iter 66/118 - loss 0.22950014\n",
            "2019-08-03 01:32:36,238 epoch 18 - iter 77/118 - loss 0.23986766\n",
            "2019-08-03 01:32:37,150 epoch 18 - iter 88/118 - loss 0.24042466\n",
            "2019-08-03 01:32:38,496 epoch 18 - iter 99/118 - loss 0.23950466\n",
            "2019-08-03 01:32:39,411 epoch 18 - iter 110/118 - loss 0.23892121\n",
            "2019-08-03 01:32:40,139 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:32:40,142 EPOCH 18 done: loss 0.2382 - lr 0.1000\n",
            "2019-08-03 01:32:41,689 DEV : loss 0.21088719367980957 - score 0.6457\n",
            "2019-08-03 01:32:44,194 TEST : loss 0.20198357105255127 - score 0.5053\n",
            "2019-08-03 01:32:44,617 BAD EPOCHS (no improvement): 0\n",
            "2019-08-03 01:32:48,585 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:32:49,106 epoch 19 - iter 0/118 - loss 0.25730380\n",
            "2019-08-03 01:32:50,102 epoch 19 - iter 11/118 - loss 0.17401289\n",
            "2019-08-03 01:32:51,048 epoch 19 - iter 22/118 - loss 0.18651981\n",
            "2019-08-03 01:32:52,071 epoch 19 - iter 33/118 - loss 0.19489534\n",
            "2019-08-03 01:32:53,416 epoch 19 - iter 44/118 - loss 0.18885725\n",
            "2019-08-03 01:32:54,320 epoch 19 - iter 55/118 - loss 0.19096160\n",
            "2019-08-03 01:32:55,216 epoch 19 - iter 66/118 - loss 0.21250794\n",
            "2019-08-03 01:32:56,063 epoch 19 - iter 77/118 - loss 0.21676845\n",
            "2019-08-03 01:32:56,914 epoch 19 - iter 88/118 - loss 0.21704224\n",
            "2019-08-03 01:32:58,412 epoch 19 - iter 99/118 - loss 0.22017539\n",
            "2019-08-03 01:32:59,312 epoch 19 - iter 110/118 - loss 0.22103170\n",
            "2019-08-03 01:33:00,034 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:33:00,044 EPOCH 19 done: loss 0.2254 - lr 0.1000\n",
            "2019-08-03 01:33:01,506 DEV : loss 0.2502114474773407 - score 0.5983\n",
            "2019-08-03 01:33:03,885 TEST : loss 0.2451067715883255 - score 0.4319\n",
            "2019-08-03 01:33:04,305 BAD EPOCHS (no improvement): 1\n",
            "2019-08-03 01:33:04,310 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:33:04,754 epoch 20 - iter 0/118 - loss 0.25562680\n",
            "2019-08-03 01:33:05,696 epoch 20 - iter 11/118 - loss 0.19966656\n",
            "2019-08-03 01:33:06,701 epoch 20 - iter 22/118 - loss 0.23848165\n",
            "2019-08-03 01:33:07,690 epoch 20 - iter 33/118 - loss 0.23635657\n",
            "2019-08-03 01:33:08,632 epoch 20 - iter 44/118 - loss 0.22433446\n",
            "2019-08-03 01:33:09,572 epoch 20 - iter 55/118 - loss 0.22395148\n",
            "2019-08-03 01:33:10,941 epoch 20 - iter 66/118 - loss 0.21698050\n",
            "2019-08-03 01:33:11,967 epoch 20 - iter 77/118 - loss 0.22013174\n",
            "2019-08-03 01:33:12,873 epoch 20 - iter 88/118 - loss 0.22087261\n",
            "2019-08-03 01:33:13,783 epoch 20 - iter 99/118 - loss 0.21691102\n",
            "2019-08-03 01:33:14,741 epoch 20 - iter 110/118 - loss 0.21787317\n",
            "2019-08-03 01:33:16,022 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:33:16,024 EPOCH 20 done: loss 0.2202 - lr 0.1000\n",
            "2019-08-03 01:33:17,675 DEV : loss 0.19398437440395355 - score 0.6496\n",
            "2019-08-03 01:33:19,460 TEST : loss 0.19073860347270966 - score 0.4615\n",
            "2019-08-03 01:33:19,894 BAD EPOCHS (no improvement): 0\n",
            "2019-08-03 01:33:23,871 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:33:24,302 epoch 21 - iter 0/118 - loss 0.13864699\n",
            "2019-08-03 01:33:25,890 epoch 21 - iter 11/118 - loss 0.20029766\n",
            "2019-08-03 01:33:26,807 epoch 21 - iter 22/118 - loss 0.21118177\n",
            "2019-08-03 01:33:27,789 epoch 21 - iter 33/118 - loss 0.22386795\n",
            "2019-08-03 01:33:28,797 epoch 21 - iter 44/118 - loss 0.22189503\n",
            "2019-08-03 01:33:29,710 epoch 21 - iter 55/118 - loss 0.21432464\n",
            "2019-08-03 01:33:30,785 epoch 21 - iter 66/118 - loss 0.21314959\n",
            "2019-08-03 01:33:32,235 epoch 21 - iter 77/118 - loss 0.21336097\n",
            "2019-08-03 01:33:33,204 epoch 21 - iter 88/118 - loss 0.21223868\n",
            "2019-08-03 01:33:34,191 epoch 21 - iter 99/118 - loss 0.21391787\n",
            "2019-08-03 01:33:35,203 epoch 21 - iter 110/118 - loss 0.21741251\n",
            "2019-08-03 01:33:35,999 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:33:36,001 EPOCH 21 done: loss 0.2174 - lr 0.1000\n",
            "2019-08-03 01:33:38,240 DEV : loss 0.20013932883739471 - score 0.4421\n",
            "2019-08-03 01:33:40,138 TEST : loss 0.20776782929897308 - score 0.282\n",
            "2019-08-03 01:33:40,547 BAD EPOCHS (no improvement): 1\n",
            "2019-08-03 01:33:40,553 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:33:40,973 epoch 22 - iter 0/118 - loss 0.09690768\n",
            "2019-08-03 01:33:41,916 epoch 22 - iter 11/118 - loss 0.26591173\n",
            "2019-08-03 01:33:43,320 epoch 22 - iter 22/118 - loss 0.29106370\n",
            "2019-08-03 01:33:44,292 epoch 22 - iter 33/118 - loss 0.26524372\n",
            "2019-08-03 01:33:45,336 epoch 22 - iter 44/118 - loss 0.25346475\n",
            "2019-08-03 01:33:46,338 epoch 22 - iter 55/118 - loss 0.25078762\n",
            "2019-08-03 01:33:47,329 epoch 22 - iter 66/118 - loss 0.24038879\n",
            "2019-08-03 01:33:48,353 epoch 22 - iter 77/118 - loss 0.23271574\n",
            "2019-08-03 01:33:49,702 epoch 22 - iter 88/118 - loss 0.22677023\n",
            "2019-08-03 01:33:50,719 epoch 22 - iter 99/118 - loss 0.22172697\n",
            "2019-08-03 01:33:51,809 epoch 22 - iter 110/118 - loss 0.22158626\n",
            "2019-08-03 01:33:52,609 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:33:52,615 EPOCH 22 done: loss 0.2198 - lr 0.1000\n",
            "2019-08-03 01:33:54,457 DEV : loss 0.19254176318645477 - score 0.5769\n",
            "2019-08-03 01:33:56,403 TEST : loss 0.19841277599334717 - score 0.3377\n",
            "2019-08-03 01:33:56,789 BAD EPOCHS (no improvement): 2\n",
            "2019-08-03 01:33:56,795 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:33:57,250 epoch 23 - iter 0/118 - loss 0.24772891\n",
            "2019-08-03 01:33:58,346 epoch 23 - iter 11/118 - loss 0.21111309\n",
            "2019-08-03 01:33:59,332 epoch 23 - iter 22/118 - loss 0.20928366\n",
            "2019-08-03 01:34:00,729 epoch 23 - iter 33/118 - loss 0.20258357\n",
            "2019-08-03 01:34:01,690 epoch 23 - iter 44/118 - loss 0.20453068\n",
            "2019-08-03 01:34:02,583 epoch 23 - iter 55/118 - loss 0.19583783\n",
            "2019-08-03 01:34:03,523 epoch 23 - iter 66/118 - loss 0.19975513\n",
            "2019-08-03 01:34:04,388 epoch 23 - iter 77/118 - loss 0.19968661\n",
            "2019-08-03 01:34:05,298 epoch 23 - iter 88/118 - loss 0.20929363\n",
            "2019-08-03 01:34:06,735 epoch 23 - iter 99/118 - loss 0.21308761\n",
            "2019-08-03 01:34:07,710 epoch 23 - iter 110/118 - loss 0.21439234\n",
            "2019-08-03 01:34:08,414 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:34:08,423 EPOCH 23 done: loss 0.2103 - lr 0.1000\n",
            "2019-08-03 01:34:09,777 DEV : loss 0.19035588204860687 - score 0.6939\n",
            "2019-08-03 01:34:12,146 TEST : loss 0.18909351527690887 - score 0.5487\n",
            "2019-08-03 01:34:12,578 BAD EPOCHS (no improvement): 0\n",
            "2019-08-03 01:34:16,471 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:34:16,905 epoch 24 - iter 0/118 - loss 0.19291231\n",
            "2019-08-03 01:34:17,855 epoch 24 - iter 11/118 - loss 0.22323141\n",
            "2019-08-03 01:34:18,844 epoch 24 - iter 22/118 - loss 0.19046604\n",
            "2019-08-03 01:34:19,903 epoch 24 - iter 33/118 - loss 0.17556991\n",
            "2019-08-03 01:34:20,884 epoch 24 - iter 44/118 - loss 0.18711444\n",
            "2019-08-03 01:34:22,453 epoch 24 - iter 55/118 - loss 0.18561729\n",
            "2019-08-03 01:34:23,426 epoch 24 - iter 66/118 - loss 0.18293617\n",
            "2019-08-03 01:34:24,367 epoch 24 - iter 77/118 - loss 0.18597486\n",
            "2019-08-03 01:34:25,383 epoch 24 - iter 88/118 - loss 0.18953205\n",
            "2019-08-03 01:34:26,335 epoch 24 - iter 99/118 - loss 0.19415126\n",
            "2019-08-03 01:34:27,222 epoch 24 - iter 110/118 - loss 0.20137083\n",
            "2019-08-03 01:34:27,953 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:34:27,955 EPOCH 24 done: loss 0.2016 - lr 0.1000\n",
            "2019-08-03 01:34:30,679 DEV : loss 0.17829583585262299 - score 0.687\n",
            "2019-08-03 01:34:32,449 TEST : loss 0.1814187616109848 - score 0.4948\n",
            "2019-08-03 01:34:32,836 BAD EPOCHS (no improvement): 1\n",
            "2019-08-03 01:34:32,841 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:34:33,311 epoch 25 - iter 0/118 - loss 0.12008302\n",
            "2019-08-03 01:34:34,694 epoch 25 - iter 11/118 - loss 0.18972064\n",
            "2019-08-03 01:34:35,605 epoch 25 - iter 22/118 - loss 0.18539627\n",
            "2019-08-03 01:34:36,505 epoch 25 - iter 33/118 - loss 0.18248325\n",
            "2019-08-03 01:34:37,371 epoch 25 - iter 44/118 - loss 0.18997169\n",
            "2019-08-03 01:34:38,292 epoch 25 - iter 55/118 - loss 0.19365988\n",
            "2019-08-03 01:34:39,152 epoch 25 - iter 66/118 - loss 0.19618876\n",
            "2019-08-03 01:34:40,346 epoch 25 - iter 77/118 - loss 0.19933330\n",
            "2019-08-03 01:34:41,171 epoch 25 - iter 88/118 - loss 0.20508193\n",
            "2019-08-03 01:34:42,002 epoch 25 - iter 99/118 - loss 0.20387729\n",
            "2019-08-03 01:34:42,966 epoch 25 - iter 110/118 - loss 0.20203616\n",
            "2019-08-03 01:34:43,671 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:34:43,675 EPOCH 25 done: loss 0.2001 - lr 0.1000\n",
            "2019-08-03 01:34:45,745 DEV : loss 0.17382237315177917 - score 0.6612\n",
            "2019-08-03 01:34:47,525 TEST : loss 0.1785406470298767 - score 0.427\n",
            "2019-08-03 01:34:47,938 BAD EPOCHS (no improvement): 2\n",
            "2019-08-03 01:34:47,943 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:34:48,393 epoch 26 - iter 0/118 - loss 0.16715783\n",
            "2019-08-03 01:34:49,393 epoch 26 - iter 11/118 - loss 0.23710595\n",
            "2019-08-03 01:34:50,322 epoch 26 - iter 22/118 - loss 0.21062133\n",
            "2019-08-03 01:34:51,748 epoch 26 - iter 33/118 - loss 0.20862781\n",
            "2019-08-03 01:34:52,664 epoch 26 - iter 44/118 - loss 0.20496134\n",
            "2019-08-03 01:34:53,638 epoch 26 - iter 55/118 - loss 0.20547452\n",
            "2019-08-03 01:34:54,471 epoch 26 - iter 66/118 - loss 0.20908170\n",
            "2019-08-03 01:34:55,433 epoch 26 - iter 77/118 - loss 0.21061562\n",
            "2019-08-03 01:34:56,820 epoch 26 - iter 88/118 - loss 0.20950875\n",
            "2019-08-03 01:34:57,816 epoch 26 - iter 99/118 - loss 0.21174848\n",
            "2019-08-03 01:34:58,780 epoch 26 - iter 110/118 - loss 0.20458417\n",
            "2019-08-03 01:34:59,490 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:34:59,492 EPOCH 26 done: loss 0.2047 - lr 0.1000\n",
            "2019-08-03 01:35:00,902 DEV : loss 0.22120940685272217 - score 0.6236\n",
            "2019-08-03 01:35:03,404 TEST : loss 0.21643753349781036 - score 0.5355\n",
            "2019-08-03 01:35:03,795 BAD EPOCHS (no improvement): 3\n",
            "2019-08-03 01:35:03,800 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:35:04,253 epoch 27 - iter 0/118 - loss 0.15041816\n",
            "2019-08-03 01:35:05,184 epoch 27 - iter 11/118 - loss 0.20653095\n",
            "2019-08-03 01:35:06,056 epoch 27 - iter 22/118 - loss 0.22847895\n",
            "2019-08-03 01:35:06,945 epoch 27 - iter 33/118 - loss 0.20798668\n",
            "2019-08-03 01:35:08,331 epoch 27 - iter 44/118 - loss 0.20796155\n",
            "2019-08-03 01:35:09,324 epoch 27 - iter 55/118 - loss 0.19166545\n",
            "2019-08-03 01:35:10,355 epoch 27 - iter 66/118 - loss 0.19336584\n",
            "2019-08-03 01:35:11,248 epoch 27 - iter 77/118 - loss 0.19611451\n",
            "2019-08-03 01:35:12,126 epoch 27 - iter 88/118 - loss 0.18903202\n",
            "2019-08-03 01:35:13,028 epoch 27 - iter 99/118 - loss 0.19551512\n",
            "2019-08-03 01:35:14,477 epoch 27 - iter 110/118 - loss 0.19117389\n",
            "2019-08-03 01:35:15,179 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:35:15,183 EPOCH 27 done: loss 0.1910 - lr 0.1000\n",
            "2019-08-03 01:35:16,646 DEV : loss 0.17968271672725677 - score 0.6822\n",
            "2019-08-03 01:35:18,519 TEST : loss 0.19153434038162231 - score 0.5102\n",
            "2019-08-03 01:35:18,913 BAD EPOCHS (no improvement): 4\n",
            "2019-08-03 01:35:18,918 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:35:19,436 epoch 28 - iter 0/118 - loss 0.33291817\n",
            "2019-08-03 01:35:21,006 epoch 28 - iter 11/118 - loss 0.16894926\n",
            "2019-08-03 01:35:21,842 epoch 28 - iter 22/118 - loss 0.15474606\n",
            "2019-08-03 01:35:22,706 epoch 28 - iter 33/118 - loss 0.16818957\n",
            "2019-08-03 01:35:23,684 epoch 28 - iter 44/118 - loss 0.17024895\n",
            "2019-08-03 01:35:24,613 epoch 28 - iter 55/118 - loss 0.17461845\n",
            "2019-08-03 01:35:25,919 epoch 28 - iter 66/118 - loss 0.17481406\n",
            "2019-08-03 01:35:26,775 epoch 28 - iter 77/118 - loss 0.17957116\n",
            "2019-08-03 01:35:27,635 epoch 28 - iter 88/118 - loss 0.18122111\n",
            "2019-08-03 01:35:28,592 epoch 28 - iter 99/118 - loss 0.18642651\n",
            "2019-08-03 01:35:29,580 epoch 28 - iter 110/118 - loss 0.18801449\n",
            "2019-08-03 01:35:30,841 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:35:30,845 EPOCH 28 done: loss 0.1849 - lr 0.1000\n",
            "2019-08-03 01:35:32,427 DEV : loss 0.17780281603336334 - score 0.6875\n",
            "2019-08-03 01:35:34,367 TEST : loss 0.18030917644500732 - score 0.5968\n",
            "2019-08-03 01:35:34,794 BAD EPOCHS (no improvement): 5\n",
            "2019-08-03 01:35:34,800 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:35:35,326 epoch 29 - iter 0/118 - loss 0.02967029\n",
            "2019-08-03 01:35:36,389 epoch 29 - iter 11/118 - loss 0.12612156\n",
            "2019-08-03 01:35:37,942 epoch 29 - iter 22/118 - loss 0.14615409\n",
            "2019-08-03 01:35:38,806 epoch 29 - iter 33/118 - loss 0.16391530\n",
            "2019-08-03 01:35:39,790 epoch 29 - iter 44/118 - loss 0.17246314\n",
            "2019-08-03 01:35:40,768 epoch 29 - iter 55/118 - loss 0.16911969\n",
            "2019-08-03 01:35:41,669 epoch 29 - iter 66/118 - loss 0.17678468\n",
            "2019-08-03 01:35:43,021 epoch 29 - iter 77/118 - loss 0.17770785\n",
            "2019-08-03 01:35:44,016 epoch 29 - iter 88/118 - loss 0.18088215\n",
            "2019-08-03 01:35:44,956 epoch 29 - iter 99/118 - loss 0.18321914\n",
            "2019-08-03 01:35:45,899 epoch 29 - iter 110/118 - loss 0.18916458\n",
            "2019-08-03 01:35:46,702 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:35:46,704 EPOCH 29 done: loss 0.1880 - lr 0.1000\n",
            "2019-08-03 01:35:48,880 DEV : loss 0.17926521599292755 - score 0.6239\n",
            "2019-08-03 01:35:50,768 TEST : loss 0.1872250884771347 - score 0.3377\n",
            "Epoch    28: reducing learning rate of group 0 to 5.0000e-02.\n",
            "2019-08-03 01:35:51,163 BAD EPOCHS (no improvement): 6\n",
            "2019-08-03 01:35:51,166 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:35:51,583 epoch 30 - iter 0/118 - loss 0.29090571\n",
            "2019-08-03 01:35:52,471 epoch 30 - iter 11/118 - loss 0.15397246\n",
            "2019-08-03 01:35:53,383 epoch 30 - iter 22/118 - loss 0.16506246\n",
            "2019-08-03 01:35:55,008 epoch 30 - iter 33/118 - loss 0.17053466\n",
            "2019-08-03 01:35:55,919 epoch 30 - iter 44/118 - loss 0.17406110\n",
            "2019-08-03 01:35:56,847 epoch 30 - iter 55/118 - loss 0.17928439\n",
            "2019-08-03 01:35:57,765 epoch 30 - iter 66/118 - loss 0.17705304\n",
            "2019-08-03 01:35:58,711 epoch 30 - iter 77/118 - loss 0.16973881\n",
            "2019-08-03 01:36:00,050 epoch 30 - iter 88/118 - loss 0.16831444\n",
            "2019-08-03 01:36:00,919 epoch 30 - iter 99/118 - loss 0.16500519\n",
            "2019-08-03 01:36:01,750 epoch 30 - iter 110/118 - loss 0.16698057\n",
            "2019-08-03 01:36:02,447 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:36:02,449 EPOCH 30 done: loss 0.1655 - lr 0.0500\n",
            "2019-08-03 01:36:03,770 DEV : loss 0.26288899779319763 - score 0.6\n",
            "2019-08-03 01:36:06,013 TEST : loss 0.25996753573417664 - score 0.5576\n",
            "2019-08-03 01:36:06,401 BAD EPOCHS (no improvement): 1\n",
            "2019-08-03 01:36:06,406 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:36:06,837 epoch 31 - iter 0/118 - loss 0.20995218\n",
            "2019-08-03 01:36:07,830 epoch 31 - iter 11/118 - loss 0.14366619\n",
            "2019-08-03 01:36:08,788 epoch 31 - iter 22/118 - loss 0.15428530\n",
            "2019-08-03 01:36:09,783 epoch 31 - iter 33/118 - loss 0.15440523\n",
            "2019-08-03 01:36:11,212 epoch 31 - iter 44/118 - loss 0.16284073\n",
            "2019-08-03 01:36:12,167 epoch 31 - iter 55/118 - loss 0.16498458\n",
            "2019-08-03 01:36:13,016 epoch 31 - iter 66/118 - loss 0.16271537\n",
            "2019-08-03 01:36:13,891 epoch 31 - iter 77/118 - loss 0.16206337\n",
            "2019-08-03 01:36:14,742 epoch 31 - iter 88/118 - loss 0.16344563\n",
            "2019-08-03 01:36:16,243 epoch 31 - iter 99/118 - loss 0.16278851\n",
            "2019-08-03 01:36:17,186 epoch 31 - iter 110/118 - loss 0.16431951\n",
            "2019-08-03 01:36:17,964 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:36:17,970 EPOCH 31 done: loss 0.1635 - lr 0.0500\n",
            "2019-08-03 01:36:19,469 DEV : loss 0.16060827672481537 - score 0.7034\n",
            "2019-08-03 01:36:21,741 TEST : loss 0.17115263640880585 - score 0.6034\n",
            "2019-08-03 01:36:22,135 BAD EPOCHS (no improvement): 0\n",
            "2019-08-03 01:36:26,086 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:36:26,555 epoch 32 - iter 0/118 - loss 0.06631765\n",
            "2019-08-03 01:36:27,576 epoch 32 - iter 11/118 - loss 0.20397140\n",
            "2019-08-03 01:36:28,597 epoch 32 - iter 22/118 - loss 0.16500283\n",
            "2019-08-03 01:36:29,526 epoch 32 - iter 33/118 - loss 0.15599556\n",
            "2019-08-03 01:36:30,455 epoch 32 - iter 44/118 - loss 0.16067062\n",
            "2019-08-03 01:36:31,458 epoch 32 - iter 55/118 - loss 0.16260261\n",
            "2019-08-03 01:36:32,821 epoch 32 - iter 66/118 - loss 0.15915985\n",
            "2019-08-03 01:36:33,687 epoch 32 - iter 77/118 - loss 0.16095822\n",
            "2019-08-03 01:36:34,563 epoch 32 - iter 88/118 - loss 0.16370425\n",
            "2019-08-03 01:36:35,593 epoch 32 - iter 99/118 - loss 0.17182836\n",
            "2019-08-03 01:36:36,551 epoch 32 - iter 110/118 - loss 0.16929860\n",
            "2019-08-03 01:36:37,341 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:36:37,343 EPOCH 32 done: loss 0.1690 - lr 0.0500\n",
            "2019-08-03 01:36:40,123 DEV : loss 0.15773586928844452 - score 0.7194\n",
            "2019-08-03 01:36:41,873 TEST : loss 0.166636660695076 - score 0.6227\n",
            "2019-08-03 01:36:42,263 BAD EPOCHS (no improvement): 0\n",
            "2019-08-03 01:36:45,768 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:36:46,202 epoch 33 - iter 0/118 - loss 0.06235746\n",
            "2019-08-03 01:36:47,187 epoch 33 - iter 11/118 - loss 0.15949074\n",
            "2019-08-03 01:36:48,577 epoch 33 - iter 22/118 - loss 0.16910899\n",
            "2019-08-03 01:36:49,544 epoch 33 - iter 33/118 - loss 0.15851323\n",
            "2019-08-03 01:36:50,416 epoch 33 - iter 44/118 - loss 0.16684365\n",
            "2019-08-03 01:36:51,292 epoch 33 - iter 55/118 - loss 0.17059358\n",
            "2019-08-03 01:36:52,151 epoch 33 - iter 66/118 - loss 0.17171062\n",
            "2019-08-03 01:36:53,418 epoch 33 - iter 77/118 - loss 0.17555173\n",
            "2019-08-03 01:36:54,321 epoch 33 - iter 88/118 - loss 0.17226394\n",
            "2019-08-03 01:36:55,246 epoch 33 - iter 99/118 - loss 0.16852004\n",
            "2019-08-03 01:36:56,233 epoch 33 - iter 110/118 - loss 0.16325291\n",
            "2019-08-03 01:36:56,991 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:36:56,993 EPOCH 33 done: loss 0.1624 - lr 0.0500\n",
            "2019-08-03 01:36:59,197 DEV : loss 0.16637486219406128 - score 0.6422\n",
            "2019-08-03 01:37:00,983 TEST : loss 0.1832292228937149 - score 0.4419\n",
            "2019-08-03 01:37:01,377 BAD EPOCHS (no improvement): 1\n",
            "2019-08-03 01:37:01,382 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:37:01,813 epoch 34 - iter 0/118 - loss 0.10493785\n",
            "2019-08-03 01:37:02,833 epoch 34 - iter 11/118 - loss 0.12796933\n",
            "2019-08-03 01:37:04,208 epoch 34 - iter 22/118 - loss 0.14232801\n",
            "2019-08-03 01:37:05,075 epoch 34 - iter 33/118 - loss 0.14084576\n",
            "2019-08-03 01:37:05,937 epoch 34 - iter 44/118 - loss 0.14422426\n",
            "2019-08-03 01:37:06,864 epoch 34 - iter 55/118 - loss 0.14895552\n",
            "2019-08-03 01:37:07,810 epoch 34 - iter 66/118 - loss 0.16777458\n",
            "2019-08-03 01:37:09,220 epoch 34 - iter 77/118 - loss 0.16569636\n",
            "2019-08-03 01:37:10,150 epoch 34 - iter 88/118 - loss 0.16124138\n",
            "2019-08-03 01:37:11,069 epoch 34 - iter 99/118 - loss 0.15630896\n",
            "2019-08-03 01:37:11,931 epoch 34 - iter 110/118 - loss 0.15266428\n",
            "2019-08-03 01:37:12,664 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:37:12,666 EPOCH 34 done: loss 0.1537 - lr 0.0500\n",
            "2019-08-03 01:37:14,691 DEV : loss 0.2095007449388504 - score 0.6994\n",
            "2019-08-03 01:37:16,703 TEST : loss 0.19944460690021515 - score 0.6494\n",
            "2019-08-03 01:37:17,088 BAD EPOCHS (no improvement): 2\n",
            "2019-08-03 01:37:17,094 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:37:17,496 epoch 35 - iter 0/118 - loss 0.17927232\n",
            "2019-08-03 01:37:18,471 epoch 35 - iter 11/118 - loss 0.17790858\n",
            "2019-08-03 01:37:19,896 epoch 35 - iter 22/118 - loss 0.17850629\n",
            "2019-08-03 01:37:20,890 epoch 35 - iter 33/118 - loss 0.16869108\n",
            "2019-08-03 01:37:21,785 epoch 35 - iter 44/118 - loss 0.15481033\n",
            "2019-08-03 01:37:22,695 epoch 35 - iter 55/118 - loss 0.15060356\n",
            "2019-08-03 01:37:23,647 epoch 35 - iter 66/118 - loss 0.15139063\n",
            "2019-08-03 01:37:25,080 epoch 35 - iter 77/118 - loss 0.14714681\n",
            "2019-08-03 01:37:26,051 epoch 35 - iter 88/118 - loss 0.15109376\n",
            "2019-08-03 01:37:26,953 epoch 35 - iter 99/118 - loss 0.15096422\n",
            "2019-08-03 01:37:27,774 epoch 35 - iter 110/118 - loss 0.15717532\n",
            "2019-08-03 01:37:28,438 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:37:28,448 EPOCH 35 done: loss 0.1592 - lr 0.0500\n",
            "2019-08-03 01:37:30,571 DEV : loss 0.15893982350826263 - score 0.678\n",
            "2019-08-03 01:37:32,327 TEST : loss 0.16571180522441864 - score 0.5684\n",
            "2019-08-03 01:37:32,762 BAD EPOCHS (no improvement): 3\n",
            "2019-08-03 01:37:32,767 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:37:33,169 epoch 36 - iter 0/118 - loss 0.12721795\n",
            "2019-08-03 01:37:34,072 epoch 36 - iter 11/118 - loss 0.12591851\n",
            "2019-08-03 01:37:35,070 epoch 36 - iter 22/118 - loss 0.13929339\n",
            "2019-08-03 01:37:35,910 epoch 36 - iter 33/118 - loss 0.13036367\n",
            "2019-08-03 01:37:37,508 epoch 36 - iter 44/118 - loss 0.14351400\n",
            "2019-08-03 01:37:38,464 epoch 36 - iter 55/118 - loss 0.15106420\n",
            "2019-08-03 01:37:39,308 epoch 36 - iter 66/118 - loss 0.15017391\n",
            "2019-08-03 01:37:40,266 epoch 36 - iter 77/118 - loss 0.14805382\n",
            "2019-08-03 01:37:41,200 epoch 36 - iter 88/118 - loss 0.14779711\n",
            "2019-08-03 01:37:42,508 epoch 36 - iter 99/118 - loss 0.14682546\n",
            "2019-08-03 01:37:43,518 epoch 36 - iter 110/118 - loss 0.14778428\n",
            "2019-08-03 01:37:44,230 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:37:44,239 EPOCH 36 done: loss 0.1468 - lr 0.0500\n",
            "2019-08-03 01:37:45,812 DEV : loss 0.16076445579528809 - score 0.7023\n",
            "2019-08-03 01:37:48,260 TEST : loss 0.181364506483078 - score 0.6465\n",
            "2019-08-03 01:37:48,700 BAD EPOCHS (no improvement): 4\n",
            "2019-08-03 01:37:48,705 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:37:49,134 epoch 37 - iter 0/118 - loss 0.08807589\n",
            "2019-08-03 01:37:50,259 epoch 37 - iter 11/118 - loss 0.11125086\n",
            "2019-08-03 01:37:51,239 epoch 37 - iter 22/118 - loss 0.11978175\n",
            "2019-08-03 01:37:52,215 epoch 37 - iter 33/118 - loss 0.13819890\n",
            "2019-08-03 01:37:53,134 epoch 37 - iter 44/118 - loss 0.13298490\n",
            "2019-08-03 01:37:54,725 epoch 37 - iter 55/118 - loss 0.14117911\n",
            "2019-08-03 01:37:55,692 epoch 37 - iter 66/118 - loss 0.14426374\n",
            "2019-08-03 01:37:56,624 epoch 37 - iter 77/118 - loss 0.14889393\n",
            "2019-08-03 01:37:57,529 epoch 37 - iter 88/118 - loss 0.14804876\n",
            "2019-08-03 01:37:58,492 epoch 37 - iter 99/118 - loss 0.14978263\n",
            "2019-08-03 01:37:59,977 epoch 37 - iter 110/118 - loss 0.15003936\n",
            "2019-08-03 01:38:00,726 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:38:00,729 EPOCH 37 done: loss 0.1489 - lr 0.0500\n",
            "2019-08-03 01:38:02,353 DEV : loss 0.16813886165618896 - score 0.6885\n",
            "2019-08-03 01:38:04,316 TEST : loss 0.19400957226753235 - score 0.5807\n",
            "2019-08-03 01:38:05,276 BAD EPOCHS (no improvement): 5\n",
            "2019-08-03 01:38:05,283 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:38:05,882 epoch 38 - iter 0/118 - loss 0.39999795\n",
            "2019-08-03 01:38:06,844 epoch 38 - iter 11/118 - loss 0.15835564\n",
            "2019-08-03 01:38:07,839 epoch 38 - iter 22/118 - loss 0.14682785\n",
            "2019-08-03 01:38:08,878 epoch 38 - iter 33/118 - loss 0.13812155\n",
            "2019-08-03 01:38:09,794 epoch 38 - iter 44/118 - loss 0.13647552\n",
            "2019-08-03 01:38:11,129 epoch 38 - iter 55/118 - loss 0.14481044\n",
            "2019-08-03 01:38:12,095 epoch 38 - iter 66/118 - loss 0.14029833\n",
            "2019-08-03 01:38:13,033 epoch 38 - iter 77/118 - loss 0.15018473\n",
            "2019-08-03 01:38:13,902 epoch 38 - iter 88/118 - loss 0.15178313\n",
            "2019-08-03 01:38:14,764 epoch 38 - iter 99/118 - loss 0.15845539\n",
            "2019-08-03 01:38:15,992 epoch 38 - iter 110/118 - loss 0.15480383\n",
            "2019-08-03 01:38:16,673 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:38:16,675 EPOCH 38 done: loss 0.1544 - lr 0.0500\n",
            "2019-08-03 01:38:18,236 DEV : loss 0.16075918078422546 - score 0.7273\n",
            "2019-08-03 01:38:20,072 TEST : loss 0.16157613694667816 - score 0.736\n",
            "2019-08-03 01:38:20,489 BAD EPOCHS (no improvement): 0\n",
            "2019-08-03 01:38:24,461 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:38:25,012 epoch 39 - iter 0/118 - loss 0.10534484\n",
            "2019-08-03 01:38:26,446 epoch 39 - iter 11/118 - loss 0.15048634\n",
            "2019-08-03 01:38:27,449 epoch 39 - iter 22/118 - loss 0.14395042\n",
            "2019-08-03 01:38:28,410 epoch 39 - iter 33/118 - loss 0.16061511\n",
            "2019-08-03 01:38:29,332 epoch 39 - iter 44/118 - loss 0.15729091\n",
            "2019-08-03 01:38:30,353 epoch 39 - iter 55/118 - loss 0.14894219\n",
            "2019-08-03 01:38:31,797 epoch 39 - iter 66/118 - loss 0.13888189\n",
            "2019-08-03 01:38:32,734 epoch 39 - iter 77/118 - loss 0.14260983\n",
            "2019-08-03 01:38:33,710 epoch 39 - iter 88/118 - loss 0.14087552\n",
            "2019-08-03 01:38:34,629 epoch 39 - iter 99/118 - loss 0.14145200\n",
            "2019-08-03 01:38:35,590 epoch 39 - iter 110/118 - loss 0.14309513\n",
            "2019-08-03 01:38:36,349 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:38:36,351 EPOCH 39 done: loss 0.1458 - lr 0.0500\n",
            "2019-08-03 01:38:38,514 DEV : loss 0.15879671275615692 - score 0.7361\n",
            "2019-08-03 01:38:40,457 TEST : loss 0.16463243961334229 - score 0.7193\n",
            "2019-08-03 01:38:40,870 BAD EPOCHS (no improvement): 0\n",
            "2019-08-03 01:38:44,865 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:38:45,432 epoch 40 - iter 0/118 - loss 0.05687517\n",
            "2019-08-03 01:38:46,448 epoch 40 - iter 11/118 - loss 0.12377090\n",
            "2019-08-03 01:38:48,008 epoch 40 - iter 22/118 - loss 0.15060979\n",
            "2019-08-03 01:38:48,906 epoch 40 - iter 33/118 - loss 0.15856531\n",
            "2019-08-03 01:38:49,818 epoch 40 - iter 44/118 - loss 0.16230288\n",
            "2019-08-03 01:38:50,725 epoch 40 - iter 55/118 - loss 0.15270283\n",
            "2019-08-03 01:38:51,670 epoch 40 - iter 66/118 - loss 0.15804235\n",
            "2019-08-03 01:38:53,061 epoch 40 - iter 77/118 - loss 0.15148374\n",
            "2019-08-03 01:38:54,013 epoch 40 - iter 88/118 - loss 0.14642998\n",
            "2019-08-03 01:38:55,052 epoch 40 - iter 99/118 - loss 0.14538389\n",
            "2019-08-03 01:38:56,080 epoch 40 - iter 110/118 - loss 0.14734503\n",
            "2019-08-03 01:38:56,889 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:38:56,896 EPOCH 40 done: loss 0.1469 - lr 0.0500\n",
            "2019-08-03 01:38:58,755 DEV : loss 0.15872198343276978 - score 0.7467\n",
            "2019-08-03 01:39:00,566 TEST : loss 0.16452963650226593 - score 0.7458\n",
            "2019-08-03 01:39:00,957 BAD EPOCHS (no improvement): 0\n",
            "2019-08-03 01:39:04,666 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:39:05,172 epoch 41 - iter 0/118 - loss 0.03379008\n",
            "2019-08-03 01:39:06,092 epoch 41 - iter 11/118 - loss 0.14305209\n",
            "2019-08-03 01:39:07,044 epoch 41 - iter 22/118 - loss 0.14437952\n",
            "2019-08-03 01:39:08,005 epoch 41 - iter 33/118 - loss 0.14054228\n",
            "2019-08-03 01:39:09,583 epoch 41 - iter 44/118 - loss 0.14441107\n",
            "2019-08-03 01:39:10,544 epoch 41 - iter 55/118 - loss 0.13827455\n",
            "2019-08-03 01:39:11,410 epoch 41 - iter 66/118 - loss 0.13506492\n",
            "2019-08-03 01:39:12,299 epoch 41 - iter 77/118 - loss 0.13719176\n",
            "2019-08-03 01:39:13,248 epoch 41 - iter 88/118 - loss 0.13654927\n",
            "2019-08-03 01:39:14,597 epoch 41 - iter 99/118 - loss 0.13678628\n",
            "2019-08-03 01:39:15,548 epoch 41 - iter 110/118 - loss 0.13779369\n",
            "2019-08-03 01:39:16,275 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:39:16,278 EPOCH 41 done: loss 0.1401 - lr 0.0500\n",
            "2019-08-03 01:39:17,795 DEV : loss 0.17547550797462463 - score 0.6818\n",
            "2019-08-03 01:39:20,399 TEST : loss 0.19014088809490204 - score 0.5657\n",
            "2019-08-03 01:39:20,808 BAD EPOCHS (no improvement): 1\n",
            "2019-08-03 01:39:20,812 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:39:21,373 epoch 42 - iter 0/118 - loss 0.09424677\n",
            "2019-08-03 01:39:22,405 epoch 42 - iter 11/118 - loss 0.14723388\n",
            "2019-08-03 01:39:23,384 epoch 42 - iter 22/118 - loss 0.13646498\n",
            "2019-08-03 01:39:24,298 epoch 42 - iter 33/118 - loss 0.14089891\n",
            "2019-08-03 01:39:25,247 epoch 42 - iter 44/118 - loss 0.13243805\n",
            "2019-08-03 01:39:26,722 epoch 42 - iter 55/118 - loss 0.13488650\n",
            "2019-08-03 01:39:27,640 epoch 42 - iter 66/118 - loss 0.13193264\n",
            "2019-08-03 01:39:28,577 epoch 42 - iter 77/118 - loss 0.13104203\n",
            "2019-08-03 01:39:29,592 epoch 42 - iter 88/118 - loss 0.13763734\n",
            "2019-08-03 01:39:30,552 epoch 42 - iter 99/118 - loss 0.14504355\n",
            "2019-08-03 01:39:31,459 epoch 42 - iter 110/118 - loss 0.14782919\n",
            "2019-08-03 01:39:32,591 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:39:32,594 EPOCH 42 done: loss 0.1512 - lr 0.0500\n",
            "2019-08-03 01:39:34,161 DEV : loss 0.16445665061473846 - score 0.7297\n",
            "2019-08-03 01:39:36,094 TEST : loss 0.1615646481513977 - score 0.7\n",
            "2019-08-03 01:39:36,508 BAD EPOCHS (no improvement): 2\n",
            "2019-08-03 01:39:36,513 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:39:36,961 epoch 43 - iter 0/118 - loss 0.12814552\n",
            "2019-08-03 01:39:38,596 epoch 43 - iter 11/118 - loss 0.14781704\n",
            "2019-08-03 01:39:39,563 epoch 43 - iter 22/118 - loss 0.15443788\n",
            "2019-08-03 01:39:40,442 epoch 43 - iter 33/118 - loss 0.13867530\n",
            "2019-08-03 01:39:41,374 epoch 43 - iter 44/118 - loss 0.14269320\n",
            "2019-08-03 01:39:42,285 epoch 43 - iter 55/118 - loss 0.14336047\n",
            "2019-08-03 01:39:43,829 epoch 43 - iter 66/118 - loss 0.14158797\n",
            "2019-08-03 01:39:44,825 epoch 43 - iter 77/118 - loss 0.13499720\n",
            "2019-08-03 01:39:45,702 epoch 43 - iter 88/118 - loss 0.13546004\n",
            "2019-08-03 01:39:46,718 epoch 43 - iter 99/118 - loss 0.13947488\n",
            "2019-08-03 01:39:47,659 epoch 43 - iter 110/118 - loss 0.13811402\n",
            "2019-08-03 01:39:48,369 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:39:48,371 EPOCH 43 done: loss 0.1381 - lr 0.0500\n",
            "2019-08-03 01:39:50,961 DEV : loss 0.15786106884479523 - score 0.766\n",
            "2019-08-03 01:39:52,724 TEST : loss 0.1618405431509018 - score 0.7543\n",
            "2019-08-03 01:39:53,114 BAD EPOCHS (no improvement): 0\n",
            "2019-08-03 01:39:56,723 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:39:57,170 epoch 44 - iter 0/118 - loss 0.12608987\n",
            "2019-08-03 01:39:58,138 epoch 44 - iter 11/118 - loss 0.12185064\n",
            "2019-08-03 01:39:59,518 epoch 44 - iter 22/118 - loss 0.11250343\n",
            "2019-08-03 01:40:00,382 epoch 44 - iter 33/118 - loss 0.12281600\n",
            "2019-08-03 01:40:01,225 epoch 44 - iter 44/118 - loss 0.12077102\n",
            "2019-08-03 01:40:02,085 epoch 44 - iter 55/118 - loss 0.12453962\n",
            "2019-08-03 01:40:02,969 epoch 44 - iter 66/118 - loss 0.12652876\n",
            "2019-08-03 01:40:04,416 epoch 44 - iter 77/118 - loss 0.12820265\n",
            "2019-08-03 01:40:05,394 epoch 44 - iter 88/118 - loss 0.13490042\n",
            "2019-08-03 01:40:06,327 epoch 44 - iter 99/118 - loss 0.13101868\n",
            "2019-08-03 01:40:07,354 epoch 44 - iter 110/118 - loss 0.13730726\n",
            "2019-08-03 01:40:08,064 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:40:08,066 EPOCH 44 done: loss 0.1347 - lr 0.0500\n",
            "2019-08-03 01:40:10,195 DEV : loss 0.18022824823856354 - score 0.7262\n",
            "2019-08-03 01:40:12,109 TEST : loss 0.1716712862253189 - score 0.6809\n",
            "2019-08-03 01:40:12,534 BAD EPOCHS (no improvement): 1\n",
            "2019-08-03 01:40:12,540 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:40:13,099 epoch 45 - iter 0/118 - loss 0.06910484\n",
            "2019-08-03 01:40:14,096 epoch 45 - iter 11/118 - loss 0.14242261\n",
            "2019-08-03 01:40:15,072 epoch 45 - iter 22/118 - loss 0.14746948\n",
            "2019-08-03 01:40:16,669 epoch 45 - iter 33/118 - loss 0.14594721\n",
            "2019-08-03 01:40:17,610 epoch 45 - iter 44/118 - loss 0.14158133\n",
            "2019-08-03 01:40:18,542 epoch 45 - iter 55/118 - loss 0.14511283\n",
            "2019-08-03 01:40:19,466 epoch 45 - iter 66/118 - loss 0.13343703\n",
            "2019-08-03 01:40:20,437 epoch 45 - iter 77/118 - loss 0.13338928\n",
            "2019-08-03 01:40:21,704 epoch 45 - iter 88/118 - loss 0.13160072\n",
            "2019-08-03 01:40:22,651 epoch 45 - iter 99/118 - loss 0.13031208\n",
            "2019-08-03 01:40:23,609 epoch 45 - iter 110/118 - loss 0.12936115\n",
            "2019-08-03 01:40:24,356 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:40:24,357 EPOCH 45 done: loss 0.1321 - lr 0.0500\n",
            "2019-08-03 01:40:25,840 DEV : loss 0.16861292719841003 - score 0.7633\n",
            "2019-08-03 01:40:28,041 TEST : loss 0.17661024630069733 - score 0.6857\n",
            "2019-08-03 01:40:28,460 BAD EPOCHS (no improvement): 2\n",
            "2019-08-03 01:40:28,464 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:40:28,975 epoch 46 - iter 0/118 - loss 0.03579026\n",
            "2019-08-03 01:40:29,958 epoch 46 - iter 11/118 - loss 0.13599271\n",
            "2019-08-03 01:40:30,861 epoch 46 - iter 22/118 - loss 0.13175582\n",
            "2019-08-03 01:40:31,751 epoch 46 - iter 33/118 - loss 0.13471873\n",
            "2019-08-03 01:40:33,321 epoch 46 - iter 44/118 - loss 0.13967713\n",
            "2019-08-03 01:40:34,326 epoch 46 - iter 55/118 - loss 0.13220409\n",
            "2019-08-03 01:40:35,230 epoch 46 - iter 66/118 - loss 0.13223849\n",
            "2019-08-03 01:40:36,193 epoch 46 - iter 77/118 - loss 0.13112076\n",
            "2019-08-03 01:40:37,121 epoch 46 - iter 88/118 - loss 0.13147620\n",
            "2019-08-03 01:40:38,552 epoch 46 - iter 99/118 - loss 0.13015050\n",
            "2019-08-03 01:40:39,424 epoch 46 - iter 110/118 - loss 0.13094270\n",
            "2019-08-03 01:40:40,159 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:40:40,165 EPOCH 46 done: loss 0.1351 - lr 0.0500\n",
            "2019-08-03 01:40:41,728 DEV : loss 0.15215180814266205 - score 0.731\n",
            "2019-08-03 01:40:43,698 TEST : loss 0.15415753424167633 - score 0.7304\n",
            "2019-08-03 01:40:44,666 BAD EPOCHS (no improvement): 3\n",
            "2019-08-03 01:40:44,672 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:40:45,227 epoch 47 - iter 0/118 - loss 0.14245921\n",
            "2019-08-03 01:40:46,223 epoch 47 - iter 11/118 - loss 0.11470812\n",
            "2019-08-03 01:40:47,289 epoch 47 - iter 22/118 - loss 0.12806384\n",
            "2019-08-03 01:40:48,195 epoch 47 - iter 33/118 - loss 0.11668734\n",
            "2019-08-03 01:40:49,219 epoch 47 - iter 44/118 - loss 0.11483582\n",
            "2019-08-03 01:40:50,777 epoch 47 - iter 55/118 - loss 0.12201092\n",
            "2019-08-03 01:40:51,751 epoch 47 - iter 66/118 - loss 0.12010839\n",
            "2019-08-03 01:40:52,700 epoch 47 - iter 77/118 - loss 0.12347436\n",
            "2019-08-03 01:40:53,640 epoch 47 - iter 88/118 - loss 0.12122984\n",
            "2019-08-03 01:40:54,611 epoch 47 - iter 99/118 - loss 0.12370094\n",
            "2019-08-03 01:40:55,602 epoch 47 - iter 110/118 - loss 0.13242478\n",
            "2019-08-03 01:40:56,810 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:40:56,811 EPOCH 47 done: loss 0.1318 - lr 0.0500\n",
            "2019-08-03 01:40:58,400 DEV : loss 0.1529020518064499 - score 0.7413\n",
            "2019-08-03 01:41:00,363 TEST : loss 0.15976935625076294 - score 0.75\n",
            "2019-08-03 01:41:00,792 BAD EPOCHS (no improvement): 4\n",
            "2019-08-03 01:41:00,797 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:41:01,314 epoch 48 - iter 0/118 - loss 0.02288938\n",
            "2019-08-03 01:41:02,332 epoch 48 - iter 11/118 - loss 0.09774795\n",
            "2019-08-03 01:41:03,849 epoch 48 - iter 22/118 - loss 0.10767229\n",
            "2019-08-03 01:41:04,768 epoch 48 - iter 33/118 - loss 0.12074239\n",
            "2019-08-03 01:41:05,729 epoch 48 - iter 44/118 - loss 0.12860048\n",
            "2019-08-03 01:41:06,741 epoch 48 - iter 55/118 - loss 0.13193146\n",
            "2019-08-03 01:41:07,693 epoch 48 - iter 66/118 - loss 0.13455683\n",
            "2019-08-03 01:41:09,060 epoch 48 - iter 77/118 - loss 0.14200206\n",
            "2019-08-03 01:41:09,937 epoch 48 - iter 88/118 - loss 0.14275657\n",
            "2019-08-03 01:41:10,785 epoch 48 - iter 99/118 - loss 0.13898639\n",
            "2019-08-03 01:41:11,675 epoch 48 - iter 110/118 - loss 0.13671809\n",
            "2019-08-03 01:41:12,418 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:41:12,420 EPOCH 48 done: loss 0.1377 - lr 0.0500\n",
            "2019-08-03 01:41:14,303 DEV : loss 0.15499302744865417 - score 0.7463\n",
            "2019-08-03 01:41:16,140 TEST : loss 0.14908646047115326 - score 0.7273\n",
            "2019-08-03 01:41:16,534 BAD EPOCHS (no improvement): 5\n",
            "2019-08-03 01:41:16,540 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:41:17,010 epoch 49 - iter 0/118 - loss 0.07027879\n",
            "2019-08-03 01:41:17,964 epoch 49 - iter 11/118 - loss 0.09776868\n",
            "2019-08-03 01:41:19,439 epoch 49 - iter 22/118 - loss 0.09650759\n",
            "2019-08-03 01:41:20,421 epoch 49 - iter 33/118 - loss 0.09522322\n",
            "2019-08-03 01:41:21,382 epoch 49 - iter 44/118 - loss 0.11236860\n",
            "2019-08-03 01:41:22,346 epoch 49 - iter 55/118 - loss 0.11187027\n",
            "2019-08-03 01:41:23,275 epoch 49 - iter 66/118 - loss 0.11813983\n",
            "2019-08-03 01:41:24,735 epoch 49 - iter 77/118 - loss 0.11728763\n",
            "2019-08-03 01:41:25,758 epoch 49 - iter 88/118 - loss 0.11935612\n",
            "2019-08-03 01:41:26,752 epoch 49 - iter 99/118 - loss 0.11947651\n",
            "2019-08-03 01:41:27,710 epoch 49 - iter 110/118 - loss 0.12342645\n",
            "2019-08-03 01:41:28,496 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:41:28,499 EPOCH 49 done: loss 0.1266 - lr 0.0500\n",
            "2019-08-03 01:41:30,685 DEV : loss 0.16852730512619019 - score 0.75\n",
            "2019-08-03 01:41:32,720 TEST : loss 0.17325188219547272 - score 0.7321\n",
            "Epoch    48: reducing learning rate of group 0 to 2.5000e-02.\n",
            "2019-08-03 01:41:33,122 BAD EPOCHS (no improvement): 6\n",
            "2019-08-03 01:41:33,127 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:41:33,589 epoch 50 - iter 0/118 - loss 0.03526189\n",
            "2019-08-03 01:41:34,505 epoch 50 - iter 11/118 - loss 0.08739420\n",
            "2019-08-03 01:41:35,484 epoch 50 - iter 22/118 - loss 0.11921165\n",
            "2019-08-03 01:41:37,042 epoch 50 - iter 33/118 - loss 0.12696697\n",
            "2019-08-03 01:41:37,995 epoch 50 - iter 44/118 - loss 0.13050224\n",
            "2019-08-03 01:41:38,959 epoch 50 - iter 55/118 - loss 0.12019468\n",
            "2019-08-03 01:41:39,869 epoch 50 - iter 66/118 - loss 0.12287854\n",
            "2019-08-03 01:41:40,884 epoch 50 - iter 77/118 - loss 0.11990005\n",
            "2019-08-03 01:41:41,833 epoch 50 - iter 88/118 - loss 0.11645085\n",
            "2019-08-03 01:41:43,221 epoch 50 - iter 99/118 - loss 0.11507092\n",
            "2019-08-03 01:41:44,204 epoch 50 - iter 110/118 - loss 0.12081356\n",
            "2019-08-03 01:41:44,893 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:41:44,894 EPOCH 50 done: loss 0.1215 - lr 0.0250\n",
            "2019-08-03 01:41:46,258 DEV : loss 0.1584741175174713 - score 0.7448\n",
            "2019-08-03 01:41:48,475 TEST : loss 0.16320784389972687 - score 0.7586\n",
            "2019-08-03 01:41:48,872 BAD EPOCHS (no improvement): 1\n",
            "2019-08-03 01:41:48,878 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:41:49,396 epoch 51 - iter 0/118 - loss 0.18051375\n",
            "2019-08-03 01:41:50,343 epoch 51 - iter 11/118 - loss 0.08909792\n",
            "2019-08-03 01:41:51,337 epoch 51 - iter 22/118 - loss 0.09006240\n",
            "2019-08-03 01:41:52,279 epoch 51 - iter 33/118 - loss 0.09464503\n",
            "2019-08-03 01:41:53,284 epoch 51 - iter 44/118 - loss 0.10267176\n",
            "2019-08-03 01:41:54,754 epoch 51 - iter 55/118 - loss 0.11136779\n",
            "2019-08-03 01:41:55,735 epoch 51 - iter 66/118 - loss 0.11071856\n",
            "2019-08-03 01:41:56,657 epoch 51 - iter 77/118 - loss 0.10653394\n",
            "2019-08-03 01:41:57,609 epoch 51 - iter 88/118 - loss 0.10580046\n",
            "2019-08-03 01:41:58,506 epoch 51 - iter 99/118 - loss 0.11144482\n",
            "2019-08-03 01:41:59,479 epoch 51 - iter 110/118 - loss 0.11468458\n",
            "2019-08-03 01:42:00,518 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:42:00,519 EPOCH 51 done: loss 0.1128 - lr 0.0250\n",
            "2019-08-03 01:42:02,037 DEV : loss 0.15715378522872925 - score 0.7246\n",
            "2019-08-03 01:42:03,841 TEST : loss 0.16359904408454895 - score 0.734\n",
            "2019-08-03 01:42:04,251 BAD EPOCHS (no improvement): 2\n",
            "2019-08-03 01:42:04,256 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:42:04,785 epoch 52 - iter 0/118 - loss 0.07267223\n",
            "2019-08-03 01:42:06,219 epoch 52 - iter 11/118 - loss 0.07408581\n",
            "2019-08-03 01:42:07,175 epoch 52 - iter 22/118 - loss 0.09024436\n",
            "2019-08-03 01:42:08,068 epoch 52 - iter 33/118 - loss 0.11086019\n",
            "2019-08-03 01:42:09,022 epoch 52 - iter 44/118 - loss 0.11042320\n",
            "2019-08-03 01:42:09,915 epoch 52 - iter 55/118 - loss 0.11141925\n",
            "2019-08-03 01:42:11,181 epoch 52 - iter 66/118 - loss 0.11383706\n",
            "2019-08-03 01:42:12,048 epoch 52 - iter 77/118 - loss 0.11511664\n",
            "2019-08-03 01:42:12,969 epoch 52 - iter 88/118 - loss 0.11316594\n",
            "2019-08-03 01:42:13,897 epoch 52 - iter 99/118 - loss 0.11491537\n",
            "2019-08-03 01:42:14,778 epoch 52 - iter 110/118 - loss 0.11643685\n",
            "2019-08-03 01:42:15,544 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:42:15,546 EPOCH 52 done: loss 0.1176 - lr 0.0250\n",
            "2019-08-03 01:42:17,553 DEV : loss 0.15362143516540527 - score 0.76\n",
            "2019-08-03 01:42:19,414 TEST : loss 0.15993072092533112 - score 0.748\n",
            "2019-08-03 01:42:19,806 BAD EPOCHS (no improvement): 3\n",
            "2019-08-03 01:42:19,811 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:42:20,205 epoch 53 - iter 0/118 - loss 0.27240640\n",
            "2019-08-03 01:42:21,135 epoch 53 - iter 11/118 - loss 0.13560720\n",
            "2019-08-03 01:42:22,555 epoch 53 - iter 22/118 - loss 0.12604283\n",
            "2019-08-03 01:42:23,512 epoch 53 - iter 33/118 - loss 0.11636404\n",
            "2019-08-03 01:42:24,548 epoch 53 - iter 44/118 - loss 0.12063573\n",
            "2019-08-03 01:42:25,429 epoch 53 - iter 55/118 - loss 0.12274427\n",
            "2019-08-03 01:42:26,272 epoch 53 - iter 66/118 - loss 0.12126411\n",
            "2019-08-03 01:42:27,186 epoch 53 - iter 77/118 - loss 0.12114980\n",
            "2019-08-03 01:42:28,446 epoch 53 - iter 88/118 - loss 0.12129510\n",
            "2019-08-03 01:42:29,346 epoch 53 - iter 99/118 - loss 0.11920563\n",
            "2019-08-03 01:42:30,217 epoch 53 - iter 110/118 - loss 0.11956550\n",
            "2019-08-03 01:42:30,924 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:42:30,926 EPOCH 53 done: loss 0.1170 - lr 0.0250\n",
            "2019-08-03 01:42:32,315 DEV : loss 0.15337882936000824 - score 0.7671\n",
            "2019-08-03 01:42:34,478 TEST : loss 0.1559281200170517 - score 0.7395\n",
            "2019-08-03 01:42:34,864 BAD EPOCHS (no improvement): 0\n",
            "2019-08-03 01:42:38,657 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:42:39,192 epoch 54 - iter 0/118 - loss 0.10866024\n",
            "2019-08-03 01:42:40,203 epoch 54 - iter 11/118 - loss 0.09309146\n",
            "2019-08-03 01:42:41,130 epoch 54 - iter 22/118 - loss 0.08192944\n",
            "2019-08-03 01:42:42,168 epoch 54 - iter 33/118 - loss 0.09625111\n",
            "2019-08-03 01:42:43,707 epoch 54 - iter 44/118 - loss 0.10963872\n",
            "2019-08-03 01:42:44,711 epoch 54 - iter 55/118 - loss 0.11550292\n",
            "2019-08-03 01:42:45,684 epoch 54 - iter 66/118 - loss 0.12089420\n",
            "2019-08-03 01:42:46,569 epoch 54 - iter 77/118 - loss 0.11995435\n",
            "2019-08-03 01:42:47,433 epoch 54 - iter 88/118 - loss 0.11602196\n",
            "2019-08-03 01:42:48,290 epoch 54 - iter 99/118 - loss 0.11588107\n",
            "2019-08-03 01:42:49,543 epoch 54 - iter 110/118 - loss 0.11726016\n",
            "2019-08-03 01:42:50,254 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:42:50,257 EPOCH 54 done: loss 0.1167 - lr 0.0250\n",
            "2019-08-03 01:42:51,674 DEV : loss 0.16073159873485565 - score 0.755\n",
            "2019-08-03 01:42:53,575 TEST : loss 0.15803635120391846 - score 0.7419\n",
            "2019-08-03 01:42:54,013 BAD EPOCHS (no improvement): 1\n",
            "2019-08-03 01:42:54,018 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:42:54,547 epoch 55 - iter 0/118 - loss 0.08390667\n",
            "2019-08-03 01:42:56,007 epoch 55 - iter 11/118 - loss 0.11397156\n",
            "2019-08-03 01:42:57,025 epoch 55 - iter 22/118 - loss 0.10888280\n",
            "2019-08-03 01:42:57,942 epoch 55 - iter 33/118 - loss 0.10900793\n",
            "2019-08-03 01:42:58,873 epoch 55 - iter 44/118 - loss 0.11514171\n",
            "2019-08-03 01:42:59,895 epoch 55 - iter 55/118 - loss 0.11550894\n",
            "2019-08-03 01:43:01,638 epoch 55 - iter 66/118 - loss 0.11749211\n",
            "2019-08-03 01:43:02,587 epoch 55 - iter 77/118 - loss 0.11703143\n",
            "2019-08-03 01:43:03,921 epoch 55 - iter 88/118 - loss 0.11577220\n",
            "2019-08-03 01:43:05,069 epoch 55 - iter 99/118 - loss 0.11619071\n",
            "2019-08-03 01:43:05,895 epoch 55 - iter 110/118 - loss 0.11431193\n",
            "2019-08-03 01:43:06,905 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:43:06,907 EPOCH 55 done: loss 0.1143 - lr 0.0250\n",
            "2019-08-03 01:43:08,260 DEV : loss 0.15671572089195251 - score 0.7465\n",
            "2019-08-03 01:43:10,015 TEST : loss 0.15766538679599762 - score 0.7304\n",
            "2019-08-03 01:43:10,409 BAD EPOCHS (no improvement): 2\n",
            "2019-08-03 01:43:10,414 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:43:10,864 epoch 56 - iter 0/118 - loss 0.06617521\n",
            "2019-08-03 01:43:12,284 epoch 56 - iter 11/118 - loss 0.13012102\n",
            "2019-08-03 01:43:13,134 epoch 56 - iter 22/118 - loss 0.12486749\n",
            "2019-08-03 01:43:13,946 epoch 56 - iter 33/118 - loss 0.11569022\n",
            "2019-08-03 01:43:14,785 epoch 56 - iter 44/118 - loss 0.12573147\n",
            "2019-08-03 01:43:15,678 epoch 56 - iter 55/118 - loss 0.12120033\n",
            "2019-08-03 01:43:16,596 epoch 56 - iter 66/118 - loss 0.12168193\n",
            "2019-08-03 01:43:17,837 epoch 56 - iter 77/118 - loss 0.12043243\n",
            "2019-08-03 01:43:18,739 epoch 56 - iter 88/118 - loss 0.11400261\n",
            "2019-08-03 01:43:19,591 epoch 56 - iter 99/118 - loss 0.11400693\n",
            "2019-08-03 01:43:20,478 epoch 56 - iter 110/118 - loss 0.11240045\n",
            "2019-08-03 01:43:21,153 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:43:21,159 EPOCH 56 done: loss 0.1149 - lr 0.0250\n",
            "2019-08-03 01:43:23,056 DEV : loss 0.15991203486919403 - score 0.7703\n",
            "2019-08-03 01:43:24,982 TEST : loss 0.16011209785938263 - score 0.7541\n",
            "2019-08-03 01:43:25,374 BAD EPOCHS (no improvement): 0\n",
            "2019-08-03 01:43:29,052 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:43:29,572 epoch 57 - iter 0/118 - loss 0.14286479\n",
            "2019-08-03 01:43:30,545 epoch 57 - iter 11/118 - loss 0.12508145\n",
            "2019-08-03 01:43:31,525 epoch 57 - iter 22/118 - loss 0.12066386\n",
            "2019-08-03 01:43:33,059 epoch 57 - iter 33/118 - loss 0.11787028\n",
            "2019-08-03 01:43:34,007 epoch 57 - iter 44/118 - loss 0.11325103\n",
            "2019-08-03 01:43:34,955 epoch 57 - iter 55/118 - loss 0.11440662\n",
            "2019-08-03 01:43:35,859 epoch 57 - iter 66/118 - loss 0.11595146\n",
            "2019-08-03 01:43:36,794 epoch 57 - iter 77/118 - loss 0.11432162\n",
            "2019-08-03 01:43:38,304 epoch 57 - iter 88/118 - loss 0.11210454\n",
            "2019-08-03 01:43:39,295 epoch 57 - iter 99/118 - loss 0.11431985\n",
            "2019-08-03 01:43:40,296 epoch 57 - iter 110/118 - loss 0.11785297\n",
            "2019-08-03 01:43:41,061 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:43:41,065 EPOCH 57 done: loss 0.1176 - lr 0.0250\n",
            "2019-08-03 01:43:42,680 DEV : loss 0.15550117194652557 - score 0.7671\n",
            "2019-08-03 01:43:45,163 TEST : loss 0.15134868025779724 - score 0.7395\n",
            "2019-08-03 01:43:45,573 BAD EPOCHS (no improvement): 1\n",
            "2019-08-03 01:43:45,579 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:43:46,101 epoch 58 - iter 0/118 - loss 0.07087447\n",
            "2019-08-03 01:43:47,074 epoch 58 - iter 11/118 - loss 0.12143025\n",
            "2019-08-03 01:43:48,092 epoch 58 - iter 22/118 - loss 0.11016535\n",
            "2019-08-03 01:43:49,399 epoch 58 - iter 33/118 - loss 0.11573251\n",
            "2019-08-03 01:43:50,383 epoch 58 - iter 44/118 - loss 0.11766397\n",
            "2019-08-03 01:43:51,305 epoch 58 - iter 55/118 - loss 0.11151077\n",
            "2019-08-03 01:43:52,304 epoch 58 - iter 66/118 - loss 0.11570365\n",
            "2019-08-03 01:43:53,373 epoch 58 - iter 77/118 - loss 0.11172101\n",
            "2019-08-03 01:43:54,870 epoch 58 - iter 88/118 - loss 0.10938934\n",
            "2019-08-03 01:43:55,732 epoch 58 - iter 99/118 - loss 0.10753163\n",
            "2019-08-03 01:43:56,633 epoch 58 - iter 110/118 - loss 0.11217634\n",
            "2019-08-03 01:43:57,322 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:43:57,324 EPOCH 58 done: loss 0.1110 - lr 0.0250\n",
            "2019-08-03 01:43:58,787 DEV : loss 0.16570891439914703 - score 0.7436\n",
            "2019-08-03 01:44:01,452 TEST : loss 0.15787005424499512 - score 0.7402\n",
            "2019-08-03 01:44:01,887 BAD EPOCHS (no improvement): 2\n",
            "2019-08-03 01:44:01,892 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:44:02,355 epoch 59 - iter 0/118 - loss 0.16829138\n",
            "2019-08-03 01:44:03,414 epoch 59 - iter 11/118 - loss 0.11967302\n",
            "2019-08-03 01:44:04,466 epoch 59 - iter 22/118 - loss 0.10655247\n",
            "2019-08-03 01:44:05,498 epoch 59 - iter 33/118 - loss 0.10746510\n",
            "2019-08-03 01:44:07,044 epoch 59 - iter 44/118 - loss 0.11693447\n",
            "2019-08-03 01:44:08,048 epoch 59 - iter 55/118 - loss 0.11618847\n",
            "2019-08-03 01:44:08,996 epoch 59 - iter 66/118 - loss 0.11809555\n",
            "2019-08-03 01:44:09,965 epoch 59 - iter 77/118 - loss 0.11803909\n",
            "2019-08-03 01:44:10,941 epoch 59 - iter 88/118 - loss 0.11490920\n",
            "2019-08-03 01:44:12,306 epoch 59 - iter 99/118 - loss 0.11750480\n",
            "2019-08-03 01:44:13,364 epoch 59 - iter 110/118 - loss 0.11261041\n",
            "2019-08-03 01:44:14,247 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:44:14,256 EPOCH 59 done: loss 0.1133 - lr 0.0250\n",
            "2019-08-03 01:44:15,778 DEV : loss 0.16046233475208282 - score 0.7647\n",
            "2019-08-03 01:44:18,312 TEST : loss 0.16123738884925842 - score 0.7273\n",
            "2019-08-03 01:44:18,738 BAD EPOCHS (no improvement): 3\n",
            "2019-08-03 01:44:18,743 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:44:19,159 epoch 60 - iter 0/118 - loss 0.13426784\n",
            "2019-08-03 01:44:20,094 epoch 60 - iter 11/118 - loss 0.09618999\n",
            "2019-08-03 01:44:20,989 epoch 60 - iter 22/118 - loss 0.09172046\n",
            "2019-08-03 01:44:21,933 epoch 60 - iter 33/118 - loss 0.09996138\n",
            "2019-08-03 01:44:22,882 epoch 60 - iter 44/118 - loss 0.09862747\n",
            "2019-08-03 01:44:24,424 epoch 60 - iter 55/118 - loss 0.10124331\n",
            "2019-08-03 01:44:25,372 epoch 60 - iter 66/118 - loss 0.10355585\n",
            "2019-08-03 01:44:26,295 epoch 60 - iter 77/118 - loss 0.10326131\n",
            "2019-08-03 01:44:27,261 epoch 60 - iter 88/118 - loss 0.10142315\n",
            "2019-08-03 01:44:28,188 epoch 60 - iter 99/118 - loss 0.10614447\n",
            "2019-08-03 01:44:29,513 epoch 60 - iter 110/118 - loss 0.10765899\n",
            "2019-08-03 01:44:30,220 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:44:30,223 EPOCH 60 done: loss 0.1105 - lr 0.0250\n",
            "2019-08-03 01:44:31,590 DEV : loss 0.16296790540218353 - score 0.7703\n",
            "2019-08-03 01:44:34,037 TEST : loss 0.16102585196495056 - score 0.72\n",
            "2019-08-03 01:44:34,461 BAD EPOCHS (no improvement): 4\n",
            "2019-08-03 01:44:38,425 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:44:38,989 epoch 61 - iter 0/118 - loss 0.18033731\n",
            "2019-08-03 01:44:40,072 epoch 61 - iter 11/118 - loss 0.10369680\n",
            "2019-08-03 01:44:41,065 epoch 61 - iter 22/118 - loss 0.09892831\n",
            "2019-08-03 01:44:42,075 epoch 61 - iter 33/118 - loss 0.10501812\n",
            "2019-08-03 01:44:43,163 epoch 61 - iter 44/118 - loss 0.10058840\n",
            "2019-08-03 01:44:44,735 epoch 61 - iter 55/118 - loss 0.11121519\n",
            "2019-08-03 01:44:45,677 epoch 61 - iter 66/118 - loss 0.10778327\n",
            "2019-08-03 01:44:46,530 epoch 61 - iter 77/118 - loss 0.11339830\n",
            "2019-08-03 01:44:47,445 epoch 61 - iter 88/118 - loss 0.11253091\n",
            "2019-08-03 01:44:48,383 epoch 61 - iter 99/118 - loss 0.11154282\n",
            "2019-08-03 01:44:49,629 epoch 61 - iter 110/118 - loss 0.11175876\n",
            "2019-08-03 01:44:50,369 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:44:50,370 EPOCH 61 done: loss 0.1128 - lr 0.0250\n",
            "2019-08-03 01:44:51,711 DEV : loss 0.16140851378440857 - score 0.7483\n",
            "2019-08-03 01:44:53,431 TEST : loss 0.16492539644241333 - score 0.7419\n",
            "2019-08-03 01:44:53,865 BAD EPOCHS (no improvement): 5\n",
            "2019-08-03 01:44:53,870 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:44:54,377 epoch 62 - iter 0/118 - loss 0.10413890\n",
            "2019-08-03 01:44:55,905 epoch 62 - iter 11/118 - loss 0.07706463\n",
            "2019-08-03 01:44:56,859 epoch 62 - iter 22/118 - loss 0.09344412\n",
            "2019-08-03 01:44:57,751 epoch 62 - iter 33/118 - loss 0.10822290\n",
            "2019-08-03 01:44:58,678 epoch 62 - iter 44/118 - loss 0.11089381\n",
            "2019-08-03 01:44:59,584 epoch 62 - iter 55/118 - loss 0.10784343\n",
            "2019-08-03 01:45:00,856 epoch 62 - iter 66/118 - loss 0.11192485\n",
            "2019-08-03 01:45:01,778 epoch 62 - iter 77/118 - loss 0.11361570\n",
            "2019-08-03 01:45:02,665 epoch 62 - iter 88/118 - loss 0.11181688\n",
            "2019-08-03 01:45:03,588 epoch 62 - iter 99/118 - loss 0.10874310\n",
            "2019-08-03 01:45:04,456 epoch 62 - iter 110/118 - loss 0.11239544\n",
            "2019-08-03 01:45:05,167 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:45:05,170 EPOCH 62 done: loss 0.1136 - lr 0.0250\n",
            "2019-08-03 01:45:07,075 DEV : loss 0.16293996572494507 - score 0.7571\n",
            "2019-08-03 01:45:08,835 TEST : loss 0.15704511106014252 - score 0.7368\n",
            "Epoch    61: reducing learning rate of group 0 to 1.2500e-02.\n",
            "2019-08-03 01:45:09,265 BAD EPOCHS (no improvement): 6\n",
            "2019-08-03 01:45:09,270 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:45:09,791 epoch 63 - iter 0/118 - loss 0.02661016\n",
            "2019-08-03 01:45:10,777 epoch 63 - iter 11/118 - loss 0.12068222\n",
            "2019-08-03 01:45:11,778 epoch 63 - iter 22/118 - loss 0.09774634\n",
            "2019-08-03 01:45:13,406 epoch 63 - iter 33/118 - loss 0.11070105\n",
            "2019-08-03 01:45:14,339 epoch 63 - iter 44/118 - loss 0.10823967\n",
            "2019-08-03 01:45:15,301 epoch 63 - iter 55/118 - loss 0.10205541\n",
            "2019-08-03 01:45:16,264 epoch 63 - iter 66/118 - loss 0.10200793\n",
            "2019-08-03 01:45:17,220 epoch 63 - iter 77/118 - loss 0.10052312\n",
            "2019-08-03 01:45:18,723 epoch 63 - iter 88/118 - loss 0.10078035\n",
            "2019-08-03 01:45:19,681 epoch 63 - iter 99/118 - loss 0.10428931\n",
            "2019-08-03 01:45:20,613 epoch 63 - iter 110/118 - loss 0.10243865\n",
            "2019-08-03 01:45:21,367 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:45:21,369 EPOCH 63 done: loss 0.0992 - lr 0.0125\n",
            "2019-08-03 01:45:22,980 DEV : loss 0.16024285554885864 - score 0.7671\n",
            "2019-08-03 01:45:25,516 TEST : loss 0.15836752951145172 - score 0.7438\n",
            "2019-08-03 01:45:25,906 BAD EPOCHS (no improvement): 1\n",
            "2019-08-03 01:45:25,911 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:45:26,459 epoch 64 - iter 0/118 - loss 0.06742670\n",
            "2019-08-03 01:45:27,443 epoch 64 - iter 11/118 - loss 0.09164760\n",
            "2019-08-03 01:45:28,390 epoch 64 - iter 22/118 - loss 0.08302053\n",
            "2019-08-03 01:45:29,305 epoch 64 - iter 33/118 - loss 0.09041572\n",
            "2019-08-03 01:45:30,690 epoch 64 - iter 44/118 - loss 0.09456559\n",
            "2019-08-03 01:45:31,557 epoch 64 - iter 55/118 - loss 0.10648527\n",
            "2019-08-03 01:45:32,500 epoch 64 - iter 66/118 - loss 0.10919623\n",
            "2019-08-03 01:45:33,363 epoch 64 - iter 77/118 - loss 0.11296348\n",
            "2019-08-03 01:45:34,260 epoch 64 - iter 88/118 - loss 0.10930713\n",
            "2019-08-03 01:45:35,730 epoch 64 - iter 99/118 - loss 0.10819845\n",
            "2019-08-03 01:45:36,623 epoch 64 - iter 110/118 - loss 0.10619037\n",
            "2019-08-03 01:45:37,310 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:45:37,312 EPOCH 64 done: loss 0.1091 - lr 0.0125\n",
            "2019-08-03 01:45:38,759 DEV : loss 0.16760021448135376 - score 0.7436\n",
            "2019-08-03 01:45:41,116 TEST : loss 0.16455285251140594 - score 0.7385\n",
            "2019-08-03 01:45:41,511 BAD EPOCHS (no improvement): 2\n",
            "2019-08-03 01:45:41,516 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:45:41,939 epoch 65 - iter 0/118 - loss 0.05089821\n",
            "2019-08-03 01:45:42,972 epoch 65 - iter 11/118 - loss 0.12148117\n",
            "2019-08-03 01:45:43,932 epoch 65 - iter 22/118 - loss 0.10207081\n",
            "2019-08-03 01:45:44,852 epoch 65 - iter 33/118 - loss 0.10307647\n",
            "2019-08-03 01:45:45,846 epoch 65 - iter 44/118 - loss 0.09724480\n",
            "2019-08-03 01:45:47,245 epoch 65 - iter 55/118 - loss 0.09607607\n",
            "2019-08-03 01:45:48,147 epoch 65 - iter 66/118 - loss 0.09747905\n",
            "2019-08-03 01:45:49,067 epoch 65 - iter 77/118 - loss 0.09997685\n",
            "2019-08-03 01:45:49,976 epoch 65 - iter 88/118 - loss 0.10110916\n",
            "2019-08-03 01:45:50,912 epoch 65 - iter 99/118 - loss 0.10392905\n",
            "2019-08-03 01:45:52,347 epoch 65 - iter 110/118 - loss 0.10228883\n",
            "2019-08-03 01:45:53,081 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:45:53,088 EPOCH 65 done: loss 0.1061 - lr 0.0125\n",
            "2019-08-03 01:45:54,644 DEV : loss 0.1705106943845749 - score 0.7564\n",
            "2019-08-03 01:45:56,562 TEST : loss 0.16731415688991547 - score 0.7329\n",
            "2019-08-03 01:45:56,997 BAD EPOCHS (no improvement): 3\n",
            "2019-08-03 01:45:57,003 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:45:58,705 epoch 66 - iter 0/118 - loss 0.01943128\n",
            "2019-08-03 01:45:59,660 epoch 66 - iter 11/118 - loss 0.08251261\n",
            "2019-08-03 01:46:00,551 epoch 66 - iter 22/118 - loss 0.10710656\n",
            "2019-08-03 01:46:01,413 epoch 66 - iter 33/118 - loss 0.09722286\n",
            "2019-08-03 01:46:02,267 epoch 66 - iter 44/118 - loss 0.10122265\n",
            "2019-08-03 01:46:03,475 epoch 66 - iter 55/118 - loss 0.10121885\n",
            "2019-08-03 01:46:04,333 epoch 66 - iter 66/118 - loss 0.10752743\n",
            "2019-08-03 01:46:05,209 epoch 66 - iter 77/118 - loss 0.11352204\n",
            "2019-08-03 01:46:06,052 epoch 66 - iter 88/118 - loss 0.11301150\n",
            "2019-08-03 01:46:06,929 epoch 66 - iter 99/118 - loss 0.11092593\n",
            "2019-08-03 01:46:07,800 epoch 66 - iter 110/118 - loss 0.11058689\n",
            "2019-08-03 01:46:08,815 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:46:08,817 EPOCH 66 done: loss 0.1105 - lr 0.0125\n",
            "2019-08-03 01:46:10,171 DEV : loss 0.17280755937099457 - score 0.7422\n",
            "2019-08-03 01:46:12,036 TEST : loss 0.17012952268123627 - score 0.7218\n",
            "2019-08-03 01:46:12,443 BAD EPOCHS (no improvement): 4\n",
            "2019-08-03 01:46:12,449 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:46:12,996 epoch 67 - iter 0/118 - loss 0.13996413\n",
            "2019-08-03 01:46:14,623 epoch 67 - iter 11/118 - loss 0.07886539\n",
            "2019-08-03 01:46:15,605 epoch 67 - iter 22/118 - loss 0.07518125\n",
            "2019-08-03 01:46:16,509 epoch 67 - iter 33/118 - loss 0.08252188\n",
            "2019-08-03 01:46:17,462 epoch 67 - iter 44/118 - loss 0.08930669\n",
            "2019-08-03 01:46:18,374 epoch 67 - iter 55/118 - loss 0.09770686\n",
            "2019-08-03 01:46:19,338 epoch 67 - iter 66/118 - loss 0.09794359\n",
            "2019-08-03 01:46:20,581 epoch 67 - iter 77/118 - loss 0.09552328\n",
            "2019-08-03 01:46:21,540 epoch 67 - iter 88/118 - loss 0.09810230\n",
            "2019-08-03 01:46:22,475 epoch 67 - iter 99/118 - loss 0.09714171\n",
            "2019-08-03 01:46:23,371 epoch 67 - iter 110/118 - loss 0.10131787\n",
            "2019-08-03 01:46:24,098 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:46:24,100 EPOCH 67 done: loss 0.1027 - lr 0.0125\n",
            "2019-08-03 01:46:25,557 DEV : loss 0.15844807028770447 - score 0.7671\n",
            "2019-08-03 01:46:28,082 TEST : loss 0.1580694168806076 - score 0.7438\n",
            "2019-08-03 01:46:28,484 BAD EPOCHS (no improvement): 5\n",
            "2019-08-03 01:46:28,490 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:46:29,042 epoch 68 - iter 0/118 - loss 0.11877991\n",
            "2019-08-03 01:46:30,107 epoch 68 - iter 11/118 - loss 0.08690325\n",
            "2019-08-03 01:46:31,144 epoch 68 - iter 22/118 - loss 0.09278953\n",
            "2019-08-03 01:46:32,035 epoch 68 - iter 33/118 - loss 0.09013804\n",
            "2019-08-03 01:46:33,360 epoch 68 - iter 44/118 - loss 0.09086155\n",
            "2019-08-03 01:46:34,310 epoch 68 - iter 55/118 - loss 0.09337656\n",
            "2019-08-03 01:46:35,337 epoch 68 - iter 66/118 - loss 0.09754114\n",
            "2019-08-03 01:46:36,192 epoch 68 - iter 77/118 - loss 0.09554706\n",
            "2019-08-03 01:46:37,094 epoch 68 - iter 88/118 - loss 0.09648622\n",
            "2019-08-03 01:46:37,969 epoch 68 - iter 99/118 - loss 0.10008400\n",
            "2019-08-03 01:46:39,125 epoch 68 - iter 110/118 - loss 0.10135422\n",
            "2019-08-03 01:46:39,888 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:46:39,890 EPOCH 68 done: loss 0.1021 - lr 0.0125\n",
            "2019-08-03 01:46:41,236 DEV : loss 0.1656244397163391 - score 0.7484\n",
            "2019-08-03 01:46:43,015 TEST : loss 0.16385816037654877 - score 0.7442\n",
            "Epoch    67: reducing learning rate of group 0 to 6.2500e-03.\n",
            "2019-08-03 01:46:43,416 BAD EPOCHS (no improvement): 6\n",
            "2019-08-03 01:46:43,420 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:46:43,866 epoch 69 - iter 0/118 - loss 0.05733600\n",
            "2019-08-03 01:46:45,337 epoch 69 - iter 11/118 - loss 0.08657977\n",
            "2019-08-03 01:46:46,209 epoch 69 - iter 22/118 - loss 0.10609416\n",
            "2019-08-03 01:46:47,151 epoch 69 - iter 33/118 - loss 0.11862770\n",
            "2019-08-03 01:46:48,099 epoch 69 - iter 44/118 - loss 0.10517089\n",
            "2019-08-03 01:46:49,086 epoch 69 - iter 55/118 - loss 0.10316766\n",
            "2019-08-03 01:46:49,993 epoch 69 - iter 66/118 - loss 0.10302987\n",
            "2019-08-03 01:46:51,418 epoch 69 - iter 77/118 - loss 0.10122166\n",
            "2019-08-03 01:46:52,302 epoch 69 - iter 88/118 - loss 0.09839157\n",
            "2019-08-03 01:46:53,316 epoch 69 - iter 99/118 - loss 0.09655953\n",
            "2019-08-03 01:46:54,184 epoch 69 - iter 110/118 - loss 0.09850969\n",
            "2019-08-03 01:46:54,952 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:46:54,958 EPOCH 69 done: loss 0.1016 - lr 0.0063\n",
            "2019-08-03 01:46:56,870 DEV : loss 0.1630983203649521 - score 0.7682\n",
            "2019-08-03 01:46:58,786 TEST : loss 0.16046811640262604 - score 0.7619\n",
            "2019-08-03 01:46:59,181 BAD EPOCHS (no improvement): 1\n",
            "2019-08-03 01:46:59,187 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:46:59,661 epoch 70 - iter 0/118 - loss 0.04056346\n",
            "2019-08-03 01:47:00,662 epoch 70 - iter 11/118 - loss 0.09432713\n",
            "2019-08-03 01:47:01,661 epoch 70 - iter 22/118 - loss 0.08111247\n",
            "2019-08-03 01:47:03,262 epoch 70 - iter 33/118 - loss 0.08453570\n",
            "2019-08-03 01:47:04,120 epoch 70 - iter 44/118 - loss 0.08714327\n",
            "2019-08-03 01:47:05,082 epoch 70 - iter 55/118 - loss 0.08855716\n",
            "2019-08-03 01:47:05,993 epoch 70 - iter 66/118 - loss 0.09641322\n",
            "2019-08-03 01:47:06,887 epoch 70 - iter 77/118 - loss 0.09745617\n",
            "2019-08-03 01:47:08,391 epoch 70 - iter 88/118 - loss 0.09997744\n",
            "2019-08-03 01:47:09,437 epoch 70 - iter 99/118 - loss 0.10374673\n",
            "2019-08-03 01:47:10,348 epoch 70 - iter 110/118 - loss 0.10298627\n",
            "2019-08-03 01:47:11,016 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:47:11,018 EPOCH 70 done: loss 0.1009 - lr 0.0063\n",
            "2019-08-03 01:47:12,360 DEV : loss 0.16662396490573883 - score 0.7582\n",
            "2019-08-03 01:47:14,680 TEST : loss 0.1638309210538864 - score 0.7329\n",
            "2019-08-03 01:47:15,075 BAD EPOCHS (no improvement): 2\n",
            "2019-08-03 01:47:15,085 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:47:15,637 epoch 71 - iter 0/118 - loss 0.13074856\n",
            "2019-08-03 01:47:16,631 epoch 71 - iter 11/118 - loss 0.12333989\n",
            "2019-08-03 01:47:17,603 epoch 71 - iter 22/118 - loss 0.11676386\n",
            "2019-08-03 01:47:18,538 epoch 71 - iter 33/118 - loss 0.10212321\n",
            "2019-08-03 01:47:20,131 epoch 71 - iter 44/118 - loss 0.10451647\n",
            "2019-08-03 01:47:21,114 epoch 71 - iter 55/118 - loss 0.10666806\n",
            "2019-08-03 01:47:22,048 epoch 71 - iter 66/118 - loss 0.10429385\n",
            "2019-08-03 01:47:23,076 epoch 71 - iter 77/118 - loss 0.10090778\n",
            "2019-08-03 01:47:23,995 epoch 71 - iter 88/118 - loss 0.10015494\n",
            "2019-08-03 01:47:25,506 epoch 71 - iter 99/118 - loss 0.09922840\n",
            "2019-08-03 01:47:26,447 epoch 71 - iter 110/118 - loss 0.09738410\n",
            "2019-08-03 01:47:27,180 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:47:27,182 EPOCH 71 done: loss 0.0982 - lr 0.0063\n",
            "2019-08-03 01:47:28,653 DEV : loss 0.16500414907932281 - score 0.7785\n",
            "2019-08-03 01:47:31,197 TEST : loss 0.16151615977287292 - score 0.752\n",
            "2019-08-03 01:47:31,602 BAD EPOCHS (no improvement): 0\n",
            "2019-08-03 01:47:35,618 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:47:36,044 epoch 72 - iter 0/118 - loss 0.04306403\n",
            "2019-08-03 01:47:36,965 epoch 72 - iter 11/118 - loss 0.09430690\n",
            "2019-08-03 01:47:37,933 epoch 72 - iter 22/118 - loss 0.08964111\n",
            "2019-08-03 01:47:38,896 epoch 72 - iter 33/118 - loss 0.09199750\n",
            "2019-08-03 01:47:39,807 epoch 72 - iter 44/118 - loss 0.09291480\n",
            "2019-08-03 01:47:41,054 epoch 72 - iter 55/118 - loss 0.10056044\n",
            "2019-08-03 01:47:42,070 epoch 72 - iter 66/118 - loss 0.09682046\n",
            "2019-08-03 01:47:43,004 epoch 72 - iter 77/118 - loss 0.09728525\n",
            "2019-08-03 01:47:43,920 epoch 72 - iter 88/118 - loss 0.09710342\n",
            "2019-08-03 01:47:44,817 epoch 72 - iter 99/118 - loss 0.09978857\n",
            "2019-08-03 01:47:46,244 epoch 72 - iter 110/118 - loss 0.10069614\n",
            "2019-08-03 01:47:46,936 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:47:46,941 EPOCH 72 done: loss 0.0992 - lr 0.0063\n",
            "2019-08-03 01:47:48,430 DEV : loss 0.16593265533447266 - score 0.7682\n",
            "2019-08-03 01:47:50,216 TEST : loss 0.16311407089233398 - score 0.7402\n",
            "2019-08-03 01:47:51,176 BAD EPOCHS (no improvement): 1\n",
            "2019-08-03 01:47:51,182 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:47:51,730 epoch 73 - iter 0/118 - loss 0.08153404\n",
            "2019-08-03 01:47:52,820 epoch 73 - iter 11/118 - loss 0.12730148\n",
            "2019-08-03 01:47:53,821 epoch 73 - iter 22/118 - loss 0.10482908\n",
            "2019-08-03 01:47:54,775 epoch 73 - iter 33/118 - loss 0.10389200\n",
            "2019-08-03 01:47:55,726 epoch 73 - iter 44/118 - loss 0.10151295\n",
            "2019-08-03 01:47:57,150 epoch 73 - iter 55/118 - loss 0.09352443\n",
            "2019-08-03 01:47:58,086 epoch 73 - iter 66/118 - loss 0.09984194\n",
            "2019-08-03 01:47:59,032 epoch 73 - iter 77/118 - loss 0.09892661\n",
            "2019-08-03 01:47:59,996 epoch 73 - iter 88/118 - loss 0.09935040\n",
            "2019-08-03 01:48:00,934 epoch 73 - iter 99/118 - loss 0.09840910\n",
            "2019-08-03 01:48:02,375 epoch 73 - iter 110/118 - loss 0.09561967\n",
            "2019-08-03 01:48:03,123 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:48:03,124 EPOCH 73 done: loss 0.0945 - lr 0.0063\n",
            "2019-08-03 01:48:04,659 DEV : loss 0.16354547441005707 - score 0.7671\n",
            "2019-08-03 01:48:06,630 TEST : loss 0.16126234829425812 - score 0.7603\n",
            "2019-08-03 01:48:07,014 BAD EPOCHS (no improvement): 2\n",
            "2019-08-03 01:48:07,020 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:48:07,462 epoch 74 - iter 0/118 - loss 0.02882040\n",
            "2019-08-03 01:48:09,041 epoch 74 - iter 11/118 - loss 0.12539886\n",
            "2019-08-03 01:48:09,992 epoch 74 - iter 22/118 - loss 0.09944263\n",
            "2019-08-03 01:48:10,914 epoch 74 - iter 33/118 - loss 0.09675722\n",
            "2019-08-03 01:48:11,877 epoch 74 - iter 44/118 - loss 0.09873120\n",
            "2019-08-03 01:48:12,829 epoch 74 - iter 55/118 - loss 0.09963618\n",
            "2019-08-03 01:48:14,293 epoch 74 - iter 66/118 - loss 0.10064587\n",
            "2019-08-03 01:48:15,273 epoch 74 - iter 77/118 - loss 0.09856191\n",
            "2019-08-03 01:48:16,235 epoch 74 - iter 88/118 - loss 0.09876362\n",
            "2019-08-03 01:48:17,175 epoch 74 - iter 99/118 - loss 0.09631836\n",
            "2019-08-03 01:48:18,044 epoch 74 - iter 110/118 - loss 0.09677626\n",
            "2019-08-03 01:48:19,285 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:48:19,289 EPOCH 74 done: loss 0.0950 - lr 0.0063\n",
            "2019-08-03 01:48:20,834 DEV : loss 0.1647423952817917 - score 0.7755\n",
            "2019-08-03 01:48:22,695 TEST : loss 0.1602577418088913 - score 0.752\n",
            "2019-08-03 01:48:23,086 BAD EPOCHS (no improvement): 3\n",
            "2019-08-03 01:48:23,092 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:48:23,544 epoch 75 - iter 0/118 - loss 0.05496728\n",
            "2019-08-03 01:48:24,528 epoch 75 - iter 11/118 - loss 0.08008476\n",
            "2019-08-03 01:48:26,125 epoch 75 - iter 22/118 - loss 0.08792718\n",
            "2019-08-03 01:48:27,043 epoch 75 - iter 33/118 - loss 0.09397497\n",
            "2019-08-03 01:48:28,007 epoch 75 - iter 44/118 - loss 0.09565722\n",
            "2019-08-03 01:48:28,962 epoch 75 - iter 55/118 - loss 0.10103489\n",
            "2019-08-03 01:48:29,831 epoch 75 - iter 66/118 - loss 0.09955205\n",
            "2019-08-03 01:48:31,315 epoch 75 - iter 77/118 - loss 0.09856863\n",
            "2019-08-03 01:48:32,148 epoch 75 - iter 88/118 - loss 0.09808112\n",
            "2019-08-03 01:48:33,020 epoch 75 - iter 99/118 - loss 0.09888399\n",
            "2019-08-03 01:48:33,876 epoch 75 - iter 110/118 - loss 0.09528515\n",
            "2019-08-03 01:48:34,592 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:48:34,594 EPOCH 75 done: loss 0.0937 - lr 0.0063\n",
            "2019-08-03 01:48:36,735 DEV : loss 0.16523653268814087 - score 0.7785\n",
            "2019-08-03 01:48:38,584 TEST : loss 0.16013848781585693 - score 0.7461\n",
            "2019-08-03 01:48:39,009 BAD EPOCHS (no improvement): 4\n",
            "2019-08-03 01:48:42,924 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:48:43,465 epoch 76 - iter 0/118 - loss 0.06890643\n",
            "2019-08-03 01:48:44,473 epoch 76 - iter 11/118 - loss 0.04926532\n",
            "2019-08-03 01:48:45,491 epoch 76 - iter 22/118 - loss 0.06300555\n",
            "2019-08-03 01:48:46,949 epoch 76 - iter 33/118 - loss 0.08284348\n",
            "2019-08-03 01:48:47,852 epoch 76 - iter 44/118 - loss 0.08293706\n",
            "2019-08-03 01:48:48,775 epoch 76 - iter 55/118 - loss 0.08949762\n",
            "2019-08-03 01:48:49,733 epoch 76 - iter 66/118 - loss 0.09507737\n",
            "2019-08-03 01:48:50,731 epoch 76 - iter 77/118 - loss 0.09696965\n",
            "2019-08-03 01:48:52,042 epoch 76 - iter 88/118 - loss 0.09439574\n",
            "2019-08-03 01:48:52,987 epoch 76 - iter 99/118 - loss 0.09359975\n",
            "2019-08-03 01:48:53,855 epoch 76 - iter 110/118 - loss 0.09684265\n",
            "2019-08-03 01:48:54,560 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:48:54,562 EPOCH 76 done: loss 0.0967 - lr 0.0063\n",
            "2019-08-03 01:48:56,036 DEV : loss 0.1644815057516098 - score 0.7619\n",
            "2019-08-03 01:48:58,274 TEST : loss 0.15831919014453888 - score 0.752\n",
            "2019-08-03 01:48:58,692 BAD EPOCHS (no improvement): 5\n",
            "2019-08-03 01:48:58,698 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:48:59,217 epoch 77 - iter 0/118 - loss 0.05581994\n",
            "2019-08-03 01:49:00,162 epoch 77 - iter 11/118 - loss 0.07633835\n",
            "2019-08-03 01:49:01,195 epoch 77 - iter 22/118 - loss 0.09714702\n",
            "2019-08-03 01:49:02,085 epoch 77 - iter 33/118 - loss 0.10922108\n",
            "2019-08-03 01:49:03,473 epoch 77 - iter 44/118 - loss 0.10182289\n",
            "2019-08-03 01:49:04,400 epoch 77 - iter 55/118 - loss 0.10221409\n",
            "2019-08-03 01:49:05,360 epoch 77 - iter 66/118 - loss 0.10079268\n",
            "2019-08-03 01:49:06,251 epoch 77 - iter 77/118 - loss 0.09908499\n",
            "2019-08-03 01:49:07,113 epoch 77 - iter 88/118 - loss 0.09547105\n",
            "2019-08-03 01:49:08,359 epoch 77 - iter 99/118 - loss 0.09835111\n",
            "2019-08-03 01:49:09,329 epoch 77 - iter 110/118 - loss 0.09707836\n",
            "2019-08-03 01:49:10,016 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:49:10,018 EPOCH 77 done: loss 0.0964 - lr 0.0063\n",
            "2019-08-03 01:49:11,543 DEV : loss 0.16686849296092987 - score 0.7785\n",
            "2019-08-03 01:49:13,972 TEST : loss 0.16177323460578918 - score 0.7461\n",
            "Epoch    76: reducing learning rate of group 0 to 3.1250e-03.\n",
            "2019-08-03 01:49:14,409 BAD EPOCHS (no improvement): 6\n",
            "2019-08-03 01:49:18,521 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:49:19,095 epoch 78 - iter 0/118 - loss 0.03066277\n",
            "2019-08-03 01:49:20,297 epoch 78 - iter 11/118 - loss 0.08426843\n",
            "2019-08-03 01:49:21,369 epoch 78 - iter 22/118 - loss 0.08608564\n",
            "2019-08-03 01:49:22,418 epoch 78 - iter 33/118 - loss 0.08865806\n",
            "2019-08-03 01:49:23,476 epoch 78 - iter 44/118 - loss 0.08780056\n",
            "2019-08-03 01:49:25,105 epoch 78 - iter 55/118 - loss 0.09428597\n",
            "2019-08-03 01:49:26,039 epoch 78 - iter 66/118 - loss 0.09328955\n",
            "2019-08-03 01:49:26,991 epoch 78 - iter 77/118 - loss 0.09440417\n",
            "2019-08-03 01:49:27,912 epoch 78 - iter 88/118 - loss 0.09589623\n",
            "2019-08-03 01:49:28,784 epoch 78 - iter 99/118 - loss 0.09973103\n",
            "2019-08-03 01:49:30,204 epoch 78 - iter 110/118 - loss 0.10164216\n",
            "2019-08-03 01:49:30,967 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:49:30,969 EPOCH 78 done: loss 0.1029 - lr 0.0031\n",
            "2019-08-03 01:49:32,499 DEV : loss 0.16684465110301971 - score 0.7682\n",
            "2019-08-03 01:49:34,302 TEST : loss 0.16186457872390747 - score 0.7402\n",
            "2019-08-03 01:49:34,708 BAD EPOCHS (no improvement): 1\n",
            "2019-08-03 01:49:34,714 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:49:35,169 epoch 79 - iter 0/118 - loss 0.06655448\n",
            "2019-08-03 01:49:36,801 epoch 79 - iter 11/118 - loss 0.07691866\n",
            "2019-08-03 01:49:37,797 epoch 79 - iter 22/118 - loss 0.07751846\n",
            "2019-08-03 01:49:38,730 epoch 79 - iter 33/118 - loss 0.08201025\n",
            "2019-08-03 01:49:39,663 epoch 79 - iter 44/118 - loss 0.07939299\n",
            "2019-08-03 01:49:40,613 epoch 79 - iter 55/118 - loss 0.08785145\n",
            "2019-08-03 01:49:41,510 epoch 79 - iter 66/118 - loss 0.08407070\n",
            "2019-08-03 01:49:43,065 epoch 79 - iter 77/118 - loss 0.08958399\n",
            "2019-08-03 01:49:43,998 epoch 79 - iter 88/118 - loss 0.08791666\n",
            "2019-08-03 01:49:44,860 epoch 79 - iter 99/118 - loss 0.08776084\n",
            "2019-08-03 01:49:45,721 epoch 79 - iter 110/118 - loss 0.08726733\n",
            "2019-08-03 01:49:46,393 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:49:46,399 EPOCH 79 done: loss 0.0905 - lr 0.0031\n",
            "2019-08-03 01:49:48,543 DEV : loss 0.16596370935440063 - score 0.7785\n",
            "2019-08-03 01:49:50,334 TEST : loss 0.1618056744337082 - score 0.7402\n",
            "2019-08-03 01:49:50,725 BAD EPOCHS (no improvement): 2\n",
            "2019-08-03 01:49:54,592 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:49:55,119 epoch 80 - iter 0/118 - loss 0.01658398\n",
            "2019-08-03 01:49:56,082 epoch 80 - iter 11/118 - loss 0.10914909\n",
            "2019-08-03 01:49:57,018 epoch 80 - iter 22/118 - loss 0.10643330\n",
            "2019-08-03 01:49:58,358 epoch 80 - iter 33/118 - loss 0.09632900\n",
            "2019-08-03 01:49:59,249 epoch 80 - iter 44/118 - loss 0.09743082\n",
            "2019-08-03 01:50:00,099 epoch 80 - iter 55/118 - loss 0.09060284\n",
            "2019-08-03 01:50:01,038 epoch 80 - iter 66/118 - loss 0.08974325\n",
            "2019-08-03 01:50:02,032 epoch 80 - iter 77/118 - loss 0.09450750\n",
            "2019-08-03 01:50:03,533 epoch 80 - iter 88/118 - loss 0.09439312\n",
            "2019-08-03 01:50:04,479 epoch 80 - iter 99/118 - loss 0.09539942\n",
            "2019-08-03 01:50:05,451 epoch 80 - iter 110/118 - loss 0.09548752\n",
            "2019-08-03 01:50:06,205 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:50:06,207 EPOCH 80 done: loss 0.0960 - lr 0.0031\n",
            "2019-08-03 01:50:07,650 DEV : loss 0.16791532933712006 - score 0.7631\n",
            "2019-08-03 01:50:10,013 TEST : loss 0.1640215814113617 - score 0.75\n",
            "2019-08-03 01:50:10,438 BAD EPOCHS (no improvement): 3\n",
            "2019-08-03 01:50:10,443 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:50:10,877 epoch 81 - iter 0/118 - loss 0.03141765\n",
            "2019-08-03 01:50:11,907 epoch 81 - iter 11/118 - loss 0.11718371\n",
            "2019-08-03 01:50:12,916 epoch 81 - iter 22/118 - loss 0.09935872\n",
            "2019-08-03 01:50:13,812 epoch 81 - iter 33/118 - loss 0.09215287\n",
            "2019-08-03 01:50:15,437 epoch 81 - iter 44/118 - loss 0.09790489\n",
            "2019-08-03 01:50:16,340 epoch 81 - iter 55/118 - loss 0.09568534\n",
            "2019-08-03 01:50:17,287 epoch 81 - iter 66/118 - loss 0.09794901\n",
            "2019-08-03 01:50:18,211 epoch 81 - iter 77/118 - loss 0.09466365\n",
            "2019-08-03 01:50:19,103 epoch 81 - iter 88/118 - loss 0.09258222\n",
            "2019-08-03 01:50:19,964 epoch 81 - iter 99/118 - loss 0.09174071\n",
            "2019-08-03 01:50:21,372 epoch 81 - iter 110/118 - loss 0.09652205\n",
            "2019-08-03 01:50:22,087 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:50:22,095 EPOCH 81 done: loss 0.0977 - lr 0.0031\n",
            "2019-08-03 01:50:23,587 DEV : loss 0.16619662940502167 - score 0.7785\n",
            "2019-08-03 01:50:25,404 TEST : loss 0.1621442437171936 - score 0.7461\n",
            "2019-08-03 01:50:25,821 BAD EPOCHS (no improvement): 4\n",
            "2019-08-03 01:50:29,762 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:50:30,714 epoch 82 - iter 0/118 - loss 0.17561674\n",
            "2019-08-03 01:50:31,692 epoch 82 - iter 11/118 - loss 0.10890571\n",
            "2019-08-03 01:50:32,741 epoch 82 - iter 22/118 - loss 0.11614718\n",
            "2019-08-03 01:50:33,637 epoch 82 - iter 33/118 - loss 0.10679697\n",
            "2019-08-03 01:50:34,612 epoch 82 - iter 44/118 - loss 0.10184764\n",
            "2019-08-03 01:50:35,505 epoch 82 - iter 55/118 - loss 0.10334049\n",
            "2019-08-03 01:50:36,770 epoch 82 - iter 66/118 - loss 0.10398741\n",
            "2019-08-03 01:50:37,688 epoch 82 - iter 77/118 - loss 0.10408429\n",
            "2019-08-03 01:50:38,544 epoch 82 - iter 88/118 - loss 0.10345442\n",
            "2019-08-03 01:50:39,473 epoch 82 - iter 99/118 - loss 0.10038751\n",
            "2019-08-03 01:50:40,746 epoch 82 - iter 110/118 - loss 0.10265502\n",
            "2019-08-03 01:50:41,472 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:50:41,476 EPOCH 82 done: loss 0.1009 - lr 0.0031\n",
            "2019-08-03 01:50:42,934 DEV : loss 0.1678861528635025 - score 0.7682\n",
            "2019-08-03 01:50:44,675 TEST : loss 0.1641736477613449 - score 0.7402\n",
            "2019-08-03 01:50:45,069 BAD EPOCHS (no improvement): 5\n",
            "2019-08-03 01:50:45,073 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:50:45,529 epoch 83 - iter 0/118 - loss 0.03396374\n",
            "2019-08-03 01:50:46,903 epoch 83 - iter 11/118 - loss 0.08774737\n",
            "2019-08-03 01:50:47,814 epoch 83 - iter 22/118 - loss 0.09790135\n",
            "2019-08-03 01:50:48,663 epoch 83 - iter 33/118 - loss 0.09406887\n",
            "2019-08-03 01:50:49,533 epoch 83 - iter 44/118 - loss 0.09524694\n",
            "2019-08-03 01:50:50,408 epoch 83 - iter 55/118 - loss 0.09505946\n",
            "2019-08-03 01:50:51,638 epoch 83 - iter 66/118 - loss 0.10170690\n",
            "2019-08-03 01:50:52,535 epoch 83 - iter 77/118 - loss 0.09863206\n",
            "2019-08-03 01:50:53,429 epoch 83 - iter 88/118 - loss 0.09779684\n",
            "2019-08-03 01:50:54,366 epoch 83 - iter 99/118 - loss 0.09408004\n",
            "2019-08-03 01:50:55,257 epoch 83 - iter 110/118 - loss 0.09454071\n",
            "2019-08-03 01:50:55,971 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:50:55,974 EPOCH 83 done: loss 0.0953 - lr 0.0031\n",
            "2019-08-03 01:50:57,861 DEV : loss 0.16721010208129883 - score 0.7785\n",
            "2019-08-03 01:50:59,609 TEST : loss 0.1639285832643509 - score 0.7402\n",
            "Epoch    82: reducing learning rate of group 0 to 1.5625e-03.\n",
            "2019-08-03 01:50:59,998 BAD EPOCHS (no improvement): 6\n",
            "2019-08-03 01:51:03,965 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:51:04,523 epoch 84 - iter 0/118 - loss 0.03262769\n",
            "2019-08-03 01:51:05,477 epoch 84 - iter 11/118 - loss 0.08970997\n",
            "2019-08-03 01:51:07,075 epoch 84 - iter 22/118 - loss 0.09107485\n",
            "2019-08-03 01:51:08,026 epoch 84 - iter 33/118 - loss 0.08880415\n",
            "2019-08-03 01:51:08,970 epoch 84 - iter 44/118 - loss 0.09186501\n",
            "2019-08-03 01:51:09,915 epoch 84 - iter 55/118 - loss 0.09124248\n",
            "2019-08-03 01:51:10,839 epoch 84 - iter 66/118 - loss 0.08908076\n",
            "2019-08-03 01:51:12,121 epoch 84 - iter 77/118 - loss 0.08867905\n",
            "2019-08-03 01:51:13,128 epoch 84 - iter 88/118 - loss 0.08758762\n",
            "2019-08-03 01:51:14,075 epoch 84 - iter 99/118 - loss 0.08831527\n",
            "2019-08-03 01:51:15,021 epoch 84 - iter 110/118 - loss 0.09005415\n",
            "2019-08-03 01:51:15,748 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:51:15,754 EPOCH 84 done: loss 0.0931 - lr 0.0016\n",
            "2019-08-03 01:51:17,725 DEV : loss 0.16815416514873505 - score 0.7733\n",
            "2019-08-03 01:51:19,681 TEST : loss 0.1647351235151291 - score 0.7402\n",
            "2019-08-03 01:51:20,095 BAD EPOCHS (no improvement): 1\n",
            "2019-08-03 01:51:20,101 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:51:20,556 epoch 85 - iter 0/118 - loss 0.05356795\n",
            "2019-08-03 01:51:21,588 epoch 85 - iter 11/118 - loss 0.08043352\n",
            "2019-08-03 01:51:22,543 epoch 85 - iter 22/118 - loss 0.08725042\n",
            "2019-08-03 01:51:24,102 epoch 85 - iter 33/118 - loss 0.09276841\n",
            "2019-08-03 01:51:25,063 epoch 85 - iter 44/118 - loss 0.08944905\n",
            "2019-08-03 01:51:26,023 epoch 85 - iter 55/118 - loss 0.09187450\n",
            "2019-08-03 01:51:27,009 epoch 85 - iter 66/118 - loss 0.09228973\n",
            "2019-08-03 01:51:28,016 epoch 85 - iter 77/118 - loss 0.09164136\n",
            "2019-08-03 01:51:28,978 epoch 85 - iter 88/118 - loss 0.09148173\n",
            "2019-08-03 01:51:30,468 epoch 85 - iter 99/118 - loss 0.09353729\n",
            "2019-08-03 01:51:31,382 epoch 85 - iter 110/118 - loss 0.09596098\n",
            "2019-08-03 01:51:32,097 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:51:32,101 EPOCH 85 done: loss 0.0937 - lr 0.0016\n",
            "2019-08-03 01:51:33,583 DEV : loss 0.16699984669685364 - score 0.7785\n",
            "2019-08-03 01:51:36,002 TEST : loss 0.16335438191890717 - score 0.7402\n",
            "2019-08-03 01:51:36,436 BAD EPOCHS (no improvement): 2\n",
            "2019-08-03 01:51:40,319 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:51:40,770 epoch 86 - iter 0/118 - loss 0.03316398\n",
            "2019-08-03 01:51:41,798 epoch 86 - iter 11/118 - loss 0.10536060\n",
            "2019-08-03 01:51:42,792 epoch 86 - iter 22/118 - loss 0.09802521\n",
            "2019-08-03 01:51:43,752 epoch 86 - iter 33/118 - loss 0.09369044\n",
            "2019-08-03 01:51:44,699 epoch 86 - iter 44/118 - loss 0.09474106\n",
            "2019-08-03 01:51:46,214 epoch 86 - iter 55/118 - loss 0.09762167\n",
            "2019-08-03 01:51:47,159 epoch 86 - iter 66/118 - loss 0.09668661\n",
            "2019-08-03 01:51:48,164 epoch 86 - iter 77/118 - loss 0.10232631\n",
            "2019-08-03 01:51:49,072 epoch 86 - iter 88/118 - loss 0.10116572\n",
            "2019-08-03 01:51:49,978 epoch 86 - iter 99/118 - loss 0.09658968\n",
            "2019-08-03 01:51:50,873 epoch 86 - iter 110/118 - loss 0.09549169\n",
            "2019-08-03 01:51:52,034 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:51:52,036 EPOCH 86 done: loss 0.0936 - lr 0.0016\n",
            "2019-08-03 01:51:53,661 DEV : loss 0.1673070639371872 - score 0.7785\n",
            "2019-08-03 01:51:55,537 TEST : loss 0.1633932888507843 - score 0.7461\n",
            "2019-08-03 01:51:55,932 BAD EPOCHS (no improvement): 3\n",
            "2019-08-03 01:51:59,709 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:52:00,157 epoch 87 - iter 0/118 - loss 0.14542751\n",
            "2019-08-03 01:52:01,633 epoch 87 - iter 11/118 - loss 0.10271926\n",
            "2019-08-03 01:52:02,521 epoch 87 - iter 22/118 - loss 0.11007173\n",
            "2019-08-03 01:52:03,534 epoch 87 - iter 33/118 - loss 0.09668380\n",
            "2019-08-03 01:52:04,566 epoch 87 - iter 44/118 - loss 0.09144866\n",
            "2019-08-03 01:52:05,538 epoch 87 - iter 55/118 - loss 0.09830109\n",
            "2019-08-03 01:52:06,912 epoch 87 - iter 66/118 - loss 0.09543215\n",
            "2019-08-03 01:52:07,809 epoch 87 - iter 77/118 - loss 0.09354415\n",
            "2019-08-03 01:52:08,747 epoch 87 - iter 88/118 - loss 0.09722569\n",
            "2019-08-03 01:52:09,747 epoch 87 - iter 99/118 - loss 0.09577577\n",
            "2019-08-03 01:52:10,662 epoch 87 - iter 110/118 - loss 0.09582253\n",
            "2019-08-03 01:52:11,441 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:52:11,443 EPOCH 87 done: loss 0.0930 - lr 0.0016\n",
            "2019-08-03 01:52:14,295 DEV : loss 0.16750933229923248 - score 0.7785\n",
            "2019-08-03 01:52:16,045 TEST : loss 0.16325679421424866 - score 0.7402\n",
            "2019-08-03 01:52:16,439 BAD EPOCHS (no improvement): 4\n",
            "2019-08-03 01:52:20,080 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:52:20,561 epoch 88 - iter 0/118 - loss 0.10088344\n",
            "2019-08-03 01:52:21,505 epoch 88 - iter 11/118 - loss 0.11834336\n",
            "2019-08-03 01:52:22,831 epoch 88 - iter 22/118 - loss 0.10290161\n",
            "2019-08-03 01:52:23,686 epoch 88 - iter 33/118 - loss 0.10335165\n",
            "2019-08-03 01:52:24,636 epoch 88 - iter 44/118 - loss 0.09647909\n",
            "2019-08-03 01:52:25,526 epoch 88 - iter 55/118 - loss 0.10353920\n",
            "2019-08-03 01:52:26,457 epoch 88 - iter 66/118 - loss 0.10306935\n",
            "2019-08-03 01:52:27,833 epoch 88 - iter 77/118 - loss 0.09997919\n",
            "2019-08-03 01:52:28,811 epoch 88 - iter 88/118 - loss 0.09658643\n",
            "2019-08-03 01:52:29,752 epoch 88 - iter 99/118 - loss 0.09689862\n",
            "2019-08-03 01:52:30,602 epoch 88 - iter 110/118 - loss 0.09445881\n",
            "2019-08-03 01:52:31,298 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:52:31,302 EPOCH 88 done: loss 0.0932 - lr 0.0016\n",
            "2019-08-03 01:52:33,084 DEV : loss 0.1682596057653427 - score 0.7733\n",
            "2019-08-03 01:52:34,984 TEST : loss 0.16429667174816132 - score 0.7402\n",
            "2019-08-03 01:52:35,415 BAD EPOCHS (no improvement): 5\n",
            "2019-08-03 01:52:35,421 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:52:35,930 epoch 89 - iter 0/118 - loss 0.01978889\n",
            "2019-08-03 01:52:36,895 epoch 89 - iter 11/118 - loss 0.09341799\n",
            "2019-08-03 01:52:37,845 epoch 89 - iter 22/118 - loss 0.08332087\n",
            "2019-08-03 01:52:39,204 epoch 89 - iter 33/118 - loss 0.09791215\n",
            "2019-08-03 01:52:40,171 epoch 89 - iter 44/118 - loss 0.10609545\n",
            "2019-08-03 01:52:41,125 epoch 89 - iter 55/118 - loss 0.10715504\n",
            "2019-08-03 01:52:42,100 epoch 89 - iter 66/118 - loss 0.10069736\n",
            "2019-08-03 01:52:43,021 epoch 89 - iter 77/118 - loss 0.10098475\n",
            "2019-08-03 01:52:44,602 epoch 89 - iter 88/118 - loss 0.09820674\n",
            "2019-08-03 01:52:45,519 epoch 89 - iter 99/118 - loss 0.09556999\n",
            "2019-08-03 01:52:46,421 epoch 89 - iter 110/118 - loss 0.09539540\n",
            "2019-08-03 01:52:47,117 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:52:47,123 EPOCH 89 done: loss 0.0959 - lr 0.0016\n",
            "2019-08-03 01:52:48,427 DEV : loss 0.16778682172298431 - score 0.7785\n",
            "2019-08-03 01:52:50,615 TEST : loss 0.16325326263904572 - score 0.7402\n",
            "Epoch    88: reducing learning rate of group 0 to 7.8125e-04.\n",
            "2019-08-03 01:52:51,038 BAD EPOCHS (no improvement): 6\n",
            "2019-08-03 01:52:54,878 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:52:55,393 epoch 90 - iter 0/118 - loss 0.23658243\n",
            "2019-08-03 01:52:56,327 epoch 90 - iter 11/118 - loss 0.10695716\n",
            "2019-08-03 01:52:57,238 epoch 90 - iter 22/118 - loss 0.09158932\n",
            "2019-08-03 01:52:58,204 epoch 90 - iter 33/118 - loss 0.08221770\n",
            "2019-08-03 01:52:59,611 epoch 90 - iter 44/118 - loss 0.09247731\n",
            "2019-08-03 01:53:00,586 epoch 90 - iter 55/118 - loss 0.09447246\n",
            "2019-08-03 01:53:01,563 epoch 90 - iter 66/118 - loss 0.09360239\n",
            "2019-08-03 01:53:02,551 epoch 90 - iter 77/118 - loss 0.09532935\n",
            "2019-08-03 01:53:03,494 epoch 90 - iter 88/118 - loss 0.09564738\n",
            "2019-08-03 01:53:04,426 epoch 90 - iter 99/118 - loss 0.09526362\n",
            "2019-08-03 01:53:05,896 epoch 90 - iter 110/118 - loss 0.09516468\n",
            "2019-08-03 01:53:06,708 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:53:06,710 EPOCH 90 done: loss 0.0942 - lr 0.0008\n",
            "2019-08-03 01:53:08,189 DEV : loss 0.16821230947971344 - score 0.7733\n",
            "2019-08-03 01:53:10,873 TEST : loss 0.16377682983875275 - score 0.7402\n",
            "2019-08-03 01:53:11,297 BAD EPOCHS (no improvement): 1\n",
            "2019-08-03 01:53:11,306 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:53:11,822 epoch 91 - iter 0/118 - loss 0.06214355\n",
            "2019-08-03 01:53:12,921 epoch 91 - iter 11/118 - loss 0.08468758\n",
            "2019-08-03 01:53:13,869 epoch 91 - iter 22/118 - loss 0.11240320\n",
            "2019-08-03 01:53:14,889 epoch 91 - iter 33/118 - loss 0.11427088\n",
            "2019-08-03 01:53:15,824 epoch 91 - iter 44/118 - loss 0.10191960\n",
            "2019-08-03 01:53:17,176 epoch 91 - iter 55/118 - loss 0.09682531\n",
            "2019-08-03 01:53:18,071 epoch 91 - iter 66/118 - loss 0.09433056\n",
            "2019-08-03 01:53:18,946 epoch 91 - iter 77/118 - loss 0.09488128\n",
            "2019-08-03 01:53:19,797 epoch 91 - iter 88/118 - loss 0.09519890\n",
            "2019-08-03 01:53:20,659 epoch 91 - iter 99/118 - loss 0.09469706\n",
            "2019-08-03 01:53:22,146 epoch 91 - iter 110/118 - loss 0.09515876\n",
            "2019-08-03 01:53:22,901 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:53:22,904 EPOCH 91 done: loss 0.0960 - lr 0.0008\n",
            "2019-08-03 01:53:24,529 DEV : loss 0.16824273765087128 - score 0.7733\n",
            "2019-08-03 01:53:26,612 TEST : loss 0.16345413029193878 - score 0.7402\n",
            "2019-08-03 01:53:27,051 BAD EPOCHS (no improvement): 2\n",
            "2019-08-03 01:53:27,057 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:53:29,216 epoch 92 - iter 0/118 - loss 0.04877318\n",
            "2019-08-03 01:53:30,151 epoch 92 - iter 11/118 - loss 0.09795292\n",
            "2019-08-03 01:53:31,048 epoch 92 - iter 22/118 - loss 0.10641326\n",
            "2019-08-03 01:53:31,938 epoch 92 - iter 33/118 - loss 0.10845960\n",
            "2019-08-03 01:53:32,828 epoch 92 - iter 44/118 - loss 0.10501166\n",
            "2019-08-03 01:53:33,681 epoch 92 - iter 55/118 - loss 0.09897567\n",
            "2019-08-03 01:53:34,935 epoch 92 - iter 66/118 - loss 0.10393309\n",
            "2019-08-03 01:53:35,834 epoch 92 - iter 77/118 - loss 0.10121649\n",
            "2019-08-03 01:53:36,692 epoch 92 - iter 88/118 - loss 0.09728927\n",
            "2019-08-03 01:53:37,558 epoch 92 - iter 99/118 - loss 0.09265892\n",
            "2019-08-03 01:53:38,389 epoch 92 - iter 110/118 - loss 0.09364598\n",
            "2019-08-03 01:53:39,030 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:53:39,033 EPOCH 92 done: loss 0.0951 - lr 0.0008\n",
            "2019-08-03 01:53:40,856 DEV : loss 0.16820307075977325 - score 0.7733\n",
            "2019-08-03 01:53:42,800 TEST : loss 0.16315524280071259 - score 0.7402\n",
            "2019-08-03 01:53:43,204 BAD EPOCHS (no improvement): 3\n",
            "2019-08-03 01:53:43,209 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:53:43,753 epoch 93 - iter 0/118 - loss 0.07675833\n",
            "2019-08-03 01:53:44,754 epoch 93 - iter 11/118 - loss 0.08283402\n",
            "2019-08-03 01:53:46,155 epoch 93 - iter 22/118 - loss 0.08856988\n",
            "2019-08-03 01:53:47,121 epoch 93 - iter 33/118 - loss 0.08682671\n",
            "2019-08-03 01:53:48,065 epoch 93 - iter 44/118 - loss 0.08509327\n",
            "2019-08-03 01:53:48,951 epoch 93 - iter 55/118 - loss 0.08470569\n",
            "2019-08-03 01:53:49,814 epoch 93 - iter 66/118 - loss 0.09459929\n",
            "2019-08-03 01:53:50,766 epoch 93 - iter 77/118 - loss 0.09339550\n",
            "2019-08-03 01:53:52,260 epoch 93 - iter 88/118 - loss 0.09339169\n",
            "2019-08-03 01:53:53,119 epoch 93 - iter 99/118 - loss 0.09147479\n",
            "2019-08-03 01:53:53,989 epoch 93 - iter 110/118 - loss 0.09042516\n",
            "2019-08-03 01:53:54,739 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:53:54,741 EPOCH 93 done: loss 0.0901 - lr 0.0008\n",
            "2019-08-03 01:53:56,971 DEV : loss 0.16801892220973969 - score 0.7785\n",
            "2019-08-03 01:53:58,950 TEST : loss 0.16311302781105042 - score 0.7402\n",
            "2019-08-03 01:53:59,397 BAD EPOCHS (no improvement): 4\n",
            "2019-08-03 01:54:03,209 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:54:03,762 epoch 94 - iter 0/118 - loss 0.07652839\n",
            "2019-08-03 01:54:04,706 epoch 94 - iter 11/118 - loss 0.09070669\n",
            "2019-08-03 01:54:05,617 epoch 94 - iter 22/118 - loss 0.09505309\n",
            "2019-08-03 01:54:06,959 epoch 94 - iter 33/118 - loss 0.09405570\n",
            "2019-08-03 01:54:07,811 epoch 94 - iter 44/118 - loss 0.08807452\n",
            "2019-08-03 01:54:08,667 epoch 94 - iter 55/118 - loss 0.08788542\n",
            "2019-08-03 01:54:09,622 epoch 94 - iter 66/118 - loss 0.08425214\n",
            "2019-08-03 01:54:10,615 epoch 94 - iter 77/118 - loss 0.08446132\n",
            "2019-08-03 01:54:12,211 epoch 94 - iter 88/118 - loss 0.08549023\n",
            "2019-08-03 01:54:13,199 epoch 94 - iter 99/118 - loss 0.08723230\n",
            "2019-08-03 01:54:14,065 epoch 94 - iter 110/118 - loss 0.08692628\n",
            "2019-08-03 01:54:14,799 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:54:14,808 EPOCH 94 done: loss 0.0873 - lr 0.0008\n",
            "2019-08-03 01:54:16,291 DEV : loss 0.16837181150913239 - score 0.7733\n",
            "2019-08-03 01:54:18,650 TEST : loss 0.16347187757492065 - score 0.7402\n",
            "2019-08-03 01:54:19,084 BAD EPOCHS (no improvement): 5\n",
            "2019-08-03 01:54:19,089 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:54:19,509 epoch 95 - iter 0/118 - loss 0.14482974\n",
            "2019-08-03 01:54:20,541 epoch 95 - iter 11/118 - loss 0.10045733\n",
            "2019-08-03 01:54:21,558 epoch 95 - iter 22/118 - loss 0.09976793\n",
            "2019-08-03 01:54:22,411 epoch 95 - iter 33/118 - loss 0.09113537\n",
            "2019-08-03 01:54:23,876 epoch 95 - iter 44/118 - loss 0.08600843\n",
            "2019-08-03 01:54:24,900 epoch 95 - iter 55/118 - loss 0.08343862\n",
            "2019-08-03 01:54:25,906 epoch 95 - iter 66/118 - loss 0.08938104\n",
            "2019-08-03 01:54:26,915 epoch 95 - iter 77/118 - loss 0.09076189\n",
            "2019-08-03 01:54:27,965 epoch 95 - iter 88/118 - loss 0.09105401\n",
            "2019-08-03 01:54:29,252 epoch 95 - iter 99/118 - loss 0.09146801\n",
            "2019-08-03 01:54:30,264 epoch 95 - iter 110/118 - loss 0.08935441\n",
            "2019-08-03 01:54:31,054 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:54:31,056 EPOCH 95 done: loss 0.0882 - lr 0.0008\n",
            "2019-08-03 01:54:32,584 DEV : loss 0.1680072844028473 - score 0.7785\n",
            "2019-08-03 01:54:34,542 TEST : loss 0.16304004192352295 - score 0.7402\n",
            "Epoch    94: reducing learning rate of group 0 to 3.9063e-04.\n",
            "2019-08-03 01:54:35,353 BAD EPOCHS (no improvement): 6\n",
            "2019-08-03 01:54:39,260 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:54:39,742 epoch 96 - iter 0/118 - loss 0.11712045\n",
            "2019-08-03 01:54:40,788 epoch 96 - iter 11/118 - loss 0.06845587\n",
            "2019-08-03 01:54:41,814 epoch 96 - iter 22/118 - loss 0.07578092\n",
            "2019-08-03 01:54:42,815 epoch 96 - iter 33/118 - loss 0.08673143\n",
            "2019-08-03 01:54:43,728 epoch 96 - iter 44/118 - loss 0.08824044\n",
            "2019-08-03 01:54:44,734 epoch 96 - iter 55/118 - loss 0.09446585\n",
            "2019-08-03 01:54:46,316 epoch 96 - iter 66/118 - loss 0.09322744\n",
            "2019-08-03 01:54:47,319 epoch 96 - iter 77/118 - loss 0.09383688\n",
            "2019-08-03 01:54:48,270 epoch 96 - iter 88/118 - loss 0.09313082\n",
            "2019-08-03 01:54:49,130 epoch 96 - iter 99/118 - loss 0.09144467\n",
            "2019-08-03 01:54:50,049 epoch 96 - iter 110/118 - loss 0.09123588\n",
            "2019-08-03 01:54:50,771 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:54:50,774 EPOCH 96 done: loss 0.0928 - lr 0.0004\n",
            "2019-08-03 01:54:52,748 DEV : loss 0.16820228099822998 - score 0.7733\n",
            "2019-08-03 01:54:54,491 TEST : loss 0.16314755380153656 - score 0.7402\n",
            "2019-08-03 01:54:54,910 BAD EPOCHS (no improvement): 1\n",
            "2019-08-03 01:54:54,915 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:54:55,330 epoch 97 - iter 0/118 - loss 0.09487605\n",
            "2019-08-03 01:54:56,267 epoch 97 - iter 11/118 - loss 0.09055218\n",
            "2019-08-03 01:54:57,907 epoch 97 - iter 22/118 - loss 0.09956384\n",
            "2019-08-03 01:54:58,824 epoch 97 - iter 33/118 - loss 0.09845837\n",
            "2019-08-03 01:54:59,766 epoch 97 - iter 44/118 - loss 0.10319597\n",
            "2019-08-03 01:55:00,639 epoch 97 - iter 55/118 - loss 0.09679499\n",
            "2019-08-03 01:55:01,540 epoch 97 - iter 66/118 - loss 0.09496502\n",
            "2019-08-03 01:55:02,460 epoch 97 - iter 77/118 - loss 0.09456300\n",
            "2019-08-03 01:55:03,808 epoch 97 - iter 88/118 - loss 0.09550635\n",
            "2019-08-03 01:55:04,715 epoch 97 - iter 99/118 - loss 0.09376334\n",
            "2019-08-03 01:55:05,703 epoch 97 - iter 110/118 - loss 0.09320747\n",
            "2019-08-03 01:55:06,422 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:55:06,429 EPOCH 97 done: loss 0.0930 - lr 0.0004\n",
            "2019-08-03 01:55:07,886 DEV : loss 0.16828952729701996 - score 0.7733\n",
            "2019-08-03 01:55:10,093 TEST : loss 0.16324160993099213 - score 0.7402\n",
            "2019-08-03 01:55:10,486 BAD EPOCHS (no improvement): 2\n",
            "2019-08-03 01:55:10,489 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:55:11,019 epoch 98 - iter 0/118 - loss 0.16040733\n",
            "2019-08-03 01:55:12,031 epoch 98 - iter 11/118 - loss 0.06408532\n",
            "2019-08-03 01:55:12,960 epoch 98 - iter 22/118 - loss 0.08186484\n",
            "2019-08-03 01:55:13,961 epoch 98 - iter 33/118 - loss 0.09389921\n",
            "2019-08-03 01:55:14,951 epoch 98 - iter 44/118 - loss 0.09029014\n",
            "2019-08-03 01:55:16,277 epoch 98 - iter 55/118 - loss 0.09304446\n",
            "2019-08-03 01:55:17,228 epoch 98 - iter 66/118 - loss 0.09555317\n",
            "2019-08-03 01:55:18,083 epoch 98 - iter 77/118 - loss 0.09307078\n",
            "2019-08-03 01:55:18,980 epoch 98 - iter 88/118 - loss 0.09175876\n",
            "2019-08-03 01:55:19,872 epoch 98 - iter 99/118 - loss 0.08957499\n",
            "2019-08-03 01:55:21,326 epoch 98 - iter 110/118 - loss 0.08966519\n",
            "2019-08-03 01:55:22,012 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:55:22,014 EPOCH 98 done: loss 0.0883 - lr 0.0004\n",
            "2019-08-03 01:55:23,351 DEV : loss 0.1681339293718338 - score 0.7785\n",
            "2019-08-03 01:55:25,071 TEST : loss 0.16308729350566864 - score 0.7402\n",
            "2019-08-03 01:55:25,497 BAD EPOCHS (no improvement): 3\n",
            "2019-08-03 01:55:29,447 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:55:29,945 epoch 99 - iter 0/118 - loss 0.02027941\n",
            "2019-08-03 01:55:31,354 epoch 99 - iter 11/118 - loss 0.10497747\n",
            "2019-08-03 01:55:32,283 epoch 99 - iter 22/118 - loss 0.10652084\n",
            "2019-08-03 01:55:33,204 epoch 99 - iter 33/118 - loss 0.10082445\n",
            "2019-08-03 01:55:34,154 epoch 99 - iter 44/118 - loss 0.10425001\n",
            "2019-08-03 01:55:35,083 epoch 99 - iter 55/118 - loss 0.09897214\n",
            "2019-08-03 01:55:35,966 epoch 99 - iter 66/118 - loss 0.09807060\n",
            "2019-08-03 01:55:37,180 epoch 99 - iter 77/118 - loss 0.09345974\n",
            "2019-08-03 01:55:38,132 epoch 99 - iter 88/118 - loss 0.09379057\n",
            "2019-08-03 01:55:39,051 epoch 99 - iter 99/118 - loss 0.09078069\n",
            "2019-08-03 01:55:39,977 epoch 99 - iter 110/118 - loss 0.09123380\n",
            "2019-08-03 01:55:40,741 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:55:40,743 EPOCH 99 done: loss 0.0914 - lr 0.0004\n",
            "2019-08-03 01:55:42,899 DEV : loss 0.16822047531604767 - score 0.7733\n",
            "2019-08-03 01:55:44,911 TEST : loss 0.1630801260471344 - score 0.7402\n",
            "2019-08-03 01:55:45,297 BAD EPOCHS (no improvement): 4\n",
            "2019-08-03 01:55:45,301 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:55:45,773 epoch 100 - iter 0/118 - loss 0.03067968\n",
            "2019-08-03 01:55:46,729 epoch 100 - iter 11/118 - loss 0.08599385\n",
            "2019-08-03 01:55:47,631 epoch 100 - iter 22/118 - loss 0.07907840\n",
            "2019-08-03 01:55:48,521 epoch 100 - iter 33/118 - loss 0.07303540\n",
            "2019-08-03 01:55:49,869 epoch 100 - iter 44/118 - loss 0.08431827\n",
            "2019-08-03 01:55:50,825 epoch 100 - iter 55/118 - loss 0.08816940\n",
            "2019-08-03 01:55:51,761 epoch 100 - iter 66/118 - loss 0.08552489\n",
            "2019-08-03 01:55:52,622 epoch 100 - iter 77/118 - loss 0.08556624\n",
            "2019-08-03 01:55:53,462 epoch 100 - iter 88/118 - loss 0.08424049\n",
            "2019-08-03 01:55:54,736 epoch 100 - iter 99/118 - loss 0.08562092\n",
            "2019-08-03 01:55:55,738 epoch 100 - iter 110/118 - loss 0.08764706\n",
            "2019-08-03 01:55:56,500 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:55:56,502 EPOCH 100 done: loss 0.0879 - lr 0.0004\n",
            "2019-08-03 01:55:58,047 DEV : loss 0.16865937411785126 - score 0.7733\n",
            "2019-08-03 01:56:00,534 TEST : loss 0.1635141223669052 - score 0.7402\n",
            "2019-08-03 01:56:00,926 BAD EPOCHS (no improvement): 5\n",
            "2019-08-03 01:56:04,614 ----------------------------------------------------------------------------------------------------\n",
            "2019-08-03 01:56:04,618 Testing using best model ...\n",
            "2019-08-03 01:56:04,621 loading file drive/My Drive/Colab Notebooks/flair-results/best-model.pt\n",
            "2019-08-03 01:56:07,537 0.7231\t0.7581\t0.7402\n",
            "2019-08-03 01:56:07,540 \n",
            "MICRO_AVG: acc 0.9 - f1-score 0.9474\n",
            "MACRO_AVG: acc 0.7653 - f1-score 0.85545\n",
            "0          tp: 547 - fp: 15 - fn: 18 - tn: 47 - precision: 0.9733 - recall: 0.9681 - accuracy: 0.9431 - f1-score: 0.9707\n",
            "1          tp: 47 - fp: 18 - fn: 15 - tn: 547 - precision: 0.7231 - recall: 0.7581 - accuracy: 0.5875 - f1-score: 0.7402\n",
            "2019-08-03 01:56:07,541 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOQGCAlcEgXS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}