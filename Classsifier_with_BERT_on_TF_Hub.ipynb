{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classsifier with BERT on TF Hub.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anjapago/AnalyzeAccountability/blob/master/Classsifier_with_BERT_on_TF_Hub.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCpvgG0vwXAZ",
        "colab_type": "text"
      },
      "source": [
        "# Binary Classifier BERT on TF Hub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiYrZKaHwV81",
        "colab_type": "text"
      },
      "source": [
        "Bidirectional Encoder Representations from Transformers(BERT) is a neural network architecture designed by Google researchers is a state-of-the-art approach or NLP tasks, including text classification, translation, summarization, and question answering.\n",
        "\n",
        "BERT has been added to [TF Hub](https://www.tensorflow.org/hub) as a loadable module, and in an existing pipeline, BERT can replace text embedding layers like ELMO and GloVE. \n",
        "\n",
        "[Finetuning](http://wiki.fast.ai/index.php/Fine_tuning) BERT can provide both an accuracy boost and faster training time in many cases.\n",
        "\n",
        "Here, we'll train a a classifier to detect accountability in news articles using BERT in Tensorflow with tf hub. Code was adapted from [this colab notebook](https://colab.research.google.com/github/google-research/bert/blob/master/predicting_movie_reviews_with_bert_on_tf_hub.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsZvic2YxnTz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from datetime import datetime"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cp5wfXDx5SPH",
        "colab_type": "text"
      },
      "source": [
        "In addition to the standard libraries we imported above, we'll need to install BERT's python package."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jviywGyWyKsA",
        "colab_type": "code",
        "outputId": "5f063c6b-256f-4914-ce45-70111894e9d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!pip install bert-tensorflow"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bert-tensorflow in /usr/local/lib/python3.6/dist-packages (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhbGEfwgdEtw",
        "colab_type": "code",
        "outputId": "d15661a7-de74-412f-dd86-67e6dd747828",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "import bert\n",
        "from bert import run_classifier\n",
        "from bert import optimization\n",
        "from bert import tokenization"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0707 18:40:22.881255 139945843152768 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVB3eOcjxxm1",
        "colab_type": "text"
      },
      "source": [
        "Below, we'll set an output directory location to store our model output and checkpoints. We are running this code in Google's hosted Colab, so the directory won't persist after the Colab session ends.\n",
        "\n",
        "Set DO_DELETE to rewrite the OUTPUT_DIR if it exists. Otherwise, Tensorflow will load existing model checkpoints from that directory (if they exist)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4n0QQStRcJut",
        "colab_type": "code",
        "outputId": "f663a92e-b536-427a-d6bd-3738cc3bbb0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Set the output directory for saving model file\n",
        "# Optionally, set a GCP bucket location\n",
        "\n",
        "OUTPUT_DIR = 'OUTPUT_DIR_NAME'#@param {type:\"string\"}\n",
        "DO_DELETE = True #@param {type:\"boolean\"}\n",
        "USE_BUCKET = False #@param {type:\"boolean\"}\n",
        "BUCKET = 'BUCKET_NAME' #@param {type:\"string\"}\n",
        "\n",
        "if USE_BUCKET:\n",
        "  OUTPUT_DIR = 'gs://{}/{}'.format(BUCKET, OUTPUT_DIR)\n",
        "  from google.colab import auth\n",
        "  auth.authenticate_user()\n",
        "\n",
        "if DO_DELETE:\n",
        "  try:\n",
        "    tf.gfile.DeleteRecursively(OUTPUT_DIR)\n",
        "  except:\n",
        "    # Doesn't matter if the directory didn't exist\n",
        "    pass\n",
        "tf.gfile.MakeDirs(OUTPUT_DIR)\n",
        "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Model output directory: OUTPUT_DIR_NAME *****\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmFYvkylMwXn",
        "colab_type": "text"
      },
      "source": [
        "#Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MC_w8SRqN0fr",
        "colab_type": "text"
      },
      "source": [
        "Load the dataset of news excerpts annotated with the accountability label. The code below loads the data from xlsx files, formats it as a pandas data frame, and splits it into test and training sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuMOGwFui4it",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_COLUMN = 'excerpt'\n",
        "LABEL_COLUMN = 'label'\n",
        "label_list = [0, 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fom_ff20gyy6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras\n",
        "import os\n",
        "import re\n",
        "\n",
        "\n",
        "# Load all files from a directory in a DataFrame.\n",
        "def load_xlsx_data(file_names):\n",
        "    excerpts = []\n",
        "    account_labels = []\n",
        "    for file_name in file_names:\n",
        "      data = pd.read_excel(file_name, sheet_name='Dedoose Excerpts Export')\n",
        "      data = data.dropna(axis=0)\n",
        "      ex_col = list(data.columns)[1]\n",
        "      excerpts.extend(list(data[ex_col]))\n",
        "      account_labels.extend(list(data['ACCOUNT']))\n",
        "    data = {}\n",
        "    data[DATA_COLUMN] = excerpts\n",
        "    data[LABEL_COLUMN] = account_labels\n",
        "    data = pd.DataFrame.from_dict(data)\n",
        "    train, test = train_test_split(data, test_size=0.2, random_state=42)\n",
        "    return train, test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQ3leLRiUvXb",
        "colab_type": "text"
      },
      "source": [
        "View the loaded data, and inspect the first few entries in the training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wx875tqkjhKp",
        "colab_type": "code",
        "outputId": "459b4719-3ced-49d6-ea58-f880b4ee32be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "file_path = '/content/sample_data/'\n",
        "file_names = [file_path+'Isla Vista - All Excerpts - 1_2_2019.xlsx',\n",
        "              file_path+'Marysville - All Excerpts - Final - 1_2_2019.xlsx',\n",
        "              file_path+'Newtown - All Excerpts - 1-2-2019.xlsx']\n",
        "train, test = load_xlsx_data(file_names)\n",
        "\n",
        "train.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>excerpt</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>18338</th>\n",
              "      <td>In some ways, Friday changed all that. Our nat...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11698</th>\n",
              "      <td>ince \\nthen, their families have become vocal ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4894</th>\n",
              "      <td>Rodger had legally obtained three semi-automat...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12223</th>\n",
              "      <td>harpe said an expansion of Medicaid under the ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14193</th>\n",
              "      <td>\\nThis is just not right. The list of the 26 v...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 excerpt  label\n",
              "18338  In some ways, Friday changed all that. Our nat...      0\n",
              "11698  ince \\nthen, their families have become vocal ...      0\n",
              "4894   Rodger had legally obtained three semi-automat...      0\n",
              "12223  harpe said an expansion of Medicaid under the ...      0\n",
              "14193  \\nThis is just not right. The list of the 26 v...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V399W0rqNJ-Z",
        "colab_type": "text"
      },
      "source": [
        "#Data Preprocessing\n",
        "We'll need to transform our data into a format BERT understands. This involves two steps. First, we create  `InputExample`'s using the constructor provided in the BERT library.\n",
        "\n",
        "- `text_a` is the text we want to classify, which in this case, is the `Request` field in our Dataframe. \n",
        "- `text_b` is used if we're training a model to understand the relationship between sentences (i.e. is `text_b` a translation of `text_a`? Is `text_b` an answer to the question asked by `text_a`?). This doesn't apply to our task, so we can leave `text_b` blank.\n",
        "- `label` is the label for our example, i.e. True, False"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9gEt5SmM6i6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use the InputExample class from BERT's run_classifier code to create examples from the data\n",
        "train_InputExamples = train.apply(lambda x: bert.run_classifier.InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this example\n",
        "                                                                   text_a = x[DATA_COLUMN], \n",
        "                                                                   text_b = None, \n",
        "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
        "\n",
        "test_InputExamples = test.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n",
        "                                                                   text_a = x[DATA_COLUMN], \n",
        "                                                                   text_b = None, \n",
        "                                                                   label = x[LABEL_COLUMN]), axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCZWZtKxObjh",
        "colab_type": "text"
      },
      "source": [
        "Next, we need to preprocess our data so that it matches the data BERT was trained on:\n",
        "\n",
        "\n",
        "1. Lowercase our text (if we're using a BERT lowercase model)\n",
        "2. Tokenize it (i.e. \"sally says hi\" -> [\"sally\", \"says\", \"hi\"])\n",
        "3. Break words into WordPieces (i.e. \"calling\" -> [\"call\", \"##ing\"])\n",
        "4. Map our words to indexes using a vocab file that BERT provides\n",
        "5. Add special \"CLS\" and \"SEP\" tokens (see the [readme](https://github.com/google-research/bert))\n",
        "6. Append \"index\" and \"segment\" tokens to each input (see the [BERT paper](https://arxiv.org/pdf/1810.04805.pdf))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMWiDtpyQSoU",
        "colab_type": "text"
      },
      "source": [
        "To start, we'll need to load a vocabulary file and lowercasing information directly from the BERT tf hub module:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhJSe0QHNG7U",
        "colab_type": "code",
        "outputId": "1d631268-031e-476d-d178-255e96160c5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# This is a path to an uncased (all lowercase) version of BERT\n",
        "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
        "\n",
        "def create_tokenizer_from_hub_module():\n",
        "  \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
        "  with tf.Graph().as_default():\n",
        "    bert_module = hub.Module(BERT_MODEL_HUB)\n",
        "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
        "    with tf.Session() as sess:\n",
        "      vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
        "                                            tokenization_info[\"do_lower_case\"]])\n",
        "      \n",
        "  return bert.tokenization.FullTokenizer(\n",
        "      vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
        "\n",
        "tokenizer = create_tokenizer_from_hub_module()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0707 18:40:37.283966 139945843152768 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsBo6RCtQmwx",
        "colab_type": "code",
        "outputId": "984875e2-9ac3-4f2f-af92-ed7d6966966a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "tokenizer.tokenize(\"This here's an example of using the BERT tokenizer\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['this',\n",
              " 'here',\n",
              " \"'\",\n",
              " 's',\n",
              " 'an',\n",
              " 'example',\n",
              " 'of',\n",
              " 'using',\n",
              " 'the',\n",
              " 'bert',\n",
              " 'token',\n",
              " '##izer']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OEzfFIt6GIc",
        "colab_type": "text"
      },
      "source": [
        "Using our tokenizer, we'll call `run_classifier.convert_examples_to_features` on our InputExamples to convert them into features BERT understands."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LL5W8gEGRTAf",
        "colab_type": "code",
        "outputId": "f53f96d2-d05e-4da9-8c34-151af3ee79b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# We'll set sequences to be at most 128 tokens long.\n",
        "MAX_SEQ_LENGTH = 128\n",
        "# Convert our train and test features to InputFeatures that BERT understands.\n",
        "train_features = bert.run_classifier.convert_examples_to_features(train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "test_features = bert.run_classifier.convert_examples_to_features(test_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0707 18:40:37.426070 139945843152768 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/bert/run_classifier.py:774: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccp5trMwRtmr",
        "colab_type": "text"
      },
      "source": [
        "#Creating a model\n",
        "\n",
        "Now that we've prepared our data, let's focus on building a model. `create_model` does just this below. First, it loads the BERT tf hub module again (this time to extract the computation graph). Next, it creates a single new layer that will be trained to adapt BERT to our accountability detection task. This strategy of using a mostly trained model is called [fine-tuning](http://wiki.fast.ai/index.php/Fine_tuning)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6o2a5ZIvRcJq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(is_predicting, input_ids, input_mask, segment_ids, labels,\n",
        "                 num_labels):\n",
        "  \"\"\"Creates a classification model.\"\"\"\n",
        "\n",
        "  bert_module = hub.Module(\n",
        "      BERT_MODEL_HUB,\n",
        "      trainable=True)\n",
        "  bert_inputs = dict(\n",
        "      input_ids=input_ids,\n",
        "      input_mask=input_mask,\n",
        "      segment_ids=segment_ids)\n",
        "  bert_outputs = bert_module(\n",
        "      inputs=bert_inputs,\n",
        "      signature=\"tokens\",\n",
        "      as_dict=True)\n",
        "\n",
        "  # beta for L2 regularizer\n",
        "  beta = 0.1\n",
        "  \n",
        "  # Use \"pooled_output\" for classification tasks on an entire sentence.\n",
        "  # Use \"sequence_outputs\" for token-level output.\n",
        "  output_layer = bert_outputs[\"pooled_output\"]\n",
        "\n",
        "  hidden_size = output_layer.shape[-1].value\n",
        "\n",
        "  # Create our own layer to tune for accountability data.\n",
        "  output_weights = tf.get_variable(\n",
        "      \"output_weights\", [num_labels, hidden_size],\n",
        "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "\n",
        "  output_bias = tf.get_variable(\n",
        "      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
        "\n",
        "  with tf.variable_scope(\"loss\"):\n",
        "\n",
        "    # Dropout helps prevent overfitting\n",
        "    output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
        "\n",
        "    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
        "    logits = tf.nn.bias_add(logits, output_bias)\n",
        "    log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
        "\n",
        "    # Convert labels into one-hot encoding\n",
        "    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
        "\n",
        "    predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
        "    # If we're predicting, we want predicted labels and the probabiltiies.\n",
        "    if is_predicting:\n",
        "      return (predicted_labels, log_probs)\n",
        "\n",
        "    # If we're train/eval, compute loss between predicted and actual label\n",
        "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
        "    regularizer = tf.nn.l2_loss(output_weights)\n",
        "    loss = tf.reduce_mean(per_example_loss + beta*regularizer)\n",
        "    return (loss, predicted_labels, log_probs)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpE0ZIDOCQzE",
        "colab_type": "text"
      },
      "source": [
        "Next we'll wrap our model function in a `model_fn_builder` function that adapts our model to work for training, evaluation, and prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnH-AnOQ9KKW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model_fn_builder actually creates our model function\n",
        "# using the passed parameters for num_labels, learning_rate, etc.\n",
        "def model_fn_builder(num_labels, learning_rate, num_train_steps,\n",
        "                     num_warmup_steps):\n",
        "  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
        "  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
        "    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
        "\n",
        "    input_ids = features[\"input_ids\"]\n",
        "    input_mask = features[\"input_mask\"]\n",
        "    segment_ids = features[\"segment_ids\"]\n",
        "    label_ids = features[\"label_ids\"]\n",
        "\n",
        "    is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
        "    \n",
        "    # TRAIN and EVAL\n",
        "    if not is_predicting:\n",
        "\n",
        "      (loss, predicted_labels, log_probs) = create_model(\n",
        "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
        "\n",
        "      train_op = bert.optimization.create_optimizer(\n",
        "          loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
        "\n",
        "      # Calculate evaluation metrics. \n",
        "      def metric_fn(label_ids, predicted_labels):\n",
        "        accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n",
        "        #f1_score = tf.contrib.metrics.f1_score(\n",
        "        #    label_ids,\n",
        "        #    predicted_labels)\n",
        "        auc = tf.metrics.auc(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        recall = tf.metrics.recall(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        precision = tf.metrics.precision(\n",
        "            label_ids,\n",
        "            predicted_labels) \n",
        "        true_pos = tf.metrics.true_positives(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        true_neg = tf.metrics.true_negatives(\n",
        "            label_ids,\n",
        "            predicted_labels)   \n",
        "        false_pos = tf.metrics.false_positives(\n",
        "            label_ids,\n",
        "            predicted_labels)  \n",
        "        false_neg = tf.metrics.false_negatives(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        return {\n",
        "            \"eval_accuracy\": accuracy,\n",
        "            #\"f1_score\": f1_score,\n",
        "            \"auc\": auc,\n",
        "            \"precision\": precision,\n",
        "            \"recall\": recall,\n",
        "            \"true_positives\": true_pos,\n",
        "            \"true_negatives\": true_neg,\n",
        "            \"false_positives\": false_pos,\n",
        "            \"false_negatives\": false_neg\n",
        "        }\n",
        "\n",
        "      eval_metrics = metric_fn(label_ids, predicted_labels)\n",
        "\n",
        "      if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "        return tf.estimator.EstimatorSpec(mode=mode,\n",
        "          loss=loss,\n",
        "          train_op=train_op)\n",
        "      else:\n",
        "          return tf.estimator.EstimatorSpec(mode=mode,\n",
        "            loss=loss,\n",
        "            eval_metric_ops=eval_metrics)\n",
        "    else:\n",
        "      (predicted_labels, log_probs) = create_model(\n",
        "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
        "\n",
        "      predictions = {\n",
        "          'probabilities': log_probs,\n",
        "          'labels': predicted_labels\n",
        "      }\n",
        "      return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
        "\n",
        "  # Return the actual model function in the closure\n",
        "  return model_fn\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjwJ4bTeWXD8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute train and warmup steps from batch size\n",
        "# These hyperparameters are copied from this colab notebook (https://colab.sandbox.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb)\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 2e-5\n",
        "NUM_TRAIN_EPOCHS = 2.0\n",
        "# Warmup is a period of time where hte learning rate \n",
        "# is small and gradually increases--usually helps training.\n",
        "WARMUP_PROPORTION = 0.1\n",
        "# Model configs\n",
        "SAVE_CHECKPOINTS_STEPS = 500\n",
        "SAVE_SUMMARY_STEPS = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emHf9GhfWBZ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute # train and warmup steps from batch size\n",
        "num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
        "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEJldMr3WYZa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Specify outpit directory and number of checkpoint steps to save\n",
        "run_config = tf.estimator.RunConfig(\n",
        "    model_dir=OUTPUT_DIR,\n",
        "    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
        "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_WebpS1X97v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_fn = model_fn_builder(\n",
        "  num_labels=len(label_list),\n",
        "  learning_rate=LEARNING_RATE,\n",
        "  num_train_steps=num_train_steps,\n",
        "  num_warmup_steps=num_warmup_steps)\n",
        "\n",
        "estimator = tf.estimator.Estimator(\n",
        "  model_fn=model_fn,\n",
        "  config=run_config,\n",
        "  params={\"batch_size\": BATCH_SIZE})\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOO3RfG1DYLo",
        "colab_type": "text"
      },
      "source": [
        "Next we create an input builder function that takes our training feature set (`train_features`) and produces a generator. This is a pretty standard design pattern for working with Tensorflow [Estimators](https://www.tensorflow.org/guide/estimators)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Pv2bAlOX_-K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create an input function for training. drop_remainder = True for using TPUs.\n",
        "train_input_fn = bert.run_classifier.input_fn_builder(\n",
        "    features=train_features,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=True,\n",
        "    drop_remainder=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6Nukby2EB6-",
        "colab_type": "text"
      },
      "source": [
        "Now we train our model! For me, using a Colab notebook running on Google's GPUs, my training time was about 25 minutes for three epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nucD4gluYJmK",
        "colab_type": "code",
        "outputId": "28cb85c4-73a6-4243-f3bd-cb6300269ad2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "print(f'Beginning Training!')\n",
        "current_time = datetime.now()\n",
        "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
        "print(\"Training took time \", datetime.now() - current_time)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0707 18:41:14.776826 139945843152768 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Beginning Training!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0707 18:41:27.033431 139945843152768 deprecation.py:506] From <ipython-input-12-baf1adda26aa>:37: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0707 18:41:27.077356 139945843152768 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "W0707 18:41:27.079145 139945843152768 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n",
            "W0707 18:41:27.087456 139945843152768 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/learning_rate_schedule.py:409: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "W0707 18:41:27.101773 139945843152768 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:70: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "W0707 18:41:27.343268 139945843152768 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0707 18:41:31.266698 139945843152768 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:117: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training took time  0:10:04.951002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmbLTVniARy3",
        "colab_type": "text"
      },
      "source": [
        "Now let's use our test data to see how well our model did:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIhejfpyJ8Bx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_input_fn = run_classifier.input_fn_builder(\n",
        "    features=test_features,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=False,\n",
        "    drop_remainder=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPVEXhNjYXC-",
        "colab_type": "code",
        "outputId": "595ed0c1-0f86-4570-aa69-cda58c7c5be5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "estimator.evaluate(input_fn=test_input_fn, steps=None)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "W0707 18:51:35.868622 139945843152768 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'auc': 0.8586856,\n",
              " 'eval_accuracy': 0.94262856,\n",
              " 'false_negatives': 150.0,\n",
              " 'false_positives': 101.0,\n",
              " 'global_step': 546,\n",
              " 'loss': 0.16572995,\n",
              " 'precision': 0.8119181,\n",
              " 'recall': 0.7440273,\n",
              " 'true_negatives': 3688.0,\n",
              " 'true_positives': 436.0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJqO--_dPw8g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "81962db5-0172-4396-b188-bb169c500444"
      },
      "source": [
        "test_train_input_fn = run_classifier.input_fn_builder(\n",
        "    features=train_features,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=False,\n",
        "    drop_remainder=False)\n",
        "estimator.evaluate(input_fn=test_train_input_fn, steps=None)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'auc': 0.9224019,\n",
              " 'eval_accuracy': 0.96668,\n",
              " 'false_negatives': 333.0,\n",
              " 'false_positives': 250.0,\n",
              " 'global_step': 546,\n",
              " 'loss': 0.11190539,\n",
              " 'precision': 0.8921949,\n",
              " 'recall': 0.86136556,\n",
              " 'true_negatives': 14845.0,\n",
              " 'true_positives': 2069.0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqiFnPZ8jfN7",
        "colab_type": "text"
      },
      "source": [
        "    Results from trainable = true, epochs = 6, random state = 0\n",
        "\n",
        "test = {'auc': 0.85972005,\n",
        " 'eval_accuracy': 0.9376,\n",
        " 'false_negatives': 150.0,\n",
        " 'false_positives': 123.0,\n",
        " 'global_step': 3280,\n",
        " 'loss': 0.2913218,\n",
        " 'precision': 0.78719723,\n",
        " 'recall': 0.75206614,\n",
        " 'true_negatives': 3647.0,\n",
        " 'true_positives': 455.0}\n",
        " \n",
        " train = {'auc': 0.9930013,\n",
        " 'eval_accuracy': 0.9955421,\n",
        " 'false_negatives': 25.0,\n",
        " 'false_positives': 53.0,\n",
        " 'global_step': 3280,\n",
        " 'loss': 0.011221944,\n",
        " 'precision': 0.97801745,\n",
        " 'recall': 0.98950905,\n",
        " 'true_negatives': 15061.0,\n",
        " 'true_positives': 2358.0}\n",
        " \n",
        "    Results from trainable = true, epochs = 3, random state = 0\n",
        " \n",
        "test = {'auc': 0.8620361,\n",
        " 'eval_accuracy': 0.9392,\n",
        " 'f1_score': 0.77457625,\n",
        " 'false_negatives': 148.0,\n",
        " 'false_positives': 118.0,\n",
        " 'global_step': 1640,\n",
        " 'loss': 0.21235444,\n",
        " 'precision': 0.7947826,\n",
        " 'recall': 0.7553719,\n",
        " 'true_negatives': 3652.0,\n",
        " 'true_positives': 457.0}\n",
        " \n",
        "    Results from trainable = true, epochs = 3, random state = 42, dropout = 0.9\n",
        "\n",
        "\n",
        "test = {'auc': 0.8757505,\n",
        " 'eval_accuracy': 0.9472,\n",
        " 'false_negatives': 130.0,\n",
        " 'false_positives': 101.0,\n",
        " 'global_step': 1640,\n",
        " 'loss': 0.20042753,\n",
        " 'precision': 0.81867146,\n",
        " 'recall': 0.778157,\n",
        " 'true_negatives': 3688.0,\n",
        " 'true_positives': 456.0}\n",
        " \n",
        " train = {'auc': 0.9838055,\n",
        " 'eval_accuracy': 0.99108416,\n",
        " 'false_negatives': 63.0,\n",
        " 'false_positives': 93.0,\n",
        " 'global_step': 1640,\n",
        " 'loss': 0.028095467,\n",
        " 'precision': 0.96175987,\n",
        " 'recall': 0.97377187,\n",
        " 'true_negatives': 15002.0,\n",
        " 'true_positives': 2339.0}\n",
        " \n",
        "     Results from trainable = true, epochs = 3, random state = 42, dropout = 0.9, with L2, beta= 0.1\n",
        " \n",
        " test = {'auc': 0.86386645,\n",
        " 'eval_accuracy': 0.94285715,\n",
        " 'false_negatives': 143.0,\n",
        " 'false_positives': 107.0,\n",
        " 'global_step': 1640,\n",
        " 'loss': 0.23301551,\n",
        " 'precision': 0.80545455,\n",
        " 'recall': 0.7559727,\n",
        " 'true_negatives': 3682.0,\n",
        " 'true_positives': 443.0}\n",
        " \n",
        " train = {'auc': 0.9849268,\n",
        " 'eval_accuracy': 0.99211293,\n",
        " 'false_negatives': 60.0,\n",
        " 'false_positives': 78.0,\n",
        " 'global_step': 1640,\n",
        " 'loss': 0.043376114,\n",
        " 'precision': 0.9677686,\n",
        " 'recall': 0.9750208,\n",
        " 'true_negatives': 15017.0,\n",
        " 'true_positives': 2342.0}\n",
        " \n",
        "      Results from trainable = true, epochs = 1, random state = 42, dropout = 0.9, with L2, beta= 0.1\n",
        " \n",
        " test = {'auc': 0.8586856,\n",
        " 'eval_accuracy': 0.94262856,\n",
        " 'false_negatives': 150.0,\n",
        " 'false_positives': 101.0,\n",
        " 'global_step': 546,\n",
        " 'loss': 0.16572995,\n",
        " 'precision': 0.8119181,\n",
        " 'recall': 0.7440273,\n",
        " 'true_negatives': 3688.0,\n",
        " 'true_positives': 436.0}\n",
        " \n",
        " train = {'auc': 0.9224019,\n",
        " 'eval_accuracy': 0.96668,\n",
        " 'false_negatives': 333.0,\n",
        " 'false_positives': 250.0,\n",
        " 'global_step': 546,\n",
        " 'loss': 0.11190539,\n",
        " 'precision': 0.8921949,\n",
        " 'recall': 0.86136556,\n",
        " 'true_negatives': 14845.0,\n",
        " 'true_positives': 2069.0}\n",
        " \n",
        "     Results from trainable = true, epochs = 3, random state = 42, dropout=1 (no dropout)\n",
        " \n",
        " test = {'auc': 0.86617136,\n",
        " 'eval_accuracy': 0.9456,\n",
        " 'false_negatives': 142.0,\n",
        " 'false_positives': 96.0,\n",
        " 'global_step': 1640,\n",
        " 'loss': 0.22034082,\n",
        " 'precision': 0.82222223,\n",
        " 'recall': 0.75767916,\n",
        " 'true_negatives': 3693.0,\n",
        " 'true_positives': 444.0}\n",
        " \n",
        " train = {'auc': 0.9862277,\n",
        " 'eval_accuracy': 0.99194145,\n",
        " 'false_negatives': 52.0,\n",
        " 'false_positives': 89.0,\n",
        " 'global_step': 1640,\n",
        " 'loss': 0.025706513,\n",
        " 'precision': 0.9635096,\n",
        " 'recall': 0.97835135,\n",
        " 'true_negatives': 15006.0,\n",
        " 'true_positives': 2350.0}\n",
        " \n",
        "    Results from trainable = true, epochs = 3, random state = 42, dropout=0.8\n",
        "  \n",
        "  test = {'auc': 0.87114984,\n",
        " 'eval_accuracy': 0.9442286,\n",
        " 'false_negatives': 134.0,\n",
        " 'false_positives': 110.0,\n",
        " 'global_step': 1640,\n",
        " 'loss': 0.20319265,\n",
        " 'precision': 0.80427045,\n",
        " 'recall': 0.7713311,\n",
        " 'true_negatives': 3679.0,\n",
        " 'true_positives': 452.0}\n",
        "  \n",
        "  train = {'auc': 0.9843448,\n",
        " 'eval_accuracy': 0.99171287,\n",
        " 'false_negatives': 62.0,\n",
        " 'false_positives': 83.0,\n",
        " 'global_step': 1640,\n",
        " 'loss': 0.024463367,\n",
        " 'precision': 0.965745,\n",
        " 'recall': 0.97418815,\n",
        " 'true_negatives': 15012.0,\n",
        " 'true_positives': 2340.0}\n",
        " \n",
        "     Results from trainable = true, epochs = 3, random state = 42, dropout = 0.6\n",
        " \n",
        " test = {'auc': 0.87173915,\n",
        " 'eval_accuracy': 0.944,\n",
        " 'false_negatives': 133.0,\n",
        " 'false_positives': 112.0,\n",
        " 'global_step': 1640,\n",
        " 'loss': 0.21192765,\n",
        " 'precision': 0.8017699,\n",
        " 'recall': 0.77303755,\n",
        " 'true_negatives': 3677.0,\n",
        " 'true_positives': 453.0}\n",
        " \n",
        " train = {'auc': 0.9841035,\n",
        " 'eval_accuracy': 0.99159855,\n",
        " 'false_negatives': 63.0,\n",
        " 'false_positives': 84.0,\n",
        " 'global_step': 1640,\n",
        " 'loss': 0.025331786,\n",
        " 'precision': 0.9653322,\n",
        " 'recall': 0.97377187,\n",
        " 'true_negatives': 15011.0,\n",
        " 'true_positives': 2339.0}\n",
        " \n",
        "      Results from trainable = true, epochs = 3, random state = 42, dropout = 0.4\n",
        " \n",
        " test = {'auc': 0.8663647,\n",
        " 'eval_accuracy': 0.9446857,\n",
        " 'false_negatives': 141.0,\n",
        " 'false_positives': 101.0,\n",
        " 'global_step': 1640,\n",
        " 'loss': 0.21934973,\n",
        " 'precision': 0.8150183,\n",
        " 'recall': 0.75938565,\n",
        " 'true_negatives': 3688.0,\n",
        " 'true_positives': 445.0}\n",
        " \n",
        " train = {'auc': 0.98442054,\n",
        " 'eval_accuracy': 0.9915414,\n",
        " 'false_negatives': 61.0,\n",
        " 'false_positives': 87.0,\n",
        " 'global_step': 1640,\n",
        " 'loss': 0.026988935,\n",
        " 'precision': 0.964168,\n",
        " 'recall': 0.9746045,\n",
        " 'true_negatives': 15008.0,\n",
        " 'true_positives': 2341.0}\n",
        " \n",
        "    Results from trainable = false, epochs = 3, random state = 42\n",
        "  \n",
        "  test = {'auc': 0.5003254,\n",
        " 'eval_accuracy': 0.8653714,\n",
        " 'false_negatives': 585.0,\n",
        " 'false_positives': 4.0,\n",
        " 'global_step': 1640,\n",
        " 'loss': 0.37944606,\n",
        " 'precision': 0.2,\n",
        " 'recall': 0.0017064846,\n",
        " 'true_negatives': 3785.0,\n",
        " 'true_positives': 1.0}\n",
        "  \n",
        "  train = {'auc': 0.49989575,\n",
        " 'eval_accuracy': 0.8616334,\n",
        " 'false_negatives': 2399.0,\n",
        " 'false_positives': 22.0,\n",
        " 'global_step': 1640,\n",
        " 'loss': 0.3832463,\n",
        " 'precision': 0.12,\n",
        " 'recall': 0.0012489592,\n",
        " 'true_negatives': 15073.0,\n",
        " 'true_positives': 3.0}\n",
        " \n",
        "     Results from trainable =false, epochs = 10, random state = 42\n",
        "  \n",
        "  test = {'auc': 0.5003254,\n",
        " 'eval_accuracy': 0.8653714,\n",
        " 'false_negatives': 585.0,\n",
        " 'false_positives': 4.0,\n",
        " 'global_step': 5467,\n",
        " 'loss': 0.35959232,\n",
        " 'precision': 0.2,\n",
        " 'recall': 0.0017064846,\n",
        " 'true_negatives': 3785.0,\n",
        " 'true_positives': 1.0}"
      ]
    }
  ]
}